{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c96143b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&display=swap');\n",
       "\n",
       "\n",
       "/* Text areas (Classic Notebook + JupyterLab) */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "div.rendered_html, .output_subarea {\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "/* RTL for rendered markdown/html content */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "h1, h2, h3, h4, h5, h6, p, strong, label, ol, ul, li {\n",
       "  line-height: 1.9;\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "h1 { font-size: 2rem; color: #070F2B; font-weight: 900}\n",
       "h2 { font-size: 1.8rem; color: #070F2B; font-weight: 800}\n",
       "h3 { font-size: 1.6rem; color: #070F2B; font-weight: 700}\n",
       "h4 { font-size: 1.4rem; color: #1E3E62; font-weight: 600}\n",
       "h5 { font-size: 1.2rem; color: #1E3E62}\n",
       "h6 { font-size: 1rem; color: #1E3E62}\n",
       "p { font-size: 1.1rem; ; font-weight: 400}\n",
       "ol, ul, li, th, td  { font-size: 1rem; }\n",
       "\n",
       "/* Keep code + outputs LTR and monospace */\n",
       ".CodeMirror, .CodeMirror *,\n",
       "pre, code,\n",
       ".jp-CodeCell .jp-InputArea, .jp-CodeCell .jp-InputArea *,\n",
       ".jp-OutputArea, .jp-OutputArea * {\n",
       "  direction: ltr !important;\n",
       "  text-align: left !important;\n",
       "  font-size: 1rem !important;\n",
       "  font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "css = Path(\"../../../css/custom.css\").read_text(encoding=\"utf-8\")\n",
    "display(HTML(f\"<style>{css}</style>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8a46c1",
   "metadata": {},
   "source": [
    "# Chapter 2 — Basics of Data and Preprocessing\n",
    "## Lesson 11: Encoding Categorical Features (One-Hot, Ordinal, Hashing, Target Encoding)\n",
    "\n",
    "### What you will learn\n",
    "By the end of this lesson, you will be able to:\n",
    "\n",
    "1. Identify *which* categorical features require encoding and *why* most ML estimators cannot consume raw strings.\n",
    "2. Implement and compare **one-hot**, **ordinal**, **hashing**, and **target** encoding.\n",
    "3. Reason about the **statistical and computational tradeoffs**: dimensionality, sparsity, collisions, bias/variance, and leakage risk.\n",
    "4. Build **production-grade preprocessing pipelines** with `ColumnTransformer` and `Pipeline`, including safe handling of unseen categories.\n",
    "5. Apply **leakage-safe target encoding** using out-of-fold statistics.\n",
    "\n",
    "Throughout, we will use multiple datasets from the repository, loaded by relative paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d4b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, SGDClassifier\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 140)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca44869",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Why categorical encoding is not a cosmetic step\n",
    "\n",
    "A categorical feature takes values in a **finite set**:\n",
    "$$\n",
    "x \\in \\mathcal{C}=\\{c_1,\\dots,c_K\\}.\n",
    "$$\n",
    "\n",
    "Most learning algorithms operate on vectors in $\\mathbb{R}^d$ and rely on algebraic operations (inner products, gradients, distances). Raw categories (strings) have **no canonical arithmetic**:\n",
    "- There is no meaningful definition of $c_i + c_j$ or $2\\cdot c_i$.\n",
    "- Even if you map categories to integers, that mapping creates **artificial geometry** unless the categories are truly ordered.\n",
    "\n",
    "Encoding is therefore a *representation choice*:\n",
    "$$\n",
    "\\phi:\\mathcal{C}\\rightarrow \\mathbb{R}^d,\\quad \\text{and we learn on } \\phi(x).\n",
    "$$\n",
    "\n",
    "A good encoding should:\n",
    "- preserve *relevant structure* (e.g., order when it exists),\n",
    "- avoid injecting *false structure* (e.g., arbitrary integer distances),\n",
    "- be robust to *unseen categories*,\n",
    "- control *dimensionality and memory*,\n",
    "- and (for target encoding) avoid **leakage**.\n",
    "\n",
    "We will analyze four standard families:\n",
    "1. One-hot encoding\n",
    "2. Ordinal encoding\n",
    "3. Hashing (feature hashing / hashing trick)\n",
    "4. Target encoding (mean encoding) with leakage-safe variants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492de481",
   "metadata": {},
   "source": [
    "## 2. Categorical taxonomy: nominal vs ordinal vs high-cardinality\n",
    "\n",
    "Categorical variables appear in several forms:\n",
    "\n",
    "### Nominal (unordered)\n",
    "Examples: `Sex ∈ {M,F}`, `Color ∈ {Red, Blue, ...}`.\n",
    "There is **no order**. Encodings must not imply that one category is “larger”.\n",
    "\n",
    "### Ordinal (ordered)\n",
    "Examples: education level, ratings (`low < medium < high`), or domain-defined scales.\n",
    "Here, order is meaningful, and an encoding may exploit that monotonic structure.\n",
    "\n",
    "### High-cardinality nominal\n",
    "Examples: product IDs, user IDs, municipalities, free-form categories.\n",
    "If $K$ (number of unique categories) is large, one-hot may be infeasible because it creates a very high-dimensional sparse matrix.\n",
    "\n",
    "A convenient summary is:\n",
    "\n",
    "| Type | Typical $K$ | Encoding candidates | Main risk |\n",
    "|---|---:|---|---|\n",
    "| Nominal | small–medium | one-hot | dimensionality if many categories |\n",
    "| Ordinal | small–medium | ordinal (with explicit ordering) | false ordering if you guess the order |\n",
    "| High-card nominal | large | hashing, target encoding | collisions (hashing), leakage (target) |\n",
    "\n",
    "Next, we implement each method with real datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505e3ff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. One-hot encoding: the default for nominal categories\n",
    "\n",
    "### Definition\n",
    "For a category set $\\mathcal{C}=\\{c_1,\\dots,c_K\\}$, one-hot encoding maps\n",
    "$$\n",
    "\\phi(c_k) = e_k \\in \\mathbb{R}^K\n",
    "$$\n",
    "where $e_k$ is the $k$-th standard basis vector (1 at index $k$, 0 otherwise).\n",
    "\n",
    "If a sample has multiple categorical fields, one-hot is applied per field and the results are concatenated.\n",
    "\n",
    "### Dummy-variable trap and identifiability\n",
    "In linear models with an intercept, one-hot columns for a single feature are linearly dependent:\n",
    "$$\n",
    "\\sum_{k=1}^{K} e_k = \\mathbf{1}.\n",
    "$$\n",
    "A common practice is to drop one category (reference coding) or rely on regularization.\n",
    "In scikit-learn, `OneHotEncoder(drop=\"first\")` drops one category per feature.\n",
    "\n",
    "### When it works well\n",
    "- Nominal categories with low–moderate $K$\n",
    "- Linear / generalized linear models that benefit from sparse, high-dimensional representations\n",
    "- Many models accept sparse matrices efficiently (e.g., logistic regression with `saga` solver)\n",
    "\n",
    "We start with the `drug200.csv` dataset (categorical predictors like `Sex`, `BP`, `Cholesterol`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b2f94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>DrugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>DrugY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0   23   F    HIGH        HIGH   25.355  DrugY\n",
       "1   47   M     LOW        HIGH   13.093  drugC\n",
       "2   47   M     LOW        HIGH   10.114  drugC\n",
       "3   28   F  NORMAL        HIGH    7.798  drugX\n",
       "4   61   F     LOW        HIGH   18.043  DrugY"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_drug = \"../../../Datasets/Classification/drug200.csv\"\n",
    "drug = pd.read_csv(path_drug)\n",
    "drug.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50beac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Age          200 non-null    int64  \n",
      " 1   Sex          200 non-null    object \n",
      " 2   BP           200 non-null    object \n",
      " 3   Cholesterol  200 non-null    object \n",
      " 4   Na_to_K      200 non-null    float64\n",
      " 5   Drug         200 non-null    object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 9.5+ KB\n"
     ]
    }
   ],
   "source": [
    "drug.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed01b2e7",
   "metadata": {},
   "source": [
    "### Build a baseline one-hot pipeline\n",
    "\n",
    "We will:\n",
    "1. split train/test,\n",
    "2. one-hot encode categorical columns,\n",
    "3. keep numeric columns as-is,\n",
    "4. fit a multinomial logistic regression.\n",
    "\n",
    "`handle_unknown=\"ignore\"` is essential for robustness when a new category appears at inference time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "616f2675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Sex', 'BP', 'Cholesterol'], ['Age', 'Na_to_K'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"Drug\"\n",
    "X = drug.drop(columns=[target])\n",
    "y = drug[target]\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "cat_cols, num_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f94de59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "preprocess_ohe = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "clf_ohe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_ohe),\n",
    "    (\"model\", LogisticRegression(max_iter=5000, solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "clf_ohe.fit(X_train, y_train)\n",
    "\n",
    "pred = clf_ohe.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7011ef90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,\n",
       " array(['Sex_F', 'Sex_M', 'BP_HIGH', 'BP_LOW', 'BP_NORMAL',\n",
       "        'Cholesterol_HIGH', 'Cholesterol_NORMAL', 'Age', 'Na_to_K'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect expanded feature space\n",
    "ohe = clf_ohe.named_steps[\"preprocess\"].named_transformers_[\"cat\"]\n",
    "ohe_feature_names = ohe.get_feature_names_out(cat_cols)\n",
    "\n",
    "num_feature_names = np.array(num_cols, dtype=object)\n",
    "all_feature_names = np.concatenate([ohe_feature_names, num_feature_names])\n",
    "\n",
    "len(all_feature_names), all_feature_names[:12]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f121c447",
   "metadata": {},
   "source": [
    "### Interpretability: coefficients per category (linear models)\n",
    "\n",
    "Logistic regression learns coefficients such that:\n",
    "$$\n",
    "\\log\\frac{P(Y=k\\mid x)}{P(Y=\\text{ref}\\mid x)} = \\beta_k^\\top \\phi(x).\n",
    "$$\n",
    "\n",
    "We can inspect which categories push the prediction toward a specific drug.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c69d75a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>BP_HIGH</th>\n",
       "      <th>BP_LOW</th>\n",
       "      <th>BP_NORMAL</th>\n",
       "      <th>Cholesterol_HIGH</th>\n",
       "      <th>Cholesterol_NORMAL</th>\n",
       "      <th>Age</th>\n",
       "      <th>Na_to_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DrugY</th>\n",
       "      <td>-0.228</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugA</th>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.224</td>\n",
       "      <td>1.611</td>\n",
       "      <td>-0.880</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugB</th>\n",
       "      <td>0.340</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>1.461</td>\n",
       "      <td>-1.008</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugC</th>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>1.707</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>1.133</td>\n",
       "      <td>-1.136</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugX</th>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-2.169</td>\n",
       "      <td>0.137</td>\n",
       "      <td>2.035</td>\n",
       "      <td>-0.805</td>\n",
       "      <td>0.809</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sex_F  Sex_M  BP_HIGH  BP_LOW  BP_NORMAL  Cholesterol_HIGH  Cholesterol_NORMAL    Age  Na_to_K\n",
       "DrugY -0.228  0.228    0.087   0.044     -0.132            -0.089               0.088  0.003    2.069\n",
       "drugA -0.230  0.224    1.611  -0.880     -0.737             0.092              -0.097 -0.086   -0.556\n",
       "drugB  0.340 -0.334    1.461  -1.008     -0.447            -0.330               0.336  0.124   -0.379\n",
       "drugC  0.021 -0.024   -0.991   1.707     -0.720             1.133              -1.136 -0.024   -0.653\n",
       "drugX  0.096 -0.093   -2.169   0.137      2.035            -0.805               0.809 -0.018   -0.480"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = clf_ohe.named_steps[\"model\"]\n",
    "coef = pd.DataFrame(model.coef_, columns=all_feature_names, index=model.classes_)\n",
    "coef.iloc[:, :15].round(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ea32c",
   "metadata": {},
   "source": [
    "### Practical notes for one-hot\n",
    "\n",
    "1. **High cardinality**: if a column has thousands of categories, one-hot can explode memory.\n",
    "2. **Rare categories**: extremely rare categories may act like noise. A common trick is to group rare categories into `\"Other\"`.\n",
    "3. **Trees**: some tree methods can accept integer codes, but one-hot can still be beneficial depending on the library and configuration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a8ac3e",
   "metadata": {},
   "source": [
    "### One-hot in matrix form (and why rank matters)\n",
    "\n",
    "Suppose you have one nominal feature with $K$ categories and $n$ samples. Let $Z\\in\\{0,1\\}^{n\\times K}$ be the one-hot design matrix, where each row has exactly one 1. Then:\n",
    "\n",
    "- Row sums are 1: $Z\\mathbf{1}=\\mathbf{1}$.\n",
    "- If your model includes an intercept (a constant column), then that intercept is **exactly** a linear combination of one-hot columns, creating collinearity.\n",
    "\n",
    "A simple rank argument:\n",
    "\n",
    "- Without an intercept, $\\text{rank}(Z)=K$ (assuming each category appears at least once).\n",
    "- With an intercept column appended, the combined matrix is rank $K$ but has $K+1$ columns, so it is not full column rank.\n",
    "- If you drop one category (reference coding), you get $K-1$ one-hot columns; with an intercept, the matrix can become full rank.\n",
    "\n",
    "In practice, many solvers can handle collinearity via regularization, but being explicit about the encoding makes debugging and interpretation easier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6247203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories in BP: 3\n",
      "Rank(Z_full): 3 shape: (200, 3)\n",
      "Rank([1 | Z_full]): 3 shape: (200, 4)\n",
      "Rank([1 | Z_drop_first]): 3 shape: (200, 3)\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate rank / collinearity on a single categorical feature from drug200\n",
    "\n",
    "Z_full = pd.get_dummies(drug[\"BP\"], prefix=\"BP\")  # K columns\n",
    "Z_full_mat = Z_full.to_numpy()\n",
    "\n",
    "# Add intercept\n",
    "X_full = np.column_stack([np.ones(len(Z_full_mat)), Z_full_mat])\n",
    "\n",
    "rank_Z = np.linalg.matrix_rank(Z_full_mat)\n",
    "rank_X_full = np.linalg.matrix_rank(X_full)\n",
    "\n",
    "Z_drop = pd.get_dummies(drug[\"BP\"], prefix=\"BP\", drop_first=True)  # K-1 columns\n",
    "X_drop = np.column_stack([np.ones(len(Z_drop)), Z_drop.to_numpy()])\n",
    "rank_X_drop = np.linalg.matrix_rank(X_drop)\n",
    "\n",
    "print(\"Categories in BP:\", drug[\"BP\"].nunique())\n",
    "print(\"Rank(Z_full):\", rank_Z, \"shape:\", Z_full_mat.shape)\n",
    "print(\"Rank([1 | Z_full]):\", rank_X_full, \"shape:\", X_full.shape)\n",
    "print(\"Rank([1 | Z_drop_first]):\", rank_X_drop, \"shape:\", X_drop.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f9a3b3",
   "metadata": {},
   "source": [
    "### One-hot with `drop=\"first\"` and regularization\n",
    "\n",
    "Two common patterns:\n",
    "\n",
    "1. **Reference coding**: `OneHotEncoder(drop=\"first\")`\n",
    "   - removes one level per feature,\n",
    "   - improves identifiability for linear models with intercept,\n",
    "   - coefficients are interpreted relative to the dropped reference level.\n",
    "\n",
    "2. **Keep all levels + regularization**\n",
    "   - keep the full one-hot matrix,\n",
    "   - use L2/L1 penalties to control coefficient magnitude.\n",
    "\n",
    "For logistic regression with L2 regularization, the optimization (binary case) is:\n",
    "$$\n",
    "\\min_\\beta \\; \\sum_{i=1}^n \\log\\left(1+\\exp(-y_i \\beta^\\top x_i)\\right) + \\lambda \\lVert \\beta\\rVert_2^2.\n",
    "$$\n",
    "\n",
    "With sparse high-dimensional one-hot features, L1 or elastic net are also common to encourage sparsity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c842158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98, 0.98)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare performance with and without drop='first' on the same task (drug200)\n",
    "\n",
    "preprocess_ohe_drop = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "clf_ohe_drop = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_ohe_drop),\n",
    "    (\"model\", LogisticRegression(max_iter=5000, solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "clf_ohe_drop.fit(X_train, y_train)\n",
    "pred_drop = clf_ohe_drop.predict(X_test)\n",
    "acc_drop = accuracy_score(y_test, pred_drop)\n",
    "\n",
    "acc, acc_drop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eabf08e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Ordinal encoding: when categories have a real order\n",
    "\n",
    "### Definition\n",
    "Ordinal encoding maps categories to integers:\n",
    "$$\n",
    "\\phi(c_k)=k \\in \\{1,\\dots,K\\}.\n",
    "$$\n",
    "\n",
    "This injects an order and a notion of distance:\n",
    "$$\n",
    "\\lvert \\phi(c_i)-\\phi(c_j)\\rvert.\n",
    "$$\n",
    "\n",
    "### Core risk\n",
    "If the variable is nominal, ordinal encoding creates **spurious monotonicity**. Many models will interpret “bigger code” as “bigger effect”.\n",
    "\n",
    "### Correct use case\n",
    "When the domain defines an order, and you encode that order explicitly.\n",
    "\n",
    "We will use the `diamonds.csv` dataset, where variables such as `cut` and `clarity` have widely used orderings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "088ac78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_diamonds = \"../../../Datasets/Regression/diamonds.csv\"\n",
    "diamonds = pd.read_csv(path_diamonds)\n",
    "diamonds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e1bf1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>price</th>\n",
       "      <th>carat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>326</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>326</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>327</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>334</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>335</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cut color clarity  price  carat\n",
       "0    Ideal     E     SI2    326   0.23\n",
       "1  Premium     E     SI1    326   0.21\n",
       "2     Good     E     VS1    327   0.23\n",
       "3  Premium     I     VS2    334   0.29\n",
       "4     Good     J     SI2    335   0.31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds[[\"cut\",\"color\",\"clarity\",\"price\",\"carat\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c564609b",
   "metadata": {},
   "source": [
    "### Define explicit orderings\n",
    "\n",
    "For demonstration, we specify typical orderings:\n",
    "\n",
    "- `cut`: Fair < Good < Very Good < Premium < Ideal\n",
    "- `clarity`: I1 < SI2 < SI1 < VS2 < VS1 < VVS2 < VVS1 < IF\n",
    "- `color`: D (best) < E < F < G < H < I < J (worst)\n",
    "\n",
    "The key point is that **you** must define the order—not let alphabetical order decide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "983874c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(804.1108889588803), 0.904912475392502)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_order = [\"Fair\", \"Good\", \"Very Good\", \"Premium\", \"Ideal\"]\n",
    "clarity_order = [\"I1\",\"SI2\",\"SI1\",\"VS2\",\"VS1\",\"VVS2\",\"VVS1\",\"IF\"]\n",
    "color_order = [\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"]\n",
    "\n",
    "diam = diamonds.sample(n=min(20000, len(diamonds)), random_state=42).copy()\n",
    "\n",
    "X = diam.drop(columns=[\"price\"])\n",
    "y = diam[\"price\"]\n",
    "\n",
    "cat_cols = [\"cut\",\"color\",\"clarity\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "preprocess_ord = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"ord\", OrdinalEncoder(\n",
    "            categories=[cut_order, color_order, clarity_order],\n",
    "            handle_unknown=\"use_encoded_value\",\n",
    "            unknown_value=-1\n",
    "        ), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "reg_ord = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_ord),\n",
    "    (\"model\", Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "reg_ord.fit(X_train, y_train)\n",
    "pred = reg_ord.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "(mae, r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cef837",
   "metadata": {},
   "source": [
    "### Compare against one-hot on the same task\n",
    "\n",
    "One-hot makes no assumption of linear spacing between categories.\n",
    "Ordinal encoding assumes **equal spacing** between adjacent levels, which may be too strong.\n",
    "\n",
    "We compare using the same regression model (Ridge).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9a0f3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(728.335640540434), 0.9190160142230512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_ohe_d = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "reg_ohe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_ohe_d),\n",
    "    (\"model\", Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "reg_ohe.fit(X_train, y_train)\n",
    "pred_ohe = reg_ohe.predict(X_test)\n",
    "\n",
    "mae_ohe = mean_absolute_error(y_test, pred_ohe)\n",
    "r2_ohe = r2_score(y_test, pred_ohe)\n",
    "(mae_ohe, r2_ohe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fce972",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.5 Encoding and geometry: why distance-based models are especially sensitive\n",
    "\n",
    "For distance-based models (kNN, k-means, RBF-kernel SVM), the *geometry* of the encoded space directly determines learning behavior.\n",
    "\n",
    "### One-hot geometry\n",
    "If two categories are different, their one-hot vectors are orthogonal:\n",
    "$$\n",
    "e_i^\\top e_j = 0 \\quad (i\\neq j),\n",
    "$$\n",
    "and their Euclidean distance is constant:\n",
    "$$\n",
    "\\lVert e_i - e_j\\rVert_2 = \\sqrt{2}.\n",
    "$$\n",
    "So one-hot treats all mismatches as equally distant, which is appropriate for nominal categories.\n",
    "\n",
    "### Ordinal geometry\n",
    "If you encode categories as integers, distances depend on arbitrary code gaps:\n",
    "$$\n",
    "\\lvert \\phi(c_i)-\\phi(c_j)\\rvert.\n",
    "$$\n",
    "For nominal variables, this is usually meaningless and can distort kNN neighborhoods.\n",
    "\n",
    "We illustrate this effect using the `stars.csv` dataset and a kNN classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26579302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>L</th>\n",
       "      <th>R</th>\n",
       "      <th>A_M</th>\n",
       "      <th>Color</th>\n",
       "      <th>Spectral_Class</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3068</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>16.12</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>Red Dwarf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3042</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>16.60</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>Red Dwarf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>18.70</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>Red Dwarf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>16.65</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>Red Dwarf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1939</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>20.06</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>Red Dwarf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature         L       R    A_M Color Spectral_Class       Type\n",
       "0         3068  0.002400  0.1700  16.12   Red              M  Red Dwarf\n",
       "1         3042  0.000500  0.1542  16.60   Red              M  Red Dwarf\n",
       "2         2600  0.000300  0.1020  18.70   Red              M  Red Dwarf\n",
       "3         2800  0.000200  0.1600  16.65   Red              M  Red Dwarf\n",
       "4         1939  0.000138  0.1030  20.06   Red              M  Red Dwarf"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "path_stars = \"../../../Datasets/Classification/stars.csv\"\n",
    "stars = pd.read_csv(path_stars)\n",
    "stars.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc92e801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "Red Dwarf        40\n",
       "Brown Dwarf      40\n",
       "White Dwarf      40\n",
       "Main Sequence    40\n",
       "Super Giants     40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars[\"Type\"].value_counts().head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7bc89f",
   "metadata": {},
   "source": [
    "We build two pipelines:\n",
    "\n",
    "1. **One-hot** for `Color` and `Spectral_Class`, scaling numeric features.\n",
    "2. **Ordinal** (integer codes) for the same categorical features, scaling numeric features.\n",
    "\n",
    "Then we compare cross-validated accuracy. The dataset is small, so we use 5-fold stratified CV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f8b46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Type\"\n",
    "X = stars.drop(columns=[target]).copy()\n",
    "y = stars[target].copy()\n",
    "\n",
    "cat_cols = [\"Color\", \"Spectral_Class\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baab61dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.95), np.float64(0.038640077064565424))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot pipeline (dense output is fine for this dataset size)\n",
    "import inspect\n",
    "ohe_kwargs = {\"handle_unknown\": \"ignore\"}\n",
    "if \"sparse_output\" in inspect.signature(OneHotEncoder).parameters:\n",
    "    ohe_kwargs[\"sparse_output\"] = False\n",
    "else:\n",
    "    ohe_kwargs[\"sparse\"] = False\n",
    "pre_ohe = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(**ohe_kwargs), cat_cols),\n",
    "        (\"num\", Pipeline(steps=[(\"scaler\", StandardScaler())]), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "knn_ohe = Pipeline(steps=[\n",
    "    (\"pre\", pre_ohe),\n",
    "    (\"knn\", KNeighborsClassifier(n_neighbors=7))\n",
    "])\n",
    "\n",
    "scores_ohe = cross_val_score(knn_ohe, X, y, cv=cv, scoring=\"accuracy\")\n",
    "scores_ohe.mean(), scores_ohe.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edf796e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9333333333333332), np.float64(0.040397332145136085))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordinal pipeline (note: ordinal encoding on nominal categories is generally unsafe for kNN)\n",
    "pre_ord_nominal = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_cols),\n",
    "        (\"num\", Pipeline(steps=[(\"scaler\", StandardScaler())]), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "knn_ord = Pipeline(steps=[\n",
    "    (\"pre\", pre_ord_nominal),\n",
    "    (\"knn\", KNeighborsClassifier(n_neighbors=7))\n",
    "])\n",
    "\n",
    "scores_ord = cross_val_score(knn_ord, X, y, cv=cv, scoring=\"accuracy\")\n",
    "scores_ord.mean(), scores_ord.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a7536e",
   "metadata": {},
   "source": [
    "### What to take away\n",
    "\n",
    "If the ordinal-coded pipeline performs worse or is unstable across folds, that is a direct symptom of distorted geometry: “nearby” integer codes may be unrelated categories.\n",
    "\n",
    "For nominal categories with distance-based models, one-hot (or specialized similarity measures) is typically the correct baseline.\n",
    "\n",
    "For ordinal categories (true order), ordinal encoding can be valid—but you must confirm the order and consider whether equal spacing is reasonable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef201dcd",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "- If one-hot outperforms ordinal, the “equal spacing” assumption is harming the model.\n",
    "- If ordinal performs similarly (or better) with fewer features, it is an efficient representation.\n",
    "\n",
    "Next, we address high-cardinality issues with hashing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b20e4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Hashing (feature hashing): scaling to high-cardinality categories\n",
    "\n",
    "### Motivation\n",
    "If a nominal feature has $K$ categories, one-hot creates $K$ columns. When $K$ is large, memory and training time can become problematic.\n",
    "\n",
    "Hashing uses:\n",
    "$$\n",
    "h:\\mathcal{C}\\rightarrow \\{0,1,\\dots,m-1\\}\n",
    "$$\n",
    "to map categories into a fixed-dimensional space $\\mathbb{R}^m$.\n",
    "\n",
    "A sign-hashed variant sets:\n",
    "$$\n",
    "\\phi(c)_{h(c)} = s(c)\\in\\{-1,+1\\}.\n",
    "$$\n",
    "\n",
    "### Key tradeoff: collisions\n",
    "Different categories may share the same bucket:\n",
    "$$\n",
    "h(c_i)=h(c_j),\\; c_i\\neq c_j.\n",
    "$$\n",
    "Collisions introduce noise, but they are often tolerable with enough buckets and regularization.\n",
    "\n",
    "Hashing is useful when:\n",
    "- the vocabulary evolves over time,\n",
    "- you cannot store or ship a growing dictionary,\n",
    "- you need constant memory and fast transforms.\n",
    "\n",
    "We use `airports.csv` and predict whether an airport has scheduled service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9941560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>municipality</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>scheduled_service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heliport</td>\n",
       "      <td>Total RF Heliport</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Katmai Lodge Airport</td>\n",
       "      <td>King Salmon</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type                  name  municipality iso_region scheduled_service\n",
       "0       heliport     Total RF Heliport      Bensalem      US-PA                no\n",
       "1  small_airport  Aero B Ranch Airport         Leoti      US-KS                no\n",
       "2  small_airport          Lowell Field  Anchor Point      US-AK                no\n",
       "3  small_airport          Epps Airpark       Harvest      US-AL                no\n",
       "4  small_airport  Katmai Lodge Airport   King Salmon      US-AK                no"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_airports = \"../../../Datasets/Clustering/airports.csv\"\n",
    "airports = pd.read_csv(path_airports)\n",
    "airports[[\"type\",\"name\",\"municipality\",\"iso_region\",\"scheduled_service\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48fefa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62343, 5), np.float64(0.052515919991017436))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air = airports.dropna(subset=[\"scheduled_service\"]).copy()\n",
    "air[\"scheduled_service\"] = air[\"scheduled_service\"].astype(str).str.lower().str.strip()\n",
    "air = air[air[\"scheduled_service\"].isin([\"yes\",\"no\"])].copy()\n",
    "\n",
    "y = (air[\"scheduled_service\"] == \"yes\").astype(int)\n",
    "\n",
    "X = air[[\"type\",\"name\",\"municipality\",\"iso_region\",\"iso_country\"]].fillna(\"\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "X_train.shape, y_train.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b68fd4",
   "metadata": {},
   "source": [
    "### Build hashed features with `FeatureHasher`\n",
    "\n",
    "`FeatureHasher` expects an iterable of mappings per sample.\n",
    "We create a dictionary where keys are `field=value` tokens and values are 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "780586d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62343, 16384)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def row_to_token_dict(row):\n",
    "    d = {}\n",
    "    for col, val in row.items():\n",
    "        d[f\"{col}={val}\"] = 1\n",
    "    return d\n",
    "\n",
    "train_dicts = X_train.apply(row_to_token_dict, axis=1).tolist()\n",
    "test_dicts = X_test.apply(row_to_token_dict, axis=1).tolist()\n",
    "\n",
    "hasher = FeatureHasher(n_features=2**14, input_type=\"dict\")  # 16384 dims\n",
    "Xh_train = hasher.transform(train_dicts)\n",
    "Xh_test = hasher.transform(test_dicts)\n",
    "\n",
    "Xh_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4060aa0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9631892984313348, np.float64(0.9557876248518706))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_hash = SGDClassifier(loss=\"log_loss\", alpha=1e-5, max_iter=2000, random_state=42)\n",
    "clf_hash.fit(Xh_train, y_train)\n",
    "\n",
    "proba = clf_hash.predict_proba(Xh_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "auc = roc_auc_score(y_test, proba)\n",
    "(acc, auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fec22b",
   "metadata": {},
   "source": [
    "### Compare to one-hot on a smaller subset\n",
    "\n",
    "A full one-hot on `name` and `municipality` can be large.\n",
    "We restrict to a smaller set of categorical columns for a fair and feasible comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44678425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96352, np.float64(0.9566508463802617), 14315)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = air.sample(n=min(25000, len(air)), random_state=42).copy()\n",
    "y_s = (sample[\"scheduled_service\"] == \"yes\").astype(int)\n",
    "X_s = sample[[\"type\",\"municipality\",\"iso_region\",\"iso_country\"]].fillna(\"\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.25, random_state=42, stratify=y_s)\n",
    "\n",
    "cat_cols = X_s.columns.tolist()\n",
    "\n",
    "preprocess_ohe_air = ColumnTransformer(\n",
    "    transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "clf_ohe_air = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_ohe_air),\n",
    "    (\"model\", LogisticRegression(max_iter=2000, solver=\"saga\"))\n",
    "])\n",
    "\n",
    "clf_ohe_air.fit(X_train, y_train)\n",
    "proba = clf_ohe_air.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "acc_ohe = accuracy_score(y_test, pred)\n",
    "auc_ohe = roc_auc_score(y_test, proba)\n",
    "\n",
    "ohe = clf_ohe_air.named_steps[\"preprocess\"].named_transformers_[\"cat\"]\n",
    "dim_ohe = len(ohe.get_feature_names_out(cat_cols))\n",
    "\n",
    "(acc_ohe, auc_ohe, dim_ohe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f561aa25",
   "metadata": {},
   "source": [
    "Hashing fixes the feature dimension to $m$ and avoids a growing dictionary, at the cost of collisions.\n",
    "One-hot is collision-free but grows with vocabulary size.\n",
    "\n",
    "Now we address target encoding, which can be extremely powerful but must be used with leakage discipline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900fc71",
   "metadata": {},
   "source": [
    "### How many hashing buckets do you need?\n",
    "\n",
    "Under a simplifying assumption that the hash function distributes categories uniformly, the expected number of **occupied buckets** when hashing $K$ distinct tokens into $m$ buckets is:\n",
    "$$\n",
    "\\mathbb{E}[\\text{occupied}] = m\\left(1-\\left(1-\\frac{1}{m}\\right)^K\\right).\n",
    "$$\n",
    "\n",
    "The expected number of **collisions** (distinct tokens sharing buckets) is then approximately:\n",
    "$$\n",
    "\\mathbb{E}[\\text{collisions}] \\approx K - \\mathbb{E}[\\text{occupied}].\n",
    "$$\n",
    "\n",
    "This approximation helps you choose $m$:\n",
    "- If $m \\gg K$, collisions are rare.\n",
    "- If $m$ is comparable to $K$, collisions become common.\n",
    "- In practice, you can tune $m$ by measuring validation performance and resource usage.\n",
    "\n",
    "We estimate $K$ for the tokenization we used (field=value tokens).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdf3b651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118999"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate token vocabulary size K for the airports hashing representation\n",
    "\n",
    "X_hash_full = air[[\"type\",\"name\",\"municipality\",\"iso_region\",\"iso_country\"]].fillna(\"\")\n",
    "tokens = set()\n",
    "for _, row in X_hash_full.iterrows():\n",
    "    for col, val in row.items():\n",
    "        tokens.add(f\"{col}={val}\")\n",
    "\n",
    "K = len(tokens)\n",
    "K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3576df55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m=  1024  expected_collisions≈117975.0\n",
      "m=  4096  expected_collisions≈114903.0\n",
      "m= 16384  expected_collisions≈102626.5\n",
      "m= 65536  expected_collisions≈64126.3\n"
     ]
    }
   ],
   "source": [
    "def expected_collisions(K, m):\n",
    "    occupied = m * (1.0 - (1.0 - 1.0/m)**K)\n",
    "    return K - occupied\n",
    "\n",
    "for m in [2**10, 2**12, 2**14, 2**16]:\n",
    "    print(f\"m={m:6d}  expected_collisions≈{expected_collisions(K, m):.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2cd861",
   "metadata": {},
   "source": [
    "### Empirical tuning: AUC vs number of hashing features\n",
    "\n",
    "We now train the same classifier while varying `n_features`. This gives a concrete way to select $m$ for a particular dataset and label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9355e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1024, np.float64(0.9389039033592107)),\n",
       " (4096, np.float64(0.9450672000253004)),\n",
       " (16384, np.float64(0.9557876248518706)),\n",
       " (65536, np.float64(0.9583328682490695))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Re-create a stable train/test split for this experiment\n",
    "Xh_X = X_hash_full\n",
    "y_h = (air[\"scheduled_service\"] == \"yes\").astype(int)\n",
    "\n",
    "Xh_train_df, Xh_test_df, y_h_train, y_h_test = train_test_split(\n",
    "    Xh_X, y_h, test_size=0.25, random_state=42, stratify=y_h\n",
    ")\n",
    "\n",
    "def build_dicts(df):\n",
    "    return df.apply(row_to_token_dict, axis=1).tolist()\n",
    "\n",
    "train_dicts = build_dicts(Xh_train_df)\n",
    "test_dicts = build_dicts(Xh_test_df)\n",
    "\n",
    "results = []\n",
    "for m in [2**10, 2**12, 2**14, 2**16]:\n",
    "    hasher_m = FeatureHasher(n_features=m, input_type=\"dict\")\n",
    "    Xtr = hasher_m.transform(train_dicts)\n",
    "    Xte = hasher_m.transform(test_dicts)\n",
    "\n",
    "    clf = SGDClassifier(loss=\"log_loss\", alpha=1e-5, max_iter=2000, random_state=42)\n",
    "    clf.fit(Xtr, y_h_train)\n",
    "\n",
    "    proba = clf.predict_proba(Xte)[:, 1]\n",
    "    auc = roc_auc_score(y_h_test, proba)\n",
    "    results.append((m, auc))\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00ed1f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ms = [m for m, auc in results]\n",
    "aucs = [auc for m, auc in results]\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(ms, aucs, marker=\"o\")\n",
    "plt.xscale(\"log\", base=2)\n",
    "plt.xlabel(\"n_features (m)\")\n",
    "plt.ylabel(\"AUC on holdout\")\n",
    "plt.title(\"Hashing: AUC vs number of hashing features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab05d7e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Target encoding: compressing categories using the label (and the leakage trap)\n",
    "\n",
    "### Core idea\n",
    "Replace each category by a statistic of the target conditional on that category.\n",
    "\n",
    "For regression:\n",
    "$$\n",
    "\\text{TE}(c) \\approx \\mathbb{E}[y\\mid x=c].\n",
    "$$\n",
    "\n",
    "A smoothed estimator is:\n",
    "$$\n",
    "\\text{TE}_\\alpha(c) = \\frac{\\sum_{i:x_i=c} y_i + \\alpha \\mu}{n_c + \\alpha},\n",
    "$$\n",
    "where $\\mu$ is the global mean and $\\alpha>0$ controls shrinkage.\n",
    "\n",
    "### Leakage risk\n",
    "If you compute $\\text{TE}(c)$ using the same rows you are encoding (especially inside cross-validation), you can leak target information and overestimate performance.\n",
    "\n",
    "Leakage-safe training requires **out-of-fold target encoding**:\n",
    "- For each fold, compute TE on the remaining folds and apply to the held-out fold.\n",
    "\n",
    "We demonstrate with `diamonds.csv` predicting price from `cut`, `color`, `clarity`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e846cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "diam_te = diam.copy()\n",
    "\n",
    "X = diam_te.drop(columns=[\"price\"])\n",
    "y = diam_te[\"price\"].values\n",
    "\n",
    "cat_cols = [\"cut\", \"color\", \"clarity\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "X_cat = X[cat_cols].copy()\n",
    "X_num = X[num_cols].copy()\n",
    "\n",
    "X_train_cat, X_test_cat, X_train_num, X_test_num, y_train, y_test = train_test_split(\n",
    "    X_cat, X_num, y, test_size=0.25, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9783b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(810.4586264501206), 0.8937561031532656, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def target_encode_fit(df_cat, y, alpha=20.0):\n",
    "    # Compute smoothed target means per category for each column.\n",
    "    mu = float(np.mean(y))\n",
    "    maps = {}\n",
    "    for col in df_cat.columns:\n",
    "        stats = pd.DataFrame({col: df_cat[col].values, \"y\": y})\n",
    "        agg = stats.groupby(col)[\"y\"].agg([\"count\", \"mean\"])\n",
    "        enc = (agg[\"mean\"] * agg[\"count\"] + mu * alpha) / (agg[\"count\"] + alpha)\n",
    "        maps[col] = enc.to_dict()\n",
    "    return maps, mu\n",
    "\n",
    "def target_encode_apply(df_cat, maps, mu):\n",
    "    out = pd.DataFrame(index=df_cat.index)\n",
    "    for col in df_cat.columns:\n",
    "        out[col + \"_te\"] = df_cat[col].map(maps[col]).fillna(mu).astype(float)\n",
    "    return out\n",
    "\n",
    "maps, mu = target_encode_fit(X_train_cat, y_train, alpha=50.0)\n",
    "Xtr_te = target_encode_apply(X_train_cat, maps, mu)\n",
    "Xte_te = target_encode_apply(X_test_cat, maps, mu)\n",
    "\n",
    "Xtr = pd.concat([Xtr_te.reset_index(drop=True), X_train_num.reset_index(drop=True)], axis=1)\n",
    "Xte = pd.concat([Xte_te.reset_index(drop=True), X_test_num.reset_index(drop=True)], axis=1)\n",
    "\n",
    "reg = Ridge(alpha=1.0)\n",
    "reg.fit(Xtr, y_train)\n",
    "pred = reg.predict(Xte)\n",
    "\n",
    "(mean_absolute_error(y_test, pred), r2_score(y_test, pred), Xtr.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a03746",
   "metadata": {},
   "source": [
    "The above is valid for a train/test split (statistics were computed only on the training partition).\n",
    "However, it is not sufficient for cross-validation unless you compute encodings out-of-fold.\n",
    "\n",
    "Next: out-of-fold target encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07255665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut_te</th>\n",
       "      <th>color_te</th>\n",
       "      <th>clarity_te</th>\n",
       "      <th>id</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3939.408333</td>\n",
       "      <td>3159.618961</td>\n",
       "      <td>5024.964616</td>\n",
       "      <td>50585</td>\n",
       "      <td>0.70</td>\n",
       "      <td>59.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.79</td>\n",
       "      <td>5.81</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3476.704758</td>\n",
       "      <td>5067.516281</td>\n",
       "      <td>3956.250275</td>\n",
       "      <td>17781</td>\n",
       "      <td>1.32</td>\n",
       "      <td>62.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.99</td>\n",
       "      <td>7.04</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4583.762947</td>\n",
       "      <td>3905.978866</td>\n",
       "      <td>3250.632737</td>\n",
       "      <td>40989</td>\n",
       "      <td>0.45</td>\n",
       "      <td>61.4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.89</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3862.915819</td>\n",
       "      <td>5069.440490</td>\n",
       "      <td>3998.310188</td>\n",
       "      <td>20871</td>\n",
       "      <td>1.63</td>\n",
       "      <td>62.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.60</td>\n",
       "      <td>7.67</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4567.051100</td>\n",
       "      <td>5067.516281</td>\n",
       "      <td>3341.862819</td>\n",
       "      <td>41299</td>\n",
       "      <td>0.51</td>\n",
       "      <td>59.4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.26</td>\n",
       "      <td>5.21</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cut_te     color_te   clarity_te     id  carat  depth  table     x     y     z\n",
       "0  3939.408333  3159.618961  5024.964616  50585   0.70   59.5   56.0  5.79  5.81  3.45\n",
       "1  3476.704758  5067.516281  3956.250275  17781   1.32   62.0   57.0  6.99  7.04  4.35\n",
       "2  4583.762947  3905.978866  3250.632737  40989   0.45   61.4   61.0  4.95  4.89  3.02\n",
       "3  3862.915819  5069.440490  3998.310188  20871   1.63   62.0   54.0  7.60  7.67  4.73\n",
       "4  4567.051100  5067.516281  3341.862819  41299   0.51   59.4   60.0  5.26  5.21  3.11"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def oof_target_encode(df_cat, y, n_splits=5, alpha=50.0, random_state=42):\n",
    "    df_cat = df_cat.reset_index(drop=True)\n",
    "    y = np.asarray(y)\n",
    "    mu = float(np.mean(y))\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    oof = pd.DataFrame(index=np.arange(len(df_cat)))\n",
    "    for col in df_cat.columns:\n",
    "        oof[col + \"_te\"] = np.nan\n",
    "\n",
    "    for train_idx, val_idx in kf.split(df_cat):\n",
    "        df_tr, df_val = df_cat.iloc[train_idx], df_cat.iloc[val_idx]\n",
    "        y_tr = y[train_idx]\n",
    "\n",
    "        maps_fold, mu_fold = target_encode_fit(df_tr, y_tr, alpha=alpha)\n",
    "        enc_val = target_encode_apply(df_val, maps_fold, mu_fold)\n",
    "\n",
    "        oof.loc[val_idx, [c + \"_te\" for c in df_cat.columns]] = enc_val.values\n",
    "\n",
    "    oof = oof.astype(float)\n",
    "\n",
    "    maps_full, mu_full = target_encode_fit(df_cat, y, alpha=alpha)\n",
    "    return oof, maps_full, mu_full\n",
    "\n",
    "df_cat = X_train_cat.copy().reset_index(drop=True)\n",
    "df_num = X_train_num.copy().reset_index(drop=True)\n",
    "y_tr = y_train\n",
    "\n",
    "oof_te, maps_full, mu_full = oof_target_encode(df_cat, y_tr, n_splits=5, alpha=50.0)\n",
    "\n",
    "X_enc = pd.concat([oof_te, df_num], axis=1)\n",
    "X_enc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d4123cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(806.9206605068382), 0.8881253853563349)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick evaluation split on the out-of-fold encoded training matrix\n",
    "X_tr2, X_val2, y_tr2, y_val2 = train_test_split(X_enc, y_tr, test_size=0.25, random_state=42)\n",
    "\n",
    "reg = Ridge(alpha=1.0)\n",
    "reg.fit(X_tr2, y_tr2)\n",
    "pred = reg.predict(X_val2)\n",
    "\n",
    "(mean_absolute_error(y_val2, pred), r2_score(y_val2, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41606b",
   "metadata": {},
   "source": [
    "### Practical target encoding checklist\n",
    "\n",
    "1. Compute TE using training data only.\n",
    "2. In CV, compute encodings out-of-fold.\n",
    "3. Use smoothing (shrinkage) to stabilize rare categories.\n",
    "4. For time series or grouped data, folds must respect temporal or group boundaries.\n",
    "\n",
    "Target encoding often shines when cardinality is high and one-hot is too large.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16807cd5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Mixed encoders in a single workflow\n",
    "\n",
    "Real projects often combine encoders:\n",
    "- one-hot for small nominal fields,\n",
    "- hashing for large or evolving vocabularies,\n",
    "- ordinal for truly ordered categories,\n",
    "- target encoding for high-cardinality categories when strict leakage controls are feasible.\n",
    "\n",
    "We demonstrate a mixed design on `Fast_Food_Restaurants_US.csv`:\n",
    "- one-hot for `province`,\n",
    "- hashing for `city`, `categories`, and `name`,\n",
    "- a linear classifier on a toy label to demonstrate end-to-end mechanics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc948172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>categories</th>\n",
       "      <th>name</th>\n",
       "      <th>label_chain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LA</td>\n",
       "      <td>Thibodaux</td>\n",
       "      <td>American Restaurant and Fast Food Restaurant</td>\n",
       "      <td>SONIC Drive In</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LA</td>\n",
       "      <td>Thibodaux</td>\n",
       "      <td>Fast Food Restaurants</td>\n",
       "      <td>SONIC Drive In</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TN</td>\n",
       "      <td>Pigeon Forge</td>\n",
       "      <td>Fast Food Restaurant</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TN</td>\n",
       "      <td>Pigeon Forge</td>\n",
       "      <td>Fast Food</td>\n",
       "      <td>Arby's</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA</td>\n",
       "      <td>Morrow</td>\n",
       "      <td>Fast Food Restaurant</td>\n",
       "      <td>Steak 'n Shake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  province          city                                    categories            name  label_chain\n",
       "0       LA     Thibodaux  American Restaurant and Fast Food Restaurant  SONIC Drive In            1\n",
       "1       LA     Thibodaux                         Fast Food Restaurants  SONIC Drive In            1\n",
       "2       TN  Pigeon Forge                          Fast Food Restaurant       Taco Bell            1\n",
       "3       TN  Pigeon Forge                                     Fast Food          Arby's            1\n",
       "4       GA        Morrow                          Fast Food Restaurant  Steak 'n Shake            0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_ff = \"../../../Datasets/Classification/Fast_Food_Restaurants_US.csv\"\n",
    "ff = pd.read_csv(path_ff)\n",
    "\n",
    "ff2 = ff.copy()\n",
    "ff2[\"label_chain\"] = ff2[\"name\"].astype(str).str.contains(r\"(?i)wendy|taco|sonic|arb(?:y|ies)|burger|mcdonald|kfc\", regex=True).astype(int)\n",
    "\n",
    "ff2 = ff2[[\"province\",\"city\",\"categories\",\"name\",\"label_chain\"]].fillna(\"\")\n",
    "ff2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a71f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_row_to_dict(row):\n",
    "    d = {}\n",
    "    d[f\"city={row['city']}\"] = 1\n",
    "    d[f\"name={row['name']}\"] = 1\n",
    "    cats = str(row[\"categories\"]).replace(\" and \", \",\").split(\",\")\n",
    "    for c in cats:\n",
    "        c = c.strip()\n",
    "        if c:\n",
    "            d[f\"cat={c}\"] = 1\n",
    "    return d\n",
    "\n",
    "X = ff2[[\"province\",\"city\",\"categories\",\"name\"]].copy()\n",
    "y = ff2[\"label_chain\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd79c3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 8242)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_ohe_prov = ColumnTransformer(\n",
    "    transformers=[(\"prov\", OneHotEncoder(handle_unknown=\"ignore\"), [\"province\"])],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "hasher = FeatureHasher(n_features=2**13, input_type=\"dict\")\n",
    "\n",
    "train_dicts = X_train.apply(ff_row_to_dict, axis=1).tolist()\n",
    "test_dicts = X_test.apply(ff_row_to_dict, axis=1).tolist()\n",
    "\n",
    "Xh_train = hasher.transform(train_dicts)\n",
    "Xh_test = hasher.transform(test_dicts)\n",
    "\n",
    "Xp_train = pre_ohe_prov.fit_transform(X_train)\n",
    "Xp_test = pre_ohe_prov.transform(X_test)\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "X_train_all = hstack([Xp_train, Xh_train]).tocsr()\n",
    "X_test_all = hstack([Xp_test, Xh_test]).tocsr()\n",
    "\n",
    "X_train_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0af71d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9932, np.float64(0.9992005818262308))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss=\"log_loss\", alpha=1e-5, max_iter=2000, random_state=42)\n",
    "clf.fit(X_train_all, y_train)\n",
    "\n",
    "proba = clf.predict_proba(X_test_all)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "accuracy_score(y_test, pred), roc_auc_score(y_test, proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0760320c",
   "metadata": {},
   "source": [
    "This pattern is common in industry:\n",
    "- collision-free encodings where feasible,\n",
    "- hashing for high-cardinality or evolving categorical fields,\n",
    "- compact representations when memory and latency matter.\n",
    "\n",
    "Next, we provide a decision framework and a set of recommended exercises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef84d8d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7.5 Common pitfalls and debugging checks\n",
    "\n",
    "Even when you choose an appropriate encoder, issues often arise in practice. The following checks prevent many downstream surprises.\n",
    "\n",
    "### Pitfall A: exploding cardinality\n",
    "Before committing to one-hot, measure the number of unique categories:\n",
    "$$\n",
    "K_j = |\\{x^{(i)}_j\\}_{i=1}^n|.\n",
    "$$\n",
    "If $K_j$ is large (e.g., thousands) and the column is not obviously ordinal, consider hashing or target encoding.\n",
    "\n",
    "### Pitfall B: rare categories\n",
    "Very rare categories can behave like noise, especially for linear models.\n",
    "A standard remedy is to replace categories with frequency below a threshold by `\"Other\"` *before* encoding.\n",
    "\n",
    "### Pitfall C: unseen categories at inference time\n",
    "If your production data contains new categories, your pipeline must define behavior:\n",
    "- one-hot: ignore unseen categories,\n",
    "- ordinal: map unseen to a reserved code (e.g., -1),\n",
    "- hashing: naturally handles them,\n",
    "- target: map unseen to the global mean (or prior).\n",
    "\n",
    "We implement a minimal rare-category grouping utility on the fast-food dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1ee11fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique cities: 2764\n",
      "Top 10 cities:\n",
      "city\n",
      "Houston        107\n",
      "Las Vegas       82\n",
      "Phoenix         78\n",
      "Columbus        72\n",
      "Dallas          66\n",
      "Orlando         65\n",
      "Los Angeles     64\n",
      "Miami           62\n",
      "Chicago         57\n",
      "San Antonio     54\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique cities after grouping: 35\n",
      "Top 10 grouped cities:\n",
      "city_grouped\n",
      "Other          8363\n",
      "Houston         107\n",
      "Las Vegas        82\n",
      "Phoenix          78\n",
      "Columbus         72\n",
      "Dallas           66\n",
      "Orlando          65\n",
      "Los Angeles      64\n",
      "Miami            62\n",
      "Chicago          57\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def group_rare_categories(s, min_count=50, other_label=\"Other\"):\n",
    "    counts = s.value_counts(dropna=False)\n",
    "    rare = counts[counts < min_count].index\n",
    "    return s.where(~s.isin(rare), other_label)\n",
    "\n",
    "# Example: city cardinality and rare grouping\n",
    "city_counts = ff2[\"city\"].value_counts()\n",
    "print(\"Unique cities:\", ff2[\"city\"].nunique())\n",
    "print(\"Top 10 cities:\")\n",
    "print(city_counts.head(10))\n",
    "\n",
    "ff2_grouped = ff2.copy()\n",
    "ff2_grouped[\"city_grouped\"] = group_rare_categories(ff2_grouped[\"city\"], min_count=30)\n",
    "\n",
    "print(\"\\nUnique cities after grouping:\", ff2_grouped[\"city_grouped\"].nunique())\n",
    "print(\"Top 10 grouped cities:\")\n",
    "print(ff2_grouped[\"city_grouped\"].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b86c15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Decision framework: choosing an encoder\n",
    "\n",
    "### 8.1. Match semantics first\n",
    "- If the category is **ordered**, use ordinal encoding with an explicit order.\n",
    "- If it is **nominal**, do not impose an order.\n",
    "\n",
    "### 8.2. Control dimensionality\n",
    "Let $K$ be cardinality of a nominal feature.\n",
    "\n",
    "- One-hot: dimension grows as $K$ (exact and interpretable).\n",
    "- Hashing: dimension fixed at $m$ (approximate, collisions).\n",
    "- Target encoding: dimension fixed at 1 per feature (strong, but leakage-prone).\n",
    "\n",
    "### 8.3. Consider the model family\n",
    "\n",
    "| Model family | Common encodings | Why |\n",
    "|---|---|---|\n",
    "| Linear / GLM | one-hot, hashing, target | linear models like sparse high-dimensional features; TE can compress large vocabularies |\n",
    "| Distance-based | one-hot (careful), ordinal (only if true order) | distances in encoded space matter |\n",
    "| Trees / GBDT | ordinal, one-hot, or native categorical splits | trees can split on integer codes, but native categorical handling is often best when available |\n",
    "\n",
    "### 8.4. Handle unseen categories\n",
    "- One-hot: `handle_unknown=\"ignore\"`.\n",
    "- Ordinal: use `unknown_value` with `handle_unknown=\"use_encoded_value\"`.\n",
    "- Hashing: naturally handles new categories.\n",
    "- Target: map unseen categories to the global mean $\\mu$.\n",
    "\n",
    "### 8.5. Leakage discipline for target encoding\n",
    "If your encoding uses the label, compute it so that each row’s encoded value is computed without using that row’s target (out-of-fold).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121f33a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Exercises (recommended)\n",
    "\n",
    "1. **One-hot with regularization**: On `drug200.csv`, tune `C` for logistic regression and measure how accuracy changes.\n",
    "2. **Ordinal vs one-hot**: On `diamonds.csv`, compare ordinal vs one-hot for `cut/color/clarity` using Ridge and SGDRegressor.\n",
    "3. **Hashing dimension**: On `airports.csv`, vary `n_features` (e.g., $2^{10}$, $2^{12}$, $2^{14}$, $2^{16}$) and plot AUC.\n",
    "4. **Leakage demo**: Implement leaky target encoding inside CV and show how performance is overestimated.\n",
    "5. **Rare category grouping**: Replace categories with frequency < 10 by `\"Other\"` and compare one-hot dimensionality and performance.\n",
    "\n",
    "Completing these exercises will give you operational mastery of categorical encodings used in classical ML pipelines.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
