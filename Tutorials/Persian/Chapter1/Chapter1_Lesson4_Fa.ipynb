{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ff48cc",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap');\n",
       "@import url('https://cdnjs.cloudflare.com/ajax/libs/shabnam-font/5.0.1/font-face.css');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Amiri:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Mirza:wght@400;700&display=swap');\n",
       "\n",
       "\n",
       "\n",
       "/* Text areas (Classic Notebook + JupyterLab) */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "div.rendered_html, .output_subarea {\n",
       "  font-family: \"Vazirmatn\", \"Shabnam\", \"Mirza\", \"Amiri\", Tahoma, \"Segoe UI\", sans-serif !important;\n",
       "}\n",
       "\n",
       "/* RTL for rendered markdown/html content */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "h1, h2, h3, h4, h5, h6, p, strong, label, ol, ul, li {\n",
       "  direction: rtl !important;\n",
       "  text-align: right !important;\n",
       "  line-height: 1.9;\n",
       "  font-family: \"Vazirmatn\", \"Shabnam\", \"Mirza\", \"Amiri\", Tahoma, \"Segoe UI\", sans-serif !important;\n",
       "}\n",
       "\n",
       "h1 { font-size: 2rem; color: #070F2B; font-weight: 900}\n",
       "h2 { font-size: 1.8rem; color: #070F2B; font-weight: 800}\n",
       "h3 { font-size: 1.6rem; color: #070F2B; font-weight: 700}\n",
       "h4 { font-size: 1.4rem; color: #1E3E62; font-weight: 600}\n",
       "h5 { font-size: 1.2rem; color: #1E3E62}\n",
       "h6 { font-size: 1rem; color: #1E3E62}\n",
       "p { font-size: 1.1rem; ; font-weight: 400}\n",
       "ol, ul, li, th, td  { font-size: 1rem; }\n",
       "\n",
       "/* Keep code + outputs LTR and monospace */\n",
       ".CodeMirror, .CodeMirror *,\n",
       "pre, code,\n",
       ".jp-CodeCell .jp-InputArea, .jp-CodeCell .jp-InputArea *,\n",
       ".jp-OutputArea, .jp-OutputArea * {\n",
       "  direction: ltr !important;\n",
       "  text-align: left !important;\n",
       "  font-size: 1rem !important;\n",
       "  font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "css = Path(\"../../../css/rtl.css\").read_text(encoding=\"utf-8\")\n",
    "display(HTML(f\"<style>{css}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8aa48f",
   "metadata": {},
   "source": [
    "# فصل ۱ — مقدمه‌ای بر یادگیری ماشین \n",
    "# درس ۴: گردش‌کار یادگیری ماشین (داده، مدل، ارزیابی، استقرار)\n",
    "\n",
    "این نوت‌بوک یک مسیر عملی و انتها به انتها برای گردش‌کار یادگیری ماشین کلاسیک است. تمرکز روی یک الگوریتم خاص نیست؛ بلکه روی انضباط مهندسی‌ای است که داده را به مدل **قابل اعتماد** و سپس به مصنوعات **قابل استفاده** تبدیل می‌کند.\n",
    "\n",
    "الگوهای مشابه گردش‌کار را در سه نوع مسئله می‌بینید:\n",
    "\n",
    "- **طبقه‌بندی**: پیش‌بینی برچسب دودویی (دیابتی/غیردیابتی).\n",
    "- **رگرسیون**: پیش‌بینی مقدار عددی (قیمت الماس).\n",
    "- **خوشه‌بندی**: کشف ساختار بدون برچسب (مختصات فرودگاه‌ها).\n",
    "\n",
    "کد از مسیرهای مطابق ساختار ریپوی شما استفاده می‌کند، مانند:\n",
    "\n",
    "- `../../../Datasets/Classification/diabetes.csv`\n",
    "- `../../../Datasets/Regression/diamonds.csv`\n",
    "- `../../../Datasets/Clustering/airports.csv`\n",
    "\n",
    "اگر فایل داده در محیط اجرا موجود نباشد، نوت‌بوک داده‌ای با طرح‌واره سازگار تولید می‌کند تا همه بخش‌ها قابل اجرا بمانند.\n",
    "\n",
    "---\n",
    "\n",
    "## نمای کلی گردش‌کار\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "A[داده] --> B[صورت‌بندی مسئله]\n",
    "B --> C[راهبرد تقسیم]\n",
    "C --> D[پیش‌پردازش و مهندسی ویژگی]\n",
    "D --> E[آموزش مدل]\n",
    "E --> F[ارزیابی و تحلیل خطا]\n",
    "F --> G{کافی است؟}\n",
    "G -- خیر --> D\n",
    "G -- بله --> H[بسته‌بندی و استقرار]\n",
    "H --> I[پایش و بازخورد]\n",
    "I --> D\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## نگاه ریاضی فشرده\n",
    "\n",
    "آموزش معمولاً به صورت کمینه‌سازی ریسک تجربی نوشته می‌شود:\n",
    "\n",
    "$$\n",
    "\\hat{f} = \\arg\\min_{f \\in \\mathcal{F}} \\frac{1}{n}\\sum_{i=1}^{n} \\ell\\big(y_i, f(x_i)\\big) + \\lambda \\Omega(f)\n",
    "$$\n",
    "\n",
    "در کار واقعی، اعتمادپذیری نتیجه بیش از هر چیز به *گردش‌کار پیرامون* این هدف بستگی دارد.\n",
    "\n",
    "---\n",
    "\n",
    "## ۰) صورت‌بندی مسئله (چه چیزهایی را قبل از مدل‌سازی باید تصمیم بگیرید)\n",
    "\n",
    "### ۰.۱ واحد پیش‌بینی\n",
    "\n",
    "تعریف کنید هر ردیف نماینده چیست؛ مثلاً:\n",
    "\n",
    "- یک snapshot از بیمار\n",
    "- یک درخواست وام\n",
    "- یک تراکنش\n",
    "- یک آگهی\n",
    "\n",
    "این انتخاب روی نشت، تقسیم و تفسیرپذیری اثر می‌گذارد.\n",
    "\n",
    "### ۰.۲ تعریف هدف و زمان‌بندی\n",
    "\n",
    "تعریف هدف باید بدون ابهام باشد:\n",
    "\n",
    "- چه رخدادی را پیش‌بینی می‌کنید؟\n",
    "- این رخداد نسبت به ویژگی‌های در دسترس چه زمانی اتفاق می‌افتد؟\n",
    "- برچسب‌ها چگونه تولید می‌شوند؟ (دستی/خودکار/با تاخیر/نویزی)\n",
    "- موارد مرزی یا برچسب‌های مبهم چگونه مدیریت می‌شوند؟\n",
    "\n",
    "اگر هدف «آیا کاربر در ۳۰ روز آینده ریزش می‌کند» باشد، ویژگی‌ها باید فقط اطلاعات موجود **در زمان پیش‌بینی** را داشته باشند، نه بعد از ریزش.\n",
    "\n",
    "### ۰.۳ محدودیت‌ها و معیار موفقیت\n",
    "\n",
    "محدودیت‌ها را صریح بنویسید:\n",
    "\n",
    "- تاخیر (مثلاً کمتر از ۵۰ میلی‌ثانیه)\n",
    "- اندازه مدل\n",
    "- تفسیرپذیری/حسابرسی\n",
    "- حریم خصوصی و نگهداشت داده\n",
    "- انصاف\n",
    "- هزینه FP/FN\n",
    "\n",
    "موفقیت را تعریف کنید:\n",
    "\n",
    "- معیار اصلی (ROC-AUC یا RMSE و …)\n",
    "- نقطه عملیاتی (precision/recall در یک آستانه)\n",
    "- پایداری (واریانس بین foldها و برش‌ها)\n",
    "\n",
    "### ۰.۴ راهبرد تقسیم\n",
    "\n",
    "تقسیم یک انتخاب مدل‌سازی است:\n",
    "\n",
    "- تقسیم تصادفی برای داده i.i.d.\n",
    "- تقسیم لایه‌ای برای حفظ نسبت کلاس‌ها\n",
    "- تقسیم گروهی برای جلوگیری از نشت موجودیت‌ها\n",
    "- تقسیم زمانی برای شبیه‌سازی شرایط استقرار\n",
    "\n",
    "---\n",
    "\n",
    "## ۱) مرحله داده: ورود، اعتبارسنجی، درک\n",
    "\n",
    "### ۱.۱ ورود داده\n",
    "\n",
    "عادت‌های خوب:\n",
    "\n",
    "- خواندن از مسیرهای مشخص\n",
    "- ثبت نسخه/اسنپ‌شات\n",
    "- بررسی shape و نام ستون‌ها\n",
    "- خلاصه‌سازی سریع (min/max، گمشدگی)\n",
    "\n",
    "### ۱.۲ اعتبارسنجی (قرارداد داده حداقلی)\n",
    "\n",
    "حداقل:\n",
    "\n",
    "- ستون‌های ضروری وجود دارند\n",
    "- بازه‌های عددی معقول هستند\n",
    "- مقادیر دسته‌ای شناخته‌شده‌اند یا ایمن مدیریت می‌شوند\n",
    "- گمشدگی در حد انتظار است\n",
    "\n",
    "### ۱.۳ درک داده\n",
    "\n",
    "همیشه دنبال این‌ها باشید:\n",
    "\n",
    "- عدم‌تعادل کلاس‌ها\n",
    "- نویز هدف\n",
    "- ردیف‌های تکراری\n",
    "- ویژگی‌های «بیش از حد اطلاع‌رسان» (کاندید نشت)\n",
    "\n",
    "---\n",
    "\n",
    "## ۲) مرحله مدل‌سازی: پایپ‌لاین‌ها و خط‌پایه\n",
    "\n",
    "### ۲.۱ پایپ‌لاین‌ها مانع نشت می‌شوند\n",
    "\n",
    "همه پیش‌پردازش‌ها باید داخل پایپ‌لاین باشند؛ وگرنه خطر آلوده‌سازی اعتبارسنجی/test با آمارهای کل داده وجود دارد.\n",
    "\n",
    "### ۲.۲ اول خط‌پایه\n",
    "\n",
    "خط‌پایه پاسخ می‌دهد:\n",
    "\n",
    "- آیا سیگنال واقعی وجود دارد؟\n",
    "- مسئله چقدر سخت است؟\n",
    "- سطح عملکرد قابل انتظار چیست؟\n",
    "\n",
    "ما Logistic Regression را به عنوان خط‌پایه قوی برای طبقه‌بندی جدولی استفاده می‌کنیم و سپس با یک Random Forest کوچک مقایسه می‌کنیم.\n",
    "\n",
    "---\n",
    "\n",
    "## ۳) مرحله ارزیابی: معیارها، آستانه‌ها، برش‌ها\n",
    "\n",
    "### ۳.۱ معیارهای کلی\n",
    "\n",
    "طبقه‌بندی دودویی:\n",
    "\n",
    "- Accuracy، Precision، Recall، F1\n",
    "- ROC-AUC (کیفیت رتبه‌بندی بدون وابستگی به آستانه)\n",
    "\n",
    "رگرسیون:\n",
    "\n",
    "- MAE، RMSE، $R^2$\n",
    "\n",
    "### ۳.۲ تنظیم آستانه تحت هزینه\n",
    "\n",
    "استقرار نیاز به آستانه دارد. اگر FN پنج برابر FP هزینه دارد، آستانه‌ای را انتخاب کنید که هزینه را کمینه کند:\n",
    "\n",
    "$$\n",
    "\\text{Cost}(t) = c_{FP}\\cdot FP(t) + c_{FN}\\cdot FN(t)\n",
    "$$\n",
    "\n",
    "### ۳.۳ تحلیل برش\n",
    "\n",
    "معیارها را به تفکیک زیرگروه‌ها حساب کنید (مثلاً بازه‌های سن). ممکن است مدل در کل خوب باشد اما در زیرگروه حساس شکست بخورد.\n",
    "\n",
    "---\n",
    "\n",
    "## ۴) مرحله استقرار (حداقلی اما واقعی)\n",
    "\n",
    "باید بتوانید:\n",
    "\n",
    "- کل پایپ‌لاین را ذخیره کنید\n",
    "- دوباره بارگذاری کنید\n",
    "- روی ردیف‌های جدید پیش‌بینی انجام دهید\n",
    "- طرح‌واره ورودی لازم را مستند کنید\n",
    "\n",
    "---\n",
    "\n",
    "## ۵) مرحله پایش (حداقل ضروری)\n",
    "\n",
    "پایش معمولاً شامل:\n",
    "\n",
    "- دریفت ویژگی‌ها\n",
    "- افت عملکرد\n",
    "- سلامت عملیاتی\n",
    "\n",
    "در این درس، PSI را به عنوان شاخص ساده دریفت برای یک ویژگی محاسبه می‌کنیم.\n",
    "\n",
    "---\n",
    "\n",
    "## ۶) نشت اطلاعات (شکست کلاسیک گردش‌کار)\n",
    "\n",
    "نشت اغلب معیارهای بسیار بالا و غیرواقعی ایجاد می‌کند. یک ویژگی نشتی می‌سازیم تا ببینید چگونه معیارها می‌توانند گمراه‌کننده باشند.\n",
    "\n",
    "---\n",
    "\n",
    "## ۷) گردش‌کار بدون برچسب (خوشه‌بندی)\n",
    "\n",
    "حتی بدون برچسب هم انضباط گردش‌کار ثابت است:\n",
    "\n",
    "- هدف را تعریف کنید (تقسیم‌بندی/ناهنجاری/فشرده‌سازی)\n",
    "- ویژگی‌ها را استاندارد کنید\n",
    "- $k$ را انتخاب کنید (elbow/inertia، پایداری، محدودیت‌های کسب‌وکار)\n",
    "- خوشه‌ها را تفسیر کنید و با بررسی‌های دامنه‌ای اعتبارسنجی کنید\n",
    "\n",
    "---\n",
    "\n",
    "## چک‌لیست‌های عملی\n",
    "\n",
    "### چک‌لیست داده\n",
    "- [ ] تعریف هدف شامل محدودیت زمانی است\n",
    "- [ ] راهبرد تقسیم مطابق استقرار واقعی است\n",
    "- [ ] اعتبارسنجی طرح‌واره پیاده‌سازی شده\n",
    "- [ ] کاندیدهای نشت بررسی شده‌اند\n",
    "- [ ] نسخه داده ثبت شده است\n",
    "\n",
    "### چک‌لیست مدل‌سازی\n",
    "- [ ] خط‌پایه دارید\n",
    "- [ ] پیش‌پردازش داخل پایپ‌لاین است\n",
    "- [ ] بازتولیدپذیری (seed، محیط) کنترل می‌شود\n",
    "- [ ] تنظیم پارامترها بدون نشت به test انجام می‌شود\n",
    "\n",
    "### چک‌لیست ارزیابی\n",
    "- [ ] معیارهای کلی + عدم‌قطعیت (CV)\n",
    "- [ ] آستانه تحت هزینه‌ها انتخاب شده\n",
    "- [ ] تحلیل برش انجام شده\n",
    "- [ ] نمونه‌های خطا دستی بررسی شده‌اند\n",
    "\n",
    "### چک‌لیست استقرار\n",
    "- [ ] مصنوعات ذخیره و load-test شده\n",
    "- [ ] طرح‌واره ورودی مستند است\n",
    "- [ ] برنامه پایش و محرک بازآموزی مشخص است\n",
    "\n",
    "این نوت‌بوک نسخه حداقلی هر مرحله را نشان می‌دهد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca248bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import joblib\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6030ad3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification_iris': '../../../Datasets/Classification/iris.csv',\n",
       " 'classification_wine': '../../../Datasets/Classification/Wine_Quality.csv',\n",
       " 'classification_diabetes': '../../../Datasets/Classification/diabetes.csv'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = [\n",
    "    (\"classification_diabetes\", \"../../../Datasets/Classification/diabetes.csv\"),\n",
    "    (\"classification_iris\", \"../../../Datasets/Classification/iris.csv\"),\n",
    "    (\"classification_wine\", \"../../../Datasets/Classification/Wine_Quality.csv\"),\n",
    "    (\"regression_diamonds\", \"../../../Datasets/Regression/diamonds.csv\"),\n",
    "    (\"regression_house_prices\", \"../../../Datasets/Regression/house-prices.csv\"),\n",
    "    (\"clustering_airports\", \"../../../Datasets/Clustering/airports.csv\"),\n",
    "    (\"clustering_hw200\", \"../../../Datasets/Clustering/hw_200.csv\"),\n",
    "]\n",
    "\n",
    "random.seed(4)  # fixed for stable lesson content\n",
    "chosen = dict(random.sample(candidates, k=3))\n",
    "chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932c2679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader functions ready.\n"
     ]
    }
   ],
   "source": [
    "def _exists(path_str: str) -> bool:\n",
    "    try:\n",
    "        return Path(path_str).exists()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "DIABETES_SAMPLE = r'''Pregnancies,Glucose,BloodPressure,SkinThickness,Insulin,BMI,DiabetesPedigreeFunction,Age,classification\n",
    "6,148,72,35,0,33.6,0.627,50,Diabetic\n",
    "1,85,66,29,0,26.6,0.351,31,Non-Diabetic\n",
    "8,183,64,0,0,23.3,0.672,32,Diabetic\n",
    "1,89,66,23,94,28.1,0.167,21,Non-Diabetic\n",
    "0,137,40,35,168,43.1,2.288,33,Diabetic\n",
    "'''\n",
    "\n",
    "AIRPORTS_SAMPLE = r'''\"latitude_deg\",\"longitude_deg\",\"elevation_ft\"\n",
    "40.070985,-74.933689,11\n",
    "38.704022,-101.473911,3435\n",
    "59.947733,-151.692524,450\n",
    "'''\n",
    "\n",
    "def load_or_synthesize_diabetes(path: str, n: int = 420, seed: int = 42) -> pd.DataFrame:\n",
    "    if _exists(path):\n",
    "        return pd.read_csv(path)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df0 = pd.read_csv(pd.io.common.StringIO(DIABETES_SAMPLE))\n",
    "    cols = [c for c in df0.columns if c != \"classification\"]\n",
    "    mu = df0[cols].mean()\n",
    "    sd = df0[cols].std().replace(0, 1.0).fillna(1.0)\n",
    "\n",
    "    X = rng.normal(loc=mu.values, scale=sd.values, size=(n, len(cols)))\n",
    "    X = pd.DataFrame(X, columns=cols)\n",
    "\n",
    "    X[\"Pregnancies\"] = np.clip(np.round(X[\"Pregnancies\"]), 0, 20)\n",
    "    X[\"Glucose\"] = np.clip(X[\"Glucose\"], 50, 250)\n",
    "    X[\"BloodPressure\"] = np.clip(X[\"BloodPressure\"], 30, 140)\n",
    "    X[\"SkinThickness\"] = np.clip(X[\"SkinThickness\"], 0, 100)\n",
    "    X[\"Insulin\"] = np.clip(X[\"Insulin\"], 0, 600)\n",
    "    X[\"BMI\"] = np.clip(X[\"BMI\"], 15, 60)\n",
    "    X[\"DiabetesPedigreeFunction\"] = np.clip(X[\"DiabetesPedigreeFunction\"], 0.05, 3.0)\n",
    "    X[\"Age\"] = np.clip(X[\"Age\"], 18, 85)\n",
    "\n",
    "    score = (\n",
    "        0.03 * (X[\"Glucose\"] - 120)\n",
    "        + 0.06 * (X[\"BMI\"] - 30)\n",
    "        + 0.02 * (X[\"Age\"] - 35)\n",
    "        + 0.15 * (X[\"DiabetesPedigreeFunction\"] - 0.5)\n",
    "    )\n",
    "    p = 1 / (1 + np.exp(-score))\n",
    "    y = rng.binomial(1, np.clip(p, 0.05, 0.95), size=n)\n",
    "    X[\"classification\"] = np.where(y == 1, \"Diabetic\", \"Non-Diabetic\")\n",
    "    return X\n",
    "\n",
    "def load_or_synthesize_diamonds(path: str, n: int = 600, seed: int = 42) -> pd.DataFrame:\n",
    "    if _exists(path):\n",
    "        return pd.read_csv(path)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    cuts = [\"Fair\", \"Good\", \"Very Good\", \"Premium\", \"Ideal\"]\n",
    "    colors = list(\"DEFGHIJ\")\n",
    "    clarities = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]\n",
    "\n",
    "    carat = np.clip(rng.lognormal(mean=-0.4, sigma=0.5, size=n), 0.2, 2.5)\n",
    "    cut = rng.choice(cuts, size=n, p=[0.03, 0.10, 0.25, 0.30, 0.32])\n",
    "    color = rng.choice(colors, size=n, p=[0.15, 0.18, 0.17, 0.15, 0.13, 0.12, 0.10])\n",
    "    clarity = rng.choice(clarities, size=n, p=[0.02, 0.10, 0.18, 0.20, 0.18, 0.15, 0.10, 0.07])\n",
    "\n",
    "    depth = np.clip(rng.normal(61.5, 1.5, size=n), 55, 70)\n",
    "    table = np.clip(rng.normal(57.0, 2.0, size=n), 50, 70)\n",
    "\n",
    "    x = np.clip(3.0 + 2.2 * np.sqrt(carat) + rng.normal(0, 0.15, size=n), 3.0, 10.0)\n",
    "    y = np.clip(x + rng.normal(0, 0.08, size=n), 3.0, 10.0)\n",
    "    z = np.clip(2.0 + 1.4 * np.sqrt(carat) + rng.normal(0, 0.12, size=n), 1.5, 6.5)\n",
    "\n",
    "    base = 800 * (carat ** 1.7)\n",
    "    noise = rng.normal(0, 250, size=n)\n",
    "    price = np.clip(base + noise, 200, None)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"id\": np.arange(1, n+1).astype(str),\n",
    "        \"carat\": carat,\n",
    "        \"cut\": cut,\n",
    "        \"color\": color,\n",
    "        \"clarity\": clarity,\n",
    "        \"depth\": depth,\n",
    "        \"table\": table,\n",
    "        \"price\": price.round(0).astype(int),\n",
    "        \"x\": x.round(2),\n",
    "        \"y\": y.round(2),\n",
    "        \"z\": z.round(2),\n",
    "    })\n",
    "\n",
    "def load_or_synthesize_airports(path: str, n: int = 240, seed: int = 42) -> pd.DataFrame:\n",
    "    if _exists(path):\n",
    "        return pd.read_csv(path)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df0 = pd.read_csv(pd.io.common.StringIO(AIRPORTS_SAMPLE))\n",
    "    centers = df0[[\"latitude_deg\", \"longitude_deg\", \"elevation_ft\"]].to_numpy()\n",
    "    cluster = rng.integers(0, len(centers), size=n)\n",
    "    base = centers[cluster]\n",
    "    lat = base[:, 0] + rng.normal(0, 1.0, size=n)\n",
    "    lon = base[:, 1] + rng.normal(0, 1.6, size=n)\n",
    "    elev = np.clip(base[:, 2] + rng.normal(0, 800, size=n), 0, 12000).astype(int)\n",
    "    return pd.DataFrame({\"latitude_deg\": lat, \"longitude_deg\": lon, \"elevation_ft\": elev})\n",
    "\n",
    "print(\"Loader functions ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "652d629b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes: (768, 9)  Diamonds: (53940, 11)  Airports: (83125, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>Non-Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>Non-Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age classification  \n",
       "0                     0.627   50       Diabetic  \n",
       "1                     0.351   31   Non-Diabetic  \n",
       "2                     0.672   32       Diabetic  \n",
       "3                     0.167   21   Non-Diabetic  \n",
       "4                     2.288   33       Diabetic  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetes_path = chosen.get(\"classification_diabetes\", \"../../../Datasets/Classification/diabetes.csv\")\n",
    "diamonds_path = chosen.get(\"regression_diamonds\", \"../../../Datasets/Regression/diamonds.csv\")\n",
    "airports_path = chosen.get(\"clustering_airports\", \"../../../Datasets/Clustering/airports.csv\")\n",
    "\n",
    "df_diabetes = load_or_synthesize_diabetes(diabetes_path, n=420, seed=SEED)\n",
    "df_diamonds = load_or_synthesize_diamonds(diamonds_path, n=600, seed=SEED)\n",
    "df_airports = load_or_synthesize_airports(airports_path, n=240, seed=SEED)\n",
    "\n",
    "print(\"Diabetes:\", df_diabetes.shape, \" Diamonds:\", df_diamonds.shape, \" Airports:\", df_airports.shape)\n",
    "display(df_diabetes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb80f329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation OK? True\n"
     ]
    }
   ],
   "source": [
    "def validate_input(df: pd.DataFrame, required_cols, numeric_ranges=None):\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "    if numeric_ranges:\n",
    "        for c, (lo, hi) in numeric_ranges.items():\n",
    "            if c in df.columns:\n",
    "                bad = df[(df[c] < lo) | (df[c] > hi)]\n",
    "                if len(bad) > 0:\n",
    "                    raise ValueError(f\"Column {c} has values outside [{lo}, {hi}] (n_bad={len(bad)})\")\n",
    "    return True\n",
    "\n",
    "required = [\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"BMI\",\"Age\",\"classification\"]\n",
    "ranges = {\"Age\": (0, 120), \"Glucose\": (0, 400), \"BMI\": (0, 100)}\n",
    "print(\"Validation OK?\", validate_input(df_diabetes, required, ranges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbe2ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (576, 8) Test: (192, 8)\n",
      "Positive rate (train/test): 0.349 0.349\n"
     ]
    }
   ],
   "source": [
    "target = \"classification\"\n",
    "X = df_diabetes.drop(columns=[target]).copy()\n",
    "y = df_diabetes[target].map({\"Non-Diabetic\": 0, \"Diabetic\": 1}).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
    "print(\"Positive rate (train/test):\", round(y_train.mean(), 3), round(y_test.mean(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1574f473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy     0.7344\n",
       "precision    0.6481\n",
       "recall       0.5224\n",
       "f1           0.5785\n",
       "roc_auc      0.8320\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = X_train.columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), numeric_features)]\n",
    ")\n",
    "\n",
    "lr = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=250, random_state=SEED))\n",
    "])\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "proba_lr = lr.predict_proba(X_test)[:, 1]\n",
    "pred_lr = (proba_lr >= 0.5).astype(int)\n",
    "\n",
    "metrics_lr = {\n",
    "    \"accuracy\": accuracy_score(y_test, pred_lr),\n",
    "    \"precision\": precision_score(y_test, pred_lr, zero_division=0),\n",
    "    \"recall\": recall_score(y_test, pred_lr, zero_division=0),\n",
    "    \"f1\": f1_score(y_test, pred_lr, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(y_test, proba_lr),\n",
    "}\n",
    "\n",
    "pd.Series(metrics_lr).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e7f9303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.7344</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.5224</td>\n",
       "      <td>0.5785</td>\n",
       "      <td>0.8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.7037</td>\n",
       "      <td>0.5672</td>\n",
       "      <td>0.6281</td>\n",
       "      <td>0.8192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  precision  recall      f1  roc_auc\n",
       "LogReg          0.7344     0.6481  0.5224  0.5785   0.8320\n",
       "RandomForest    0.7656     0.7037  0.5672  0.6281   0.8192"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=40, random_state=SEED, n_jobs=-1,\n",
    "        max_depth=7, min_samples_leaf=2\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "pred_rf = (proba_rf >= 0.5).astype(int)\n",
    "\n",
    "metrics_rf = {\n",
    "    \"accuracy\": accuracy_score(y_test, pred_rf),\n",
    "    \"precision\": precision_score(y_test, pred_rf, zero_division=0),\n",
    "    \"recall\": recall_score(y_test, pred_rf, zero_division=0),\n",
    "    \"f1\": f1_score(y_test, pred_rf, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(y_test, proba_rf),\n",
    "}\n",
    "\n",
    "pd.DataFrame([metrics_lr, metrics_rf], index=[\"LogReg\", \"RandomForest\"]).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd0ed41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline LR CV ROC-AUC: [0.8206 0.8086]  mean: 0.8146\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=SEED)\n",
    "cv_auc = cross_val_score(lr, X_train, y_train, scoring=\"roc_auc\", cv=skf)\n",
    "print(\"Baseline LR CV ROC-AUC:\", np.round(cv_auc, 4), \" mean:\", round(cv_auc.mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24de4cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>53</td>\n",
       "      <td>44</td>\n",
       "      <td>81</td>\n",
       "      <td>14</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>98</td>\n",
       "      <td>22</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "      <td>109</td>\n",
       "      <td>29</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>38</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>46</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>58</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>67</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  TP  FP   TN  FN   cost\n",
       "0        0.1  65  78   47   2   88.0\n",
       "1        0.2  58  60   65   9  105.0\n",
       "2        0.3  53  44   81  14  114.0\n",
       "3        0.4  45  27   98  22  137.0\n",
       "4        0.5  38  16  109  29  161.0\n",
       "5        0.6  29  10  115  38  200.0\n",
       "6        0.7  21   4  121  46  234.0\n",
       "7        0.8   9   0  125  58  290.0\n",
       "8        0.9   0   0  125  67  335.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold by cost:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  TP  FP  TN  FN  cost\n",
       "0        0.1  65  78  47   2  88.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost_fp = 1.0\n",
    "cost_fn = 5.0\n",
    "\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    p = (proba_rf >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, p).ravel()\n",
    "    cost = cost_fp * fp + cost_fn * fn\n",
    "    rows.append((t, tp, fp, tn, fn, cost))\n",
    "\n",
    "df_thr = pd.DataFrame(rows, columns=[\"threshold\", \"TP\", \"FP\", \"TN\", \"FN\", \"cost\"])\n",
    "display(df_thr)\n",
    "print(\"Best threshold by cost:\")\n",
    "display(df_thr.sort_values(\"cost\").head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca9713b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO.PIESC\\AppData\\Local\\Temp\\ipykernel_2852\\1229140657.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_eval.groupby(\"age_band\", observed=True).apply(slice_metrics).reset_index().round(4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_band</th>\n",
       "      <th>n</th>\n",
       "      <th>pos_rate</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(17.999, 30.0]</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(30.0, 40.0]</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.6286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(40.0, 50.0]</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.8667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(50.0, 60.0]</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.4615</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(60.0, 85.0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age_band      n  pos_rate  recall  precision      f1\n",
       "0  (17.999, 30.0]  114.0    0.2105  0.3750     0.6000  0.4615\n",
       "1    (30.0, 40.0]   33.0    0.6364  0.5238     0.7857  0.6286\n",
       "2    (40.0, 50.0]   27.0    0.5556  0.8667     0.8667  0.8667\n",
       "3    (50.0, 60.0]   13.0    0.4615  0.6667     0.5000  0.5714\n",
       "4    (60.0, 85.0]    5.0    0.2000  1.0000     0.5000  0.6667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = X_test.copy()\n",
    "df_eval[\"y_true\"] = y_test.values\n",
    "df_eval[\"y_pred\"] = pred_rf\n",
    "\n",
    "df_eval[\"age_band\"] = pd.cut(df_eval[\"Age\"], bins=[18, 30, 40, 50, 60, 85], include_lowest=True)\n",
    "\n",
    "def slice_metrics(g):\n",
    "    yt = g[\"y_true\"].values\n",
    "    yp = g[\"y_pred\"].values\n",
    "    return pd.Series({\n",
    "        \"n\": len(g),\n",
    "        \"pos_rate\": yt.mean(),\n",
    "        \"recall\": recall_score(yt, yp, zero_division=0),\n",
    "        \"precision\": precision_score(yt, yp, zero_division=0),\n",
    "        \"f1\": f1_score(yt, yp, zero_division=0),\n",
    "    })\n",
    "\n",
    "df_eval.groupby(\"age_band\", observed=True).apply(slice_metrics).reset_index().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59669973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC with leakage: 1.0\n"
     ]
    }
   ],
   "source": [
    "X_leaky = X.copy()\n",
    "rng = np.random.default_rng(SEED)\n",
    "X_leaky[\"leaky_target_proxy\"] = y + rng.normal(0, 0.02, size=len(y))\n",
    "\n",
    "Xl_train, Xl_test, yl_train, yl_test = train_test_split(\n",
    "    X_leaky, y, test_size=0.25, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "pre_leaky = ColumnTransformer(\n",
    "    transformers=[(\"num\", Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), Xl_train.columns.tolist())]\n",
    ")\n",
    "\n",
    "leaky = Pipeline(steps=[\n",
    "    (\"preprocess\", pre_leaky),\n",
    "    (\"model\", LogisticRegression(max_iter=250, random_state=SEED))\n",
    "])\n",
    "\n",
    "leaky.fit(Xl_train, yl_train)\n",
    "proba = leaky.predict_proba(Xl_test)[:, 1]\n",
    "print(\"ROC-AUC with leakage:\", round(roc_auc_score(yl_test, proba), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "960e02ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>13</td>\n",
       "      <td>104</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.465</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "635           13      104             72              0        0  31.2   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "635                     0.465   38  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(diabetic) = 0.3655  -> class = 0\n"
     ]
    }
   ],
   "source": [
    "artifact_dir = Path(\"./_artifacts\")\n",
    "artifact_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = artifact_dir / \"chapter1_lesson4_diabetes_rf_pipeline.joblib\"\n",
    "joblib.dump(rf, model_path)\n",
    "\n",
    "loaded = joblib.load(model_path)\n",
    "\n",
    "one = X_test.iloc[[0]].copy()\n",
    "display(one)\n",
    "\n",
    "p1 = loaded.predict_proba(one)[:, 1][0]\n",
    "print(\"P(diabetic) =\", round(float(p1), 4), \" -> class =\", int(p1 >= 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fea625fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSI(Glucose): 0.291\n"
     ]
    }
   ],
   "source": [
    "def psi(expected: np.ndarray, actual: np.ndarray, bins: int = 10, eps: float = 1e-6) -> float:\n",
    "    q = np.linspace(0, 1, bins + 1)\n",
    "    cuts = np.quantile(expected, q)\n",
    "    cuts[0], cuts[-1] = -np.inf, np.inf\n",
    "    e_counts, _ = np.histogram(expected, bins=cuts)\n",
    "    a_counts, _ = np.histogram(actual, bins=cuts)\n",
    "    e = np.clip(e_counts / max(e_counts.sum(), 1), eps, 1)\n",
    "    a = np.clip(a_counts / max(a_counts.sum(), 1), eps, 1)\n",
    "    return float(np.sum((a - e) * np.log(a / e)))\n",
    "\n",
    "future = X_test.copy()\n",
    "future[\"Glucose\"] = future[\"Glucose\"] + 15  # simulate shift\n",
    "print(\"PSI(Glucose):\", round(psi(X_train[\"Glucose\"].to_numpy(), future[\"Glucose\"].to_numpy()), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c576b132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 12.32  RMSE: 63.21  R^2: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>559.0</td>\n",
       "      <td>555.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2201.0</td>\n",
       "      <td>2202.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1238.0</td>\n",
       "      <td>1241.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1304.0</td>\n",
       "      <td>1294.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6901.0</td>\n",
       "      <td>6901.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3011.0</td>\n",
       "      <td>3014.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1765.0</td>\n",
       "      <td>1764.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1679.0</td>\n",
       "      <td>1675.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_true   y_pred\n",
       "0   559.0   555.48\n",
       "1  2201.0  2202.37\n",
       "2  1238.0  1241.60\n",
       "3  1304.0  1294.37\n",
       "4  6901.0  6901.72\n",
       "5  3011.0  3014.04\n",
       "6  1765.0  1764.63\n",
       "7  1679.0  1675.78"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df_diamonds.copy()\n",
    "y_r = df[\"price\"].astype(float)\n",
    "X_r = df.drop(columns=[\"price\"]).copy()\n",
    "\n",
    "cat_cols = [c for c in X_r.columns if X_r[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X_r.columns if c not in cat_cols]\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_r, y_r, test_size=0.25, random_state=SEED)\n",
    "\n",
    "preprocess_r = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]), num_cols),\n",
    "        (\"cat\", Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reg = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_r),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=40, random_state=SEED, n_jobs=-1,\n",
    "        max_depth=10, min_samples_leaf=2\n",
    "    ))\n",
    "])\n",
    "\n",
    "reg.fit(X_train_r, y_train_r)\n",
    "pred = reg.predict(X_test_r)\n",
    "\n",
    "mae = mean_absolute_error(y_test_r, pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test_r, pred))\n",
    "r2 = r2_score(y_test_r, pred)\n",
    "\n",
    "print(\"MAE:\", round(mae, 2), \" RMSE:\", round(rmse, 2), \" R^2:\", round(r2, 4))\n",
    "display(pd.DataFrame({\"y_true\": y_test_r.values[:8], \"y_pred\": pred[:8]}).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "626fb969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>inertia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>171305.319500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>123707.639589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>80408.774662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>64335.499902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>54530.896375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k        inertia\n",
       "0  2  171305.319500\n",
       "1  3  123707.639589\n",
       "2  4   80408.774662\n",
       "3  5   64335.499902\n",
       "4  6   54530.896375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    55872\n",
       "1    19937\n",
       "2     7316\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Robust clustering prep: handle missing values and enforce numeric types ---\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "dfc = df_airports.copy()\n",
    "\n",
    "cols = [\"latitude_deg\", \"longitude_deg\", \"elevation_ft\"]\n",
    "missing_cols = [c for c in cols if c not in dfc.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(\n",
    "        f\"Expected columns not found in airports data: {missing_cols}\\n\"\n",
    "        f\"Available columns (first 40): {list(dfc.columns)[:40]}\"\n",
    "    )\n",
    "\n",
    "Xc = dfc[cols].copy()\n",
    "\n",
    "# Coerce to numeric (some CSVs store these as strings); invalid parses become NaN\n",
    "for c in cols:\n",
    "    Xc[c] = pd.to_numeric(Xc[c], errors=\"coerce\")\n",
    "\n",
    "# Impute NaNs (KMeans cannot handle NaN)\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_imp = imputer.fit_transform(Xc)\n",
    "\n",
    "# Standardize\n",
    "Xs = StandardScaler().fit_transform(X_imp)\n",
    "\n",
    "# --- Model selection proxy: inertia for a small k grid (fast) ---\n",
    "ks = [2, 3, 4, 5, 6]\n",
    "rows = []\n",
    "models = {}\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, random_state=SEED, n_init=10)\n",
    "    km.fit(Xs)\n",
    "    rows.append((k, float(km.inertia_)))\n",
    "    models[k] = km\n",
    "\n",
    "inertia_df = pd.DataFrame(rows, columns=[\"k\", \"inertia\"]).sort_values(\"k\")\n",
    "display(inertia_df)\n",
    "\n",
    "best_k = 3  # for demonstration; in practice use elbow + stability + constraints\n",
    "km = models[best_k]\n",
    "dfc[\"cluster\"] = km.predict(Xs)\n",
    "display(dfc[\"cluster\"].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f29982",
   "metadata": {},
   "source": [
    "## تمرین‌ها (پیشنهادی)\n",
    "\n",
    "1. **آزمون راهبرد تقسیم**  \n",
    "   تقسیم تصادفی را با تقسیم زمانی جایگزین کنید (زمان را با مرتب‌سازی روی سن یا ویژگی دیگر شبیه‌سازی کنید) و معیارها را مقایسه کنید.\n",
    "\n",
    "2. **آستانه‌گذاری مبتنی بر هزینه**  \n",
    "   نسبت هزینه را به FN ده برابر FP تغییر دهید و بهترین آستانه را دوباره محاسبه کنید. چه تغییری در precision و recall رخ می‌دهد؟\n",
    "\n",
    "3. **تقویت اعتبارسنجی طرح‌واره**  \n",
    "   `validate_input` را طوری توسعه دهید که:\n",
    "   - ستون اضافه را رد کند (طرح‌واره سخت‌گیرانه)\n",
    "   - بازه‌های چند ویژگی را کنترل کند\n",
    "   - قوانین رد/جایگزینی برای مقدار گمشده داشته باشد\n",
    "\n",
    "4. **کالبدشکافی نشت**  \n",
    "   یک ویژگی شبیه شناسه (مثل index) اضافه کنید و ببینید معیارها تغییر می‌کنند یا نه. توضیح دهید در چه شرایطی شناسه‌ها نشت ایجاد می‌کنند.\n",
    "\n",
    "5. **یادداشت‌های حاکمیت مدل**  \n",
    "   یک «کارت مدل» یک صفحه‌ای بنویسید: کاربرد، داده آموزش، معیارها، محدودیت‌ها، پایش.\n",
    "\n",
    "6. **تفسیر خوشه‌ها**  \n",
    "   برای هر خوشه، میانگین/میانه latitude/longitude/elevation را حساب کنید و یک تفسیر کوتاه بنویسید.\n",
    "\n",
    "7. **بازتولیدپذیری**  \n",
    "   نوت‌بوک را دو بار اجرا کنید و مطمئن شوید انتخاب داده‌ها و معیارها پایدار است."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
