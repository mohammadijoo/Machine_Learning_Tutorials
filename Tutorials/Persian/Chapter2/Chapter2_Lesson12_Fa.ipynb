{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b9fb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap');\n",
       "@import url('https://cdnjs.cloudflare.com/ajax/libs/shabnam-font/5.0.1/font-face.css');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Amiri:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Mirza:wght@400;700&display=swap');\n",
       "\n",
       "\n",
       "\n",
       "/* Text areas (Classic Notebook + JupyterLab) */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "div.rendered_html, .output_subarea {\n",
       "  font-family: \"Vazirmatn\", \"Shabnam\", \"Mirza\", \"Amiri\", Tahoma, \"Segoe UI\", sans-serif !important;\n",
       "}\n",
       "\n",
       "/* RTL for rendered markdown/html content */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "h1, h2, h3, h4, h5, h6, p, strong, label, ol, ul, li {\n",
       "  direction: rtl !important;\n",
       "  text-align: right !important;\n",
       "  line-height: 1.9;\n",
       "  font-family: \"Vazirmatn\", \"Shabnam\", \"Mirza\", \"Amiri\", Tahoma, \"Segoe UI\", sans-serif !important;\n",
       "}\n",
       "\n",
       "h1 { font-size: 2rem; color: #070F2B; font-weight: 900}\n",
       "h2 { font-size: 1.8rem; color: #070F2B; font-weight: 800}\n",
       "h3 { font-size: 1.6rem; color: #070F2B; font-weight: 700}\n",
       "h4 { font-size: 1.4rem; color: #1E3E62; font-weight: 600}\n",
       "h5 { font-size: 1.2rem; color: #1E3E62}\n",
       "h6 { font-size: 1rem; color: #1E3E62}\n",
       "p { font-size: 1.1rem; ; font-weight: 400}\n",
       "ol, ul, li, th, td  { font-size: 1rem; }\n",
       "\n",
       "/* Keep code + outputs LTR and monospace */\n",
       ".CodeMirror, .CodeMirror *,\n",
       "pre, code,\n",
       ".jp-CodeCell .jp-InputArea, .jp-CodeCell .jp-InputArea *,\n",
       ".jp-OutputArea, .jp-OutputArea * {\n",
       "  direction: ltr !important;\n",
       "  text-align: left !important;\n",
       "  font-size: 1rem !important;\n",
       "  font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "css = Path(\"../../../css/rtl.css\").read_text(encoding=\"utf-8\")\n",
    "display(HTML(f\"<style>{css}</style>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ebde1",
   "metadata": {},
   "source": [
    "# فصل ۲ — مبانی داده و پیش‌پردازش\n",
    "## درس ۱۲: بهداشتِ Train/Validation/Test (برش‌های زمانی، برش‌های گروهی، نشتِ موجودیت)\n",
    "\n",
    "این درس درباره واقعی‌کردن ارزیابی است. حتی بهترین مدل هم اگر ارزیابی عملکرد را بیش‌ازحد واقعی نشان دهد، تصمیم‌گیری را خراب می‌کند.\n",
    "\n",
    "در این درس، برش زمان‌محور، برش گروهی/موجودیتی، فورنسیکِ نشت، و الگوهای امن پیش‌پردازش را تمرین می‌کنید. کدها برای جریان‌های کاری رایج در داده‌های جدولی طراحی شده‌اند.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6a58d0",
   "metadata": {},
   "source": [
    "### اهداف یادگیری\n",
    "\n",
    "در پایان این درس باید بتوانید:\n",
    "\n",
    "1. توضیح دهید چرا ارزیابی به استقلال تقریبی بین آموزش و آزمون نیاز دارد.\n",
    "2. تشخیص دهید چه زمانی برش تصادفی قابل قبول است و چه زمانی گمراه‌کننده است.\n",
    "3. برش زمانی، اعتبارسنجی پنجره‌ای/گسترشی و گَپ زمانی را پیاده‌سازی کنید.\n",
    "4. برش گروهی/موجودیتی و cross-validation گروه‌محور را پیاده‌سازی کنید.\n",
    "5. هم‌پوشانی موجودیت، نزدیک-به-تکراری‌ها و ویژگی‌های پس از رخداد را تشخیص دهید.\n",
    "6. با پایپلاین‌ها از نشت پیش‌پردازش جلوگیری کنید.\n",
    "7. انتخاب مدل را از آزمون نهایی جدا کنید (نشت اعتبارسنجی نداشته باشید).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916107b",
   "metadata": {},
   "source": [
    "### ایده اصلی: مجموعه آزمون دقیقاً چه چیزی را تخمین می‌زند؟\n",
    "\n",
    "اگر توزیع استقرار $\\mathcal{P}$ و تابع هزینه $\\ell(\\cdot)$ باشد، ریسک تعمیم:\n",
    "\n",
    "$$R(f) = \\mathbb{E}_{(X,Y) \\sim \\mathcal{P}}[\\ell(f(X), Y)].$$\n",
    "\n",
    "مجموعه آزمون فقط زمانی مفید است که نمونه‌ای تقریباً i.i.d. از $\\mathcal{P}$ *در زمان و مقیاس استقرار* باشد.\n",
    "اگر برش این تقریب را نقض کند (به علت وابستگی زمانی، موجودیت‌های تکراری یا نشت)، تخمین آزمون خوش‌بینانه می‌شود.\n",
    "\n",
    "به‌صورت فشرده: اگر $\\mathcal{D}_{\\text{train}}$ و $\\mathcal{D}_{\\text{test}}$ مستقل نباشند، عموماً:\n",
    "\n",
    "$$\\mathbb{E}[\\widehat{R}_{\\text{test}}(f)] \\ne R(f),$$\n",
    "\n",
    "زیرا رویه آموزش می‌تواند از هم‌بستگی بین دو مجموعه استفاده کند.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52351db9",
   "metadata": {},
   "source": [
    "### طبقه‌بندی انواع نشت\n",
    "\n",
    "نشت یعنی هر مسیری که اطلاعاتِ غیرقابل‌دسترس در زمان پیش‌بینی، بر آموزش یا ارزیابی اثر بگذارد.\n",
    "\n",
    "- **نشت زمانی:** یادگیری از آینده (مستقیم یا از طریق آمارهایی که آینده را شامل می‌شوند).\n",
    "- **نشت گروه/موجودیت:** یک موجودیت هم در train و هم در test دیده می‌شود.\n",
    "- **نشت هدف:** ویژگی‌ها جانشین مستقیم/غیرمستقیم برچسب هستند (پس از رخداد).\n",
    "- **نشت اعتبارسنجی:** تنظیم‌های مدل با نگاه‌های مکرر به test.\n",
    "\n",
    "قانون عملی: لحظه/رویداد پیش‌بینی را تعریف کنید و هر ویژگی‌ای را که در آن لحظه نامعلوم است حذف کنید.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3c0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, TimeSeriesSplit, GroupShuffleSplit, GroupKFold, KFold\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, r2_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pd.set_option('display.max_columns', 60)\n",
    "pd.set_option('display.width', 160)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca03d001",
   "metadata": {},
   "source": [
    "## ۱) یک پروتکل ارزیابی تمیز\n",
    "\n",
    "یک پروتکل قابل اتکا برای اغلب پروژه‌های جدولی:\n",
    "\n",
    "1. **قرارداد پیش‌بینی را مشخص کنید**: چه چیزی، چه زمانی، و با چه ورودی‌هایی پیش‌بینی می‌شود.\n",
    "2. **برش را طراحی کنید** تا بازتاب استقرار باشد (تصادفی، زمانی، گروهی یا ترکیبی).\n",
    "3. **test را قفل کنید**: برای تصمیم‌های تکراری از آن استفاده نکنید.\n",
    "4. **روی داده آموزش** از اعتبارسنجی/‏CV برای انتخاب مدل استفاده کنید.\n",
    "5. در صورت امکان **عدم قطعیت** را با تغییرات foldها گزارش کنید.\n",
    "\n",
    "برش سه‌گانه:\n",
    "\n",
    "$$\\mathcal{D} = \\mathcal{D}_{\\text{train}} \\cup \\mathcal{D}_{\\text{val}} \\cup \\mathcal{D}_{\\text{test}},\\quad\n",
    "\\mathcal{D}_{\\text{train}} \\cap \\mathcal{D}_{\\text{val}} = \\varnothing,\\quad\n",
    "\\mathcal{D}_{\\text{train}} \\cap \\mathcal{D}_{\\text{test}} = \\varnothing,\\quad\n",
    "\\mathcal{D}_{\\text{val}} \\cap \\mathcal{D}_{\\text{test}} = \\varnothing.$$\n",
    "\n",
    "نکته کلیدی این است که «جدا بودن» باید در ساختار وابستگی هم رعایت شود: زمان نباید به عقب برگردد و موجودیت‌ها در حالتِ تعمیم به موجودیت‌های جدید نباید هم‌پوشانی داشته باشند.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f97d28",
   "metadata": {},
   "source": [
    "### چه زمانی برش تصادفی قابل قبول است؟\n",
    "\n",
    "برش تصادفی معمولاً وقتی قابل قبول است که:\n",
    "\n",
    "- ردیف‌ها تقریباً i.i.d. باشند (ترتیب زمانی معنادار و موجودیت‌های تکراری وجود نداشته باشد).\n",
    "- توزیع استقرار پایدار باشد (drift شدید نباشد).\n",
    "- مدل روی داده‌ای مشابه داده جمع‌آوری‌شده استفاده شود.\n",
    "\n",
    "اگر یکی از موارد زیر برقرار باشد، برش تصادفی پرریسک می‌شود:\n",
    "\n",
    "- چند ردیف برای هر موجودیت.\n",
    "- وابستگی زمانی یا فصل‌مندی.\n",
    "- تغییرات عملیاتی (سیاست‌ها، محصول، ارتقای حسگر).\n",
    "- ویژگی‌های تجمیعی روی پنجره‌های زمانی.\n",
    "\n",
    "در این شرایط، معمولاً به برش زمان‌محور یا موجودیت‌محور نیاز دارید.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c02e03",
   "metadata": {},
   "source": [
    "## ۲) برش‌های زمانی\n",
    "\n",
    "برش زمانی زمانی لازم است که مسئله آینده‌نگر باشد یا فرآیند تولید داده در طول زمان تغییر کند.\n",
    "\n",
    "یک holdout زمان‌محور:\n",
    "\n",
    "$$\\text{Train} = \\{t \\le t_0\\},\\quad \\text{Test} = \\{t > t_0\\}.$$\n",
    "\n",
    "اگر برچسب با تأخیر مشاهده می‌شود یا ویژگی‌ها روی پنجره‌های زمانی ساخته می‌شوند، یک **گَپ** زمانی هم در نظر بگیرید.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6672efd",
   "metadata": {},
   "source": [
    "### مثال A: مقایسه برش تصادفی و برش زمانی روی شکایات مصرف‌کنندگان\n",
    "\n",
    "دیتاست: `ConsumerComplaints.csv` با `Date Received`.\n",
    "\n",
    "وظیفه: پیش‌بینی اینکه آیا پاسخ‌دهی به‌موقع بوده است (`Timely Response`).\n",
    "برش تصادفیِ طبقه‌بندی‌شده را با برش رو به آینده مقایسه می‌کنیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaef437d-1f80-4ae4-9d8c-ba58e25ebbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Received</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sub Product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub Issue</th>\n",
       "      <th>Consumer Complaint Narrative</th>\n",
       "      <th>Company Public Response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State Name</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer Consent Provided</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date Sent to Company</th>\n",
       "      <th>Company Response to Consumer</th>\n",
       "      <th>Timely Response</th>\n",
       "      <th>Consumer Disputed</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Vehicle loan</td>\n",
       "      <td>Managing the loan or lease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>VA</td>\n",
       "      <td>24540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phone</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>468882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>Checking account</td>\n",
       "      <td>Using a debit or ATM card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>CA</td>\n",
       "      <td>95992</td>\n",
       "      <td>Older American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>468889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>Checking account</td>\n",
       "      <td>Account opening, closing, or management</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Santander Bank US</td>\n",
       "      <td>NY</td>\n",
       "      <td>10065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fax</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>468879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>Checking account</td>\n",
       "      <td>Deposits and withdrawals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>GA</td>\n",
       "      <td>30084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>468949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Conventional fixed mortgage</td>\n",
       "      <td>Loan servicing, payments, escrow account</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Franklin Credit Management</td>\n",
       "      <td>CT</td>\n",
       "      <td>6106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>475823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date Received             Product Name                  Sub Product                                     Issue Sub Issue Consumer Complaint Narrative  \\\n",
       "0    2013-07-29            Consumer Loan                 Vehicle loan                Managing the loan or lease       NaN                          NaN   \n",
       "1    2013-07-29  Bank account or service             Checking account                 Using a debit or ATM card       NaN                          NaN   \n",
       "2    2013-07-29  Bank account or service             Checking account   Account opening, closing, or management       NaN                          NaN   \n",
       "3    2013-07-29  Bank account or service             Checking account                  Deposits and withdrawals       NaN                          NaN   \n",
       "4    2013-07-29                 Mortgage  Conventional fixed mortgage  Loan servicing, payments, escrow account       NaN                          NaN   \n",
       "\n",
       "  Company Public Response                     Company State Name Zip Code            Tags Consumer Consent Provided Submitted via Date Sent to Company  \\\n",
       "0                     NaN       Wells Fargo & Company         VA    24540             NaN                       NaN         Phone           2013-07-30   \n",
       "1                     NaN       Wells Fargo & Company         CA    95992  Older American                       NaN           Web           2013-07-31   \n",
       "2                     NaN           Santander Bank US         NY    10065             NaN                       NaN           Fax           2013-07-31   \n",
       "3                     NaN       Wells Fargo & Company         GA    30084             NaN                       NaN           Web           2013-07-30   \n",
       "4                     NaN  Franklin Credit Management         CT     6106             NaN                       NaN           Web           2013-07-30   \n",
       "\n",
       "  Company Response to Consumer Timely Response Consumer Disputed  Complaint ID  \n",
       "0      Closed with explanation             Yes                No        468882  \n",
       "1      Closed with explanation             Yes                No        468889  \n",
       "2                       Closed             Yes                No        468879  \n",
       "3      Closed with explanation             Yes                No        468949  \n",
       "4      Closed with explanation             Yes                No        475823  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_path = \"../../../Datasets/Clustering/ConsumerComplaints.csv\"\n",
    "df = pd.read_csv(complaints_path, low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "129b3034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 65499\n",
      "Positive rate: 0.9772210262752103\n",
      "Date range: 2013-07-22 to 2015-09-02\n"
     ]
    }
   ],
   "source": [
    "# Basic cleanup for the demo\n",
    "df = df.copy()\n",
    "df['Date Received'] = pd.to_datetime(df['Date Received'], errors='coerce')\n",
    "df = df.dropna(subset=['Date Received', 'Timely Response'])\n",
    "\n",
    "y = (df['Timely Response'].astype(str).str.strip().str.lower() == 'yes').astype(int)\n",
    "feature_cols = ['Product Name', 'Sub Product', 'Issue', 'Sub Issue', 'Company', 'State Name', 'Submitted via']\n",
    "X = df[feature_cols]\n",
    "\n",
    "print('Rows:', len(df))\n",
    "print('Positive rate:', float(y.mean()))\n",
    "print('Date range:', df['Date Received'].min().date(), 'to', df['Date Received'].max().date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dd463ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تعداد ردیف‌ها: 65499\n",
      "نرخ مثبت: 0.9772210262752103\n",
      "بازه تاریخ: 2013-07-22 تا 2015-09-02\n"
     ]
    }
   ],
   "source": [
    "# پاک‌سازی اولیه برای دمو\n",
    "df = df.copy()\n",
    "df['Date Received'] = pd.to_datetime(df['Date Received'], errors='coerce')\n",
    "df = df.dropna(subset=['Date Received', 'Timely Response'])\n",
    "\n",
    "y = (df['Timely Response'].astype(str).str.strip().str.lower() == 'yes').astype(int)\n",
    "feature_cols = ['Product Name', 'Sub Product', 'Issue', 'Sub Issue', 'Company', 'State Name', 'Submitted via']\n",
    "X = df[feature_cols]\n",
    "\n",
    "print('تعداد ردیف‌ها:', len(df))\n",
    "print('نرخ مثبت:', float(y.mean()))\n",
    "print('بازه تاریخ:', df['Date Received'].min().date(), 'تا', df['Date Received'].max().date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e4e8ced-0e69-4e1f-98df-3e968c451906",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = feature_cols\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', LogisticRegression(max_iter=200))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef5e0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random split accuracy: 0.9781\n",
      "Random split ROC-AUC  : 0.9154\n"
     ]
    }
   ],
   "source": [
    "# (1) Random stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "proba = clf.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "acc_random = accuracy_score(y_test, pred)\n",
    "auc_random = roc_auc_score(y_test, proba)\n",
    "print('Random split accuracy:', round(acc_random, 4))\n",
    "print('Random split ROC-AUC  :', round(auc_random, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62ee2965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دقت برش تصادفی: 0.9781\n",
      "ROC-AUC برش تصادفی: 0.9154\n"
     ]
    }
   ],
   "source": [
    "# (۱) برش تصادفیِ طبقه‌بندی‌شده\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "proba = clf.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "acc_random = accuracy_score(y_test, pred)\n",
    "auc_random = roc_auc_score(y_test, proba)\n",
    "print('دقت برش تصادفی:', round(acc_random, 4))\n",
    "print('ROC-AUC برش تصادفی:', round(auc_random, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "895f24f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دقت برش زمانی: 0.9705\n",
      "ROC-AUC برش زمانی: 0.8955\n",
      "تاریخ پایان train: 2015-01-20\n",
      "تاریخ شروع test : 2015-01-20\n"
     ]
    }
   ],
   "source": [
    "# (۲) برش زمان‌محور: آموزش روی ۸۰٪ اول و آزمون روی ۲۰٪ آخر\n",
    "df_sorted = df.sort_values('Date Received')\n",
    "X_sorted = df_sorted[feature_cols]\n",
    "y_sorted = (df_sorted['Timely Response'].astype(str).str.strip().str.lower() == 'yes').astype(int)\n",
    "\n",
    "cut = int(0.8 * len(df_sorted))\n",
    "X_train_t, X_test_t = X_sorted.iloc[:cut], X_sorted.iloc[cut:]\n",
    "y_train_t, y_test_t = y_sorted.iloc[:cut], y_sorted.iloc[cut:]\n",
    "\n",
    "clf.fit(X_train_t, y_train_t)\n",
    "proba_t = clf.predict_proba(X_test_t)[:, 1]\n",
    "pred_t = (proba_t >= 0.5).astype(int)\n",
    "\n",
    "acc_time = accuracy_score(y_test_t, pred_t)\n",
    "auc_time = roc_auc_score(y_test_t, proba_t)\n",
    "print('دقت برش زمانی:', round(acc_time, 4))\n",
    "print('ROC-AUC برش زمانی:', round(auc_time, 4))\n",
    "print('تاریخ پایان train:', df_sorted['Date Received'].iloc[cut-1].date())\n",
    "print('تاریخ شروع test :', df_sorted['Date Received'].iloc[cut].date())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d21862e",
   "metadata": {},
   "source": [
    "### تفسیر اختلاف\n",
    "\n",
    "اگر امتیاز برش تصادفی بالاتر از برش زمانی باشد، معمولاً «خبر بد» نیست؛ بلکه نشان می‌دهد آینده سخت‌تر از یک عکسِ تصادفیِ درهم‌ریخته است.\n",
    "\n",
    "علت‌های رایج:\n",
    "\n",
    "- تغییر توزیع (محصول جدید، تغییر سیاست).\n",
    "- هم‌بستگی زمانی (تاریخ‌های نزدیک زمینه مشترک دارند).\n",
    "- تغییر نرخ پایه.\n",
    "\n",
    "اگر سیستم باید روی دوره‌های آینده پیش‌بینی کند، برش رو به آینده ارزیابی مرتبط است.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97331eca",
   "metadata": {},
   "source": [
    "### اعتبارسنجی پنجره‌ای/گسترشی با `TimeSeriesSplit`\n",
    "\n",
    "برای کاهش نویز یک holdout تکی، از rolling validation استفاده کنید.\n",
    "\n",
    "در پنجره گسترشی:\n",
    "\n",
    "$$\\text{Train}_k = \\{t \\le t_k\\},\\quad \\text{Test}_k = \\{t_k < t \\le t_{k+1}\\}.$$\n",
    "\n",
    "این دقیقاً شبیه واقعیت عملی است که تا یک تاریخ آموزش می‌دهید.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db95e6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: AUC=0.8265 | پایان train=2013-12-08 | test=2013-12-08..2014-03-25\n",
      "Fold 2: AUC=0.8235 | پایان train=2014-03-25 | test=2014-03-25..2014-07-08\n",
      "Fold 3: AUC=0.8747 | پایان train=2014-07-08 | test=2014-07-08..2014-10-20\n",
      "Fold 4: AUC=0.8834 | پایان train=2014-10-20 | test=2014-10-20..2015-02-09\n",
      "Fold 5: AUC=0.8959 | پایان train=2015-02-09 | test=2015-02-09..2015-09-02\n",
      "میانگین AUC: 0.8607962707647356\n",
      "انحراف معیار AUC: 0.029990864243419388\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "X_ts = X_sorted.reset_index(drop=True)\n",
    "y_ts = y_sorted.reset_index(drop=True)\n",
    "\n",
    "aucs = []\n",
    "for fold, (tr, te) in enumerate(tscv.split(X_ts), start=1):\n",
    "    clf.fit(X_ts.iloc[tr], y_ts.iloc[tr])\n",
    "    proba = clf.predict_proba(X_ts.iloc[te])[:, 1]\n",
    "    auc = roc_auc_score(y_ts.iloc[te], proba)\n",
    "    aucs.append(auc)\n",
    "    train_end = df_sorted.iloc[tr[-1]]['Date Received'].date()\n",
    "    test_start = df_sorted.iloc[te[0]]['Date Received'].date()\n",
    "    test_end = df_sorted.iloc[te[-1]]['Date Received'].date()\n",
    "    print(f'Fold {fold}: AUC={auc:.4f} | پایان train={train_end} | test={test_start}..{test_end}')\n",
    "\n",
    "print('میانگین AUC:', float(np.mean(aucs)))\n",
    "print('انحراف معیار AUC:', float(np.std(aucs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e0cd5",
   "metadata": {},
   "source": [
    "### محافظ‌های زمانی: گَپ و تأخیر برچسب\n",
    "\n",
    "اگر برچسب با تأخیر می‌آید یا ویژگی‌ها روی پنجره‌های زمانی ساخته می‌شوند، ممکن است اطلاعات پنجره برچسب وارد ویژگی شود.\n",
    "\n",
    "یک محافظ ساده گَپ $g$ است:\n",
    "\n",
    "$$\\text{Train} = \\{t \\le t_0\\},\\quad \\text{Gap} = (t_0, t_0 + g],\\quad \\text{Test} = \\{t > t_0 + g\\}.$$\n",
    "\n",
    "گَپ را متناسب با بیشترین افق نگاه‌به‌آینده در تعریف ویژگی‌ها انتخاب کنید.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a020584a",
   "metadata": {},
   "source": [
    "## ۳) برش‌های گروهی و موجودیتی\n",
    "\n",
    "برش گروهی وابستگی ناشی از موجودیت‌های تکراری یا زمینه مشترک را کنترل می‌کند.\n",
    "\n",
    "دو سؤال عملیِ استقرار:\n",
    "\n",
    "- **تعمیم به موجودیت‌های جدید؟** → train/test باید بر اساس شناسه جدا باشند.\n",
    "- **پیش‌بینی آینده برای موجودیت‌های موجود؟** → برش زمانی درون هر موجودیت (و شاید گَپ زمانی).\n",
    "\n",
    "برش باید دقیقاً مطابق سناریوی استقرار باشد.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7a8d96",
   "metadata": {},
   "source": [
    "### یک استدلال کوتاه برای سوگیری\n",
    "\n",
    "فرض کنید $G$ شناسه موجودیت باشد و یک اثر پنهان $\\alpha_G$ وجود داشته باشد. مدل ساده:\n",
    "\n",
    "$$Y = \\beta^\\top X + \\alpha_G + \\epsilon.$$\n",
    "\n",
    "اگر همان $G$ها در train و test مشترک باشند، مدل می‌تواند $\\alpha_G$ را از داده‌های آموزش حدس بزند و پیش‌بینی روی test ساده‌تر می‌شود.\n",
    "این باعث می‌شود امتیاز آزمون به سناریوی «موجودیت دیده‌شده» سوگیر شود.\n",
    "\n",
    "اگر هدف عملکرد روی موجودیت‌های جدید است، باید هم‌پوشانی $G$ را صفر کنید.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d66e75e",
   "metadata": {},
   "source": [
    "### مثال B: نشت در سطح میزبان در listings\n",
    "\n",
    "دیتاست: `listings.csv`. موجودیت: `host_id`.\n",
    "وظیفه: پیش‌بینی `room_type`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60746438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13913</td>\n",
       "      <td>Holiday London DB Room Let-on going</td>\n",
       "      <td>54730</td>\n",
       "      <td>Alina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Islington</td>\n",
       "      <td>51.56861</td>\n",
       "      <td>-0.11270</td>\n",
       "      <td>Private room</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2025-02-09</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3</td>\n",
       "      <td>344</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15400</td>\n",
       "      <td>Bright Chelsea  Apartment. Chelsea!</td>\n",
       "      <td>60302</td>\n",
       "      <td>Philippa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kensington and Chelsea</td>\n",
       "      <td>51.48780</td>\n",
       "      <td>-0.16813</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>2024-04-28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17402</td>\n",
       "      <td>Very Central Modern 3-Bed/2 Bath By Oxford St W1</td>\n",
       "      <td>67564</td>\n",
       "      <td>Liz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>51.52195</td>\n",
       "      <td>-0.14094</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>510.0</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>5</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24328</td>\n",
       "      <td>Battersea live/work artist house</td>\n",
       "      <td>41759</td>\n",
       "      <td>Joe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>51.47072</td>\n",
       "      <td>-0.16266</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>213.0</td>\n",
       "      <td>90</td>\n",
       "      <td>94</td>\n",
       "      <td>2022-07-19</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31036</td>\n",
       "      <td>Bright  compact 1 Bedroom Apartment Brick Lane</td>\n",
       "      <td>133271</td>\n",
       "      <td>Hendryks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>51.52425</td>\n",
       "      <td>-0.06997</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              name  host_id host_name  neighbourhood_group           neighbourhood  latitude  longitude  \\\n",
       "0  13913               Holiday London DB Room Let-on going    54730     Alina                  NaN               Islington  51.56861   -0.11270   \n",
       "1  15400               Bright Chelsea  Apartment. Chelsea!    60302  Philippa                  NaN  Kensington and Chelsea  51.48780   -0.16813   \n",
       "2  17402  Very Central Modern 3-Bed/2 Bath By Oxford St W1    67564       Liz                  NaN             Westminster  51.52195   -0.14094   \n",
       "3  24328                  Battersea live/work artist house    41759       Joe                  NaN              Wandsworth  51.47072   -0.16266   \n",
       "4  31036    Bright  compact 1 Bedroom Apartment Brick Lane   133271  Hendryks                  NaN           Tower Hamlets  51.52425   -0.06997   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  reviews_per_month  calculated_host_listings_count  availability_365  \\\n",
       "0     Private room   57.0               1                 51  2025-02-09               0.29                               3               344   \n",
       "1  Entire home/apt    NaN               4                 96  2024-04-28               0.52                               1                11   \n",
       "2  Entire home/apt  510.0               3                 56  2024-02-19               0.33                               5               293   \n",
       "3  Entire home/apt  213.0              90                 94  2022-07-19               0.54                               1               194   \n",
       "4  Entire home/apt  100.0               2                126  2025-02-20               0.70                               8               353   \n",
       "\n",
       "   number_of_reviews_ltm  license  \n",
       "0                     10      NaN  \n",
       "1                      2      NaN  \n",
       "2                      0      NaN  \n",
       "3                      0      NaN  \n",
       "4                      3      NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_path = \"../../../Datasets/Regression/listings.csv\"\n",
    "ldf = pd.read_csv(listings_path, low_memory=False)\n",
    "ldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81421417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تعداد ردیف‌ها: 94559\n",
      "تعداد میزبان یکتا: 55395\n",
      "فراوانی کلاس‌ها (چند مورد اول):\n",
      "room_type\n",
      "Entire home/apt    60750\n",
      "Private room       33487\n",
      "Shared room          164\n",
      "Hotel room           158\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ldf = ldf.copy()\n",
    "ldf = ldf.dropna(subset=['host_id', 'room_type'])\n",
    "\n",
    "features = ['neighbourhood', 'latitude', 'longitude', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'availability_365']\n",
    "for col in ['price', 'reviews_per_month']:\n",
    "    ldf[col] = pd.to_numeric(ldf[col], errors='coerce')\n",
    "\n",
    "X2 = ldf[features]\n",
    "y2 = ldf['room_type'].astype(str)\n",
    "groups = ldf['host_id'].astype(str)\n",
    "\n",
    "print('تعداد ردیف‌ها:', len(ldf))\n",
    "print('تعداد میزبان یکتا:', groups.nunique())\n",
    "print('فراوانی کلاس‌ها (چند مورد اول):')\n",
    "print(y2.value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2656f814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 94559\n",
      "Unique hosts: 55395\n",
      "Class counts (top):\n",
      "room_type\n",
      "Entire home/apt    60750\n",
      "Private room       33487\n",
      "Shared room          164\n",
      "Hotel room           158\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ldf = ldf.copy()\n",
    "ldf = ldf.dropna(subset=['host_id', 'room_type'])\n",
    "\n",
    "features = ['neighbourhood', 'latitude', 'longitude', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'availability_365']\n",
    "for col in ['price', 'reviews_per_month']:\n",
    "    ldf[col] = pd.to_numeric(ldf[col], errors='coerce')\n",
    "\n",
    "X2 = ldf[features]\n",
    "y2 = ldf['room_type'].astype(str)\n",
    "groups = ldf['host_id'].astype(str)\n",
    "\n",
    "print('Rows:', len(ldf))\n",
    "print('Unique hosts:', groups.nunique())\n",
    "print('Class counts (top):')\n",
    "print(y2.value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5bff6cb-c747-46ed-8526-e80293ee4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['latitude', 'longitude', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'availability_365']\n",
    "cat_features = ['neighbourhood']\n",
    "\n",
    "preprocess2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                               ('scaler', StandardScaler())]), num_features),\n",
    "        ('cat', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                               ('onehot', OneHotEncoder(handle_unknown='ignore'))]), cat_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "clf2 = Pipeline(steps=[\n",
    "    ('preprocess', preprocess2),\n",
    "    ('model', LogisticRegression(max_iter=300))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8778f5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دقت برش تصادفی: 0.7474\n",
      "میزبان‌های مشترک train/test: 5126\n",
      "میزبان‌های train: 46337 | میزبان‌های test: 14184\n"
     ]
    }
   ],
   "source": [
    "# برش تصادفی\n",
    "X_tr, X_te, y_tr, y_te, g_tr, g_te = train_test_split(\n",
    "    X2, y2, groups, test_size=0.2, random_state=42, stratify=y2\n",
    ")\n",
    "clf2.fit(X_tr, y_tr)\n",
    "pred = clf2.predict(X_te)\n",
    "acc = accuracy_score(y_te, pred)\n",
    "\n",
    "shared_hosts = len(set(g_tr) & set(g_te))\n",
    "print('دقت برش تصادفی:', round(acc, 4))\n",
    "print('میزبان‌های مشترک train/test:', shared_hosts)\n",
    "print('میزبان‌های train:', len(set(g_tr)), '| میزبان‌های test:', len(set(g_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d80bdd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دقت برش گروهی: 0.7529\n",
      "میزبان‌های مشترک train/test: 0\n",
      "میزبان‌های train: 44316 | میزبان‌های test: 11079\n"
     ]
    }
   ],
   "source": [
    "# برش گروهی (میزبان‌ها جدا)\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "tr_idx, te_idx = next(gss.split(X2, y2, groups=groups))\n",
    "\n",
    "X_trg, X_teg = X2.iloc[tr_idx], X2.iloc[te_idx]\n",
    "y_trg, y_teg = y2.iloc[tr_idx], y2.iloc[te_idx]\n",
    "g_trg, g_teg = groups.iloc[tr_idx], groups.iloc[te_idx]\n",
    "\n",
    "clf2.fit(X_trg, y_trg)\n",
    "pred_g = clf2.predict(X_teg)\n",
    "acc_g = accuracy_score(y_teg, pred_g)\n",
    "\n",
    "shared_hosts_g = len(set(g_trg) & set(g_teg))\n",
    "print('دقت برش گروهی:', round(acc_g, 4))\n",
    "print('میزبان‌های مشترک train/test:', shared_hosts_g)\n",
    "print('میزبان‌های train:', len(set(g_trg)), '| میزبان‌های test:', len(set(g_teg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0b4fb",
   "metadata": {},
   "source": [
    "### فورنسیک نشت: هم‌پوشانی و نزدیک-به-تکراری‌ها\n",
    "\n",
    "حتی اگر شناسه موجودیت‌ها جدا باشد، نزدیک-به-تکراری‌ها می‌توانند نشت ایجاد کنند.\n",
    "\n",
    "یک کنترل ساده این است که روی چند ستون نسبتاً پایدار یک امضا (هش) بسازید و تعداد امضاهای مشترک بین train و test را بشمارید.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64517919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "امضاهای تکراری تقریبی (برش تصادفی): 556\n",
      "امضاهای تکراری تقریبی (برش گروهی) : 59\n"
     ]
    }
   ],
   "source": [
    "def overlap_count(a, b):\n",
    "    return len(set(a) & set(b))\n",
    "\n",
    "sig_cols = ['neighbourhood', 'latitude', 'longitude', 'minimum_nights']\n",
    "sig = X2[sig_cols].copy()\n",
    "sig['latitude'] = sig['latitude'].round(5)\n",
    "sig['longitude'] = sig['longitude'].round(5)\n",
    "signature = pd.util.hash_pandas_object(sig, index=False)\n",
    "\n",
    "sig_tr = signature.iloc[X_tr.index]\n",
    "sig_te = signature.iloc[X_te.index]\n",
    "dup_random = overlap_count(sig_tr, sig_te)\n",
    "\n",
    "sig_trg = signature.iloc[tr_idx]\n",
    "sig_teg = signature.iloc[te_idx]\n",
    "dup_group = overlap_count(sig_trg, sig_teg)\n",
    "\n",
    "print('امضاهای تکراری تقریبی (برش تصادفی):', dup_random)\n",
    "print('امضاهای تکراری تقریبی (برش گروهی) :', dup_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa4a58",
   "metadata": {},
   "source": [
    "### Cross-validation گروه‌محور با `GroupKFold`\n",
    "\n",
    "برای چند fold با حفظ جدایی موجودیت‌ها از `GroupKFold` استفاده کنید.\n",
    "این کار هم تخمین واریانس می‌دهد و هم وابستگی به یک برش دلخواه را کم می‌کند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69be2de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: acc=0.7404 | میزبان مشترک=0 | میزبان‌های test=11078\n",
      "Fold 2: acc=0.7416 | میزبان مشترک=0 | میزبان‌های test=11079\n",
      "Fold 3: acc=0.7348 | میزبان مشترک=0 | میزبان‌های test=11079\n",
      "Fold 4: acc=0.7481 | میزبان مشترک=0 | میزبان‌های test=11080\n",
      "Fold 5: acc=0.7515 | میزبان مشترک=0 | میزبان‌های test=11079\n",
      "میانگین دقت: 0.7432714839285025\n",
      "انحراف معیار دقت: 0.00591220648589423\n"
     ]
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "accs = []\n",
    "for fold, (tr, te) in enumerate(gkf.split(X2, y2, groups=groups), start=1):\n",
    "    clf2.fit(X2.iloc[tr], y2.iloc[tr])\n",
    "    pred = clf2.predict(X2.iloc[te])\n",
    "    acc = accuracy_score(y2.iloc[te], pred)\n",
    "    accs.append(acc)\n",
    "    shared = len(set(groups.iloc[tr]) & set(groups.iloc[te]))\n",
    "    print(f'Fold {fold}: acc={acc:.4f} | میزبان مشترک={shared} | میزبان‌های test={groups.iloc[te].nunique()}')\n",
    "\n",
    "print('میانگین دقت:', float(np.mean(accs)))\n",
    "print('انحراف معیار دقت:', float(np.std(accs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d375a25",
   "metadata": {},
   "source": [
    "## ۴) ساختار ترکیبی: زمان + موجودیت (داده‌های پنلی)\n",
    "\n",
    "بسیاری از دیتاست‌های واقعی **پنلی** هستند: اندازه‌گیری‌های تکراری برای هر موجودیت در طول زمان.\n",
    "\n",
    "در داده پنلی معمولاً باید بین دو هدف ارزیابی انتخاب کنید:\n",
    "\n",
    "- **تعمیم به موجودیت‌های دیده‌نشده**\n",
    "- **پیش‌بینی آینده برای موجودیت‌های دیده‌شده**\n",
    "\n",
    "این‌ها به برش‌های متفاوت نیاز دارند و عددهای عملکرد سؤالات متفاوتی را پاسخ می‌دهند.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc6af1",
   "metadata": {},
   "source": [
    "### مثال C: داده پنلی آموزش (`states_all.csv`)\n",
    "\n",
    "دیتاست: `states_all.csv` با ستون‌های `STATE` و `YEAR`.\n",
    "\n",
    "وظیفه: پیش‌بینی `AVG_MATH_8_SCORE` از متغیرهای درآمد/هزینه.\n",
    "\n",
    "سه برش را مقایسه می‌کنیم:\n",
    "\n",
    "1. برش تصادفی ردیف‌ها (اغلب خوش‌بینانه چون یک STATE در هر دو مجموعه می‌آید).\n",
    "2. برش گروهی بر اساس `STATE` (ارزیابی روی ایالت‌های جدید).\n",
    "3. برش زمانی درون هر STATE (پیش‌بینی سال‌های آینده همان ایالت‌ها).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddf215bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>SUPPORT_SERVICES_EXPENDITURE</th>\n",
       "      <th>OTHER_EXPENDITURE</th>\n",
       "      <th>CAPITAL_OUTLAY_EXPENDITURE</th>\n",
       "      <th>GRADES_PK_G</th>\n",
       "      <th>GRADES_KG_G</th>\n",
       "      <th>GRADES_4_G</th>\n",
       "      <th>GRADES_8_G</th>\n",
       "      <th>GRADES_12_G</th>\n",
       "      <th>GRADES_1_8_G</th>\n",
       "      <th>GRADES_9_12_G</th>\n",
       "      <th>GRADES_ALL_G</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2678885.0</td>\n",
       "      <td>304177.0</td>\n",
       "      <td>1659028.0</td>\n",
       "      <td>715680.0</td>\n",
       "      <td>2653798.0</td>\n",
       "      <td>1481703.0</td>\n",
       "      <td>735036.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174053.0</td>\n",
       "      <td>8224.0</td>\n",
       "      <td>55460.0</td>\n",
       "      <td>57948.0</td>\n",
       "      <td>58025.0</td>\n",
       "      <td>41167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>731634.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049591.0</td>\n",
       "      <td>106780.0</td>\n",
       "      <td>720711.0</td>\n",
       "      <td>222100.0</td>\n",
       "      <td>972488.0</td>\n",
       "      <td>498362.0</td>\n",
       "      <td>350902.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37451.0</td>\n",
       "      <td>2371.0</td>\n",
       "      <td>10152.0</td>\n",
       "      <td>9748.0</td>\n",
       "      <td>8789.0</td>\n",
       "      <td>6714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122487.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3258079.0</td>\n",
       "      <td>297888.0</td>\n",
       "      <td>1369815.0</td>\n",
       "      <td>1590376.0</td>\n",
       "      <td>3401580.0</td>\n",
       "      <td>1435908.0</td>\n",
       "      <td>1007732.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>609114.0</td>\n",
       "      <td>2544.0</td>\n",
       "      <td>53497.0</td>\n",
       "      <td>55433.0</td>\n",
       "      <td>49081.0</td>\n",
       "      <td>37410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>673477.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711959.0</td>\n",
       "      <td>178571.0</td>\n",
       "      <td>958785.0</td>\n",
       "      <td>574603.0</td>\n",
       "      <td>1743022.0</td>\n",
       "      <td>964323.0</td>\n",
       "      <td>483488.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145212.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>33511.0</td>\n",
       "      <td>34632.0</td>\n",
       "      <td>36011.0</td>\n",
       "      <td>27651.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441490.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26260025.0</td>\n",
       "      <td>2072470.0</td>\n",
       "      <td>16546514.0</td>\n",
       "      <td>7641041.0</td>\n",
       "      <td>27138832.0</td>\n",
       "      <td>14358922.0</td>\n",
       "      <td>8520926.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2044688.0</td>\n",
       "      <td>59067.0</td>\n",
       "      <td>431763.0</td>\n",
       "      <td>418418.0</td>\n",
       "      <td>363296.0</td>\n",
       "      <td>270675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5254844.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992     NaN      2678885.0         304177.0      1659028.0       715680.0          2653798.0                1481703.0   \n",
       "1      1992_ALASKA      ALASKA  1992     NaN      1049591.0         106780.0       720711.0       222100.0           972488.0                 498362.0   \n",
       "2     1992_ARIZONA     ARIZONA  1992     NaN      3258079.0         297888.0      1369815.0      1590376.0          3401580.0                1435908.0   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992     NaN      1711959.0         178571.0       958785.0       574603.0          1743022.0                 964323.0   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992     NaN     26260025.0        2072470.0     16546514.0      7641041.0         27138832.0               14358922.0   \n",
       "\n",
       "   SUPPORT_SERVICES_EXPENDITURE  OTHER_EXPENDITURE  CAPITAL_OUTLAY_EXPENDITURE  GRADES_PK_G  GRADES_KG_G  GRADES_4_G  GRADES_8_G  GRADES_12_G  GRADES_1_8_G  \\\n",
       "0                      735036.0                NaN                    174053.0       8224.0      55460.0     57948.0     58025.0      41167.0           NaN   \n",
       "1                      350902.0                NaN                     37451.0       2371.0      10152.0      9748.0      8789.0       6714.0           NaN   \n",
       "2                     1007732.0                NaN                    609114.0       2544.0      53497.0     55433.0     49081.0      37410.0           NaN   \n",
       "3                      483488.0                NaN                    145212.0        808.0      33511.0     34632.0     36011.0      27651.0           NaN   \n",
       "4                     8520926.0                NaN                   2044688.0      59067.0     431763.0    418418.0    363296.0     270675.0           NaN   \n",
       "\n",
       "   GRADES_9_12_G  GRADES_ALL_G  AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  AVG_READING_4_SCORE  AVG_READING_8_SCORE  \n",
       "0            NaN      731634.0             208.0             252.0                207.0                  NaN  \n",
       "1            NaN      122487.0               NaN               NaN                  NaN                  NaN  \n",
       "2            NaN      673477.0             215.0             265.0                209.0                  NaN  \n",
       "3            NaN      441490.0             210.0             256.0                211.0                  NaN  \n",
       "4            NaN     5254844.0             208.0             261.0                202.0                  NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_path = \"../../../Datasets/Regression/states_all.csv\"\n",
    "sdf = pd.read_csv(states_path, low_memory=False)\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "569465cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تعداد ردیف‌ها: 602\n",
      "تعداد ایالت‌ها: 53\n",
      "بازه سال: 1990 تا 2019\n"
     ]
    }
   ],
   "source": [
    "sdf = sdf.copy()\n",
    "sdf['YEAR'] = pd.to_numeric(sdf['YEAR'], errors='coerce')\n",
    "sdf = sdf.dropna(subset=['STATE', 'YEAR', 'AVG_MATH_8_SCORE'])\n",
    "\n",
    "target = 'AVG_MATH_8_SCORE'\n",
    "group_col = 'STATE'\n",
    "\n",
    "num_cols = [\n",
    "    'ENROLL', 'TOTAL_REVENUE', 'FEDERAL_REVENUE', 'STATE_REVENUE', 'LOCAL_REVENUE',\n",
    "    'TOTAL_EXPENDITURE', 'INSTRUCTION_EXPENDITURE', 'SUPPORT_SERVICES_EXPENDITURE', 'CAPITAL_OUTLAY_EXPENDITURE'\n",
    "]\n",
    "X4 = sdf[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "y4 = pd.to_numeric(sdf[target], errors='coerce')\n",
    "g4 = sdf[group_col].astype(str)\n",
    "t4 = sdf['YEAR'].astype(int)\n",
    "\n",
    "mask = y4.notna()\n",
    "X4, y4, g4, t4 = X4.loc[mask], y4.loc[mask], g4.loc[mask], t4.loc[mask]\n",
    "\n",
    "print('تعداد ردیف‌ها:', len(X4))\n",
    "print('تعداد ایالت‌ها:', g4.nunique())\n",
    "print('بازه سال:', int(t4.min()), 'تا', int(t4.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e29062f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Ridge())\n",
    "])\n",
    "\n",
    "def eval_regression(y_true, y_pred):\n",
    "    # RMSE بدون استفاده از پارامتر deprecated\n",
    "    rmse = mean_squared_error(y_true, y_pred) ** 0.5\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return rmse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "febfc929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "برش تصادفی | RMSE: 9.193 | R^2: 0.092\n",
      "ایالت مشترک: 48\n",
      "سال مشترک  : 12\n"
     ]
    }
   ],
   "source": [
    "# (۱) برش تصادفی ردیف‌ها\n",
    "X_tr, X_te, y_tr, y_te, g_tr, g_te, t_tr, t_te = train_test_split(\n",
    "    X4, y4, g4, t4, test_size=0.2, random_state=42\n",
    ")\n",
    "reg_pipe.fit(X_tr, y_tr)\n",
    "pred = reg_pipe.predict(X_te)\n",
    "rmse, r2 = eval_regression(y_te, pred)\n",
    "print('برش تصادفی | RMSE:', round(rmse, 3), '| R^2:', round(r2, 3))\n",
    "print('ایالت مشترک:', len(set(g_tr) & set(g_te)))\n",
    "print('سال مشترک  :', len(set(t_tr) & set(t_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b45562f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "برش گروهی (STATE) | RMSE: 9.889 | R^2: 0.164\n",
      "ایالت مشترک: 0\n"
     ]
    }
   ],
   "source": [
    "# (۲) برش گروهی بر اساس STATE (ایالت‌های جدید)\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "tr_idx, te_idx = next(gss.split(X4, y4, groups=g4))\n",
    "X_trg, X_teg = X4.iloc[tr_idx], X4.iloc[te_idx]\n",
    "y_trg, y_teg = y4.iloc[tr_idx], y4.iloc[te_idx]\n",
    "g_trg, g_teg = g4.iloc[tr_idx], g4.iloc[te_idx]\n",
    "\n",
    "reg_pipe.fit(X_trg, y_trg)\n",
    "pred = reg_pipe.predict(X_teg)\n",
    "rmse, r2 = eval_regression(y_teg, pred)\n",
    "print('برش گروهی (STATE) | RMSE:', round(rmse, 3), '| R^2:', round(r2, 3))\n",
    "print('ایالت مشترک:', len(set(g_trg) & set(g_teg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "531180fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "برش زمانی درون ایالت | RMSE: 8.322 | R^2: -0.604\n",
      "تعداد ایالت‌های دارای نقض ترتیب زمانی: 0\n"
     ]
    }
   ],
   "source": [
    "# (۳) برش زمانی درون STATE: برای هر ایالت ۲۰٪ آخر سال‌ها را test بگیرید\n",
    "sdf_work = pd.DataFrame({'state': g4.values, 'year': t4.values})\n",
    "sdf_work['idx'] = np.arange(len(sdf_work))\n",
    "\n",
    "test_mask = np.zeros(len(sdf_work), dtype=bool)\n",
    "for state, sub in sdf_work.groupby('state'):\n",
    "    years = np.sort(sub['year'].unique())\n",
    "    if len(years) < 5:\n",
    "        continue\n",
    "    cut_year = years[int(np.floor(0.8 * len(years)))]\n",
    "    sub_idx = sub.loc[sub['year'] > cut_year, 'idx'].values\n",
    "    test_mask[sub_idx] = True\n",
    "\n",
    "tr_idx = np.where(~test_mask)[0]\n",
    "te_idx = np.where(test_mask)[0]\n",
    "\n",
    "X_trt, X_tet = X4.iloc[tr_idx], X4.iloc[te_idx]\n",
    "y_trt, y_tet = y4.iloc[tr_idx], y4.iloc[te_idx]\n",
    "\n",
    "reg_pipe.fit(X_trt, y_trt)\n",
    "pred = reg_pipe.predict(X_tet)\n",
    "rmse, r2 = eval_regression(y_tet, pred)\n",
    "print('برش زمانی درون ایالت | RMSE:', round(rmse, 3), '| R^2:', round(r2, 3))\n",
    "\n",
    "violations = 0\n",
    "for state, sub in sdf_work.groupby('state'):\n",
    "    tr_years = t4.iloc[tr_idx][g4.iloc[tr_idx] == state]\n",
    "    te_years = t4.iloc[te_idx][g4.iloc[te_idx] == state]\n",
    "    if len(tr_years) and len(te_years) and tr_years.max() >= te_years.min():\n",
    "        violations += 1\n",
    "print('تعداد ایالت‌های دارای نقض ترتیب زمانی:', violations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc30b68",
   "metadata": {},
   "source": [
    "### خواندن نتایجِ برش پنلی\n",
    "\n",
    "این سه عدد به سه سؤال متفاوت پاسخ می‌دهند:\n",
    "\n",
    "- برش تصادفی: «اگر ایالت‌ها و سال‌ها را قاطی کنیم، چقدر خوب پیش‌بینی می‌کنیم؟» (اغلب خوش‌بینانه)\n",
    "- برش گروهی: «چقدر به ایالت‌های کاملاً جدید تعمیم می‌دهیم؟» (سخت‌تر)\n",
    "- برش زمانی درون ایالت: «چقدر سال‌های آینده همان ایالت‌ها را پیش‌بینی می‌کنیم؟» (شبیه استقرارِ پایش موجودیت‌های موجود)\n",
    "\n",
    "برش اشتباه می‌تواند تصمیم محصول را اشتباه کند.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8611372c",
   "metadata": {},
   "source": [
    "## ۵) بهداشت پیش‌پردازش: fit فقط روی train\n",
    "\n",
    "گام‌های پیش‌پردازش (جایگذاری، مقیاس‌بندی، کدگذاری) پارامترهایی را از داده تخمین می‌زنند.\n",
    "\n",
    "مثلاً استانداردسازی:\n",
    "\n",
    "$$\\tilde{x} = \\frac{x - \\mu}{\\sigma},\\quad \\mu = \\frac{1}{n}\\sum_{i=1}^n x_i,\\quad \\sigma^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\mu)^2.$$\n",
    "\n",
    "اگر $\\mu$ و $\\sigma$ با ردیف‌های test محاسبه شوند، آموزش به‌طور غیرمستقیم از اطلاعات test استفاده کرده است.\n",
    "پایپلاین‌ها تضمین می‌کنند تخمین پارامترها داخل برش انجام شود.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92386b2",
   "metadata": {},
   "source": [
    "### مثال D: نشت مقیاس‌بندی در دیتاست دیابت\n",
    "\n",
    "وظیفه: پیش‌بینی `classification`.\n",
    "یک الگوی نشت‌دار را با الگوی صحیح مقایسه می‌کنیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "798de50f-97f5-47af-8b4c-150c8e4cd9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>Non-Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>Non-Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  DiabetesPedigreeFunction  Age classification\n",
       "0            6      148             72             35        0  33.6                     0.627   50       Diabetic\n",
       "1            1       85             66             29        0  26.6                     0.351   31   Non-Diabetic\n",
       "2            8      183             64              0        0  23.3                     0.672   32       Diabetic\n",
       "3            1       89             66             23       94  28.1                     0.167   21   Non-Diabetic\n",
       "4            0      137             40             35      168  43.1                     2.288   33       Diabetic"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_path = \"../../../Datasets/Classification/diabetes.csv\"\n",
    "ddf = pd.read_csv(diabetes_path)\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0991d974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 576 | Test size: 192\n"
     ]
    }
   ],
   "source": [
    "ddf = ddf.copy()\n",
    "y5 = (ddf['classification'].astype(str).str.strip().str.lower() == 'diabetic').astype(int)\n",
    "X5 = ddf.drop(columns=['classification'])\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X5, y5, test_size=0.25, random_state=42, stratify=y5)\n",
    "print('Train size:', len(X_tr), '| Test size:', len(X_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6d5c76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "اندازه train: 576 | اندازه test: 192\n"
     ]
    }
   ],
   "source": [
    "ddf = pd.read_csv(diabetes_path)\n",
    "ddf = ddf.copy()\n",
    "y5 = (ddf['classification'].astype(str).str.strip().str.lower() == 'diabetic').astype(int)\n",
    "X5 = ddf.drop(columns=['classification'])\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X5, y5, test_size=0.25, random_state=42, stratify=y5)\n",
    "print('اندازه train:', len(X_tr), '| اندازه test:', len(X_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9818cdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (scaling نشت‌دار): 0.832\n"
     ]
    }
   ],
   "source": [
    "# نشت‌دار: fit روی کل داده\n",
    "scaler_bad = StandardScaler().fit(X5)\n",
    "X_tr_bad = scaler_bad.transform(X_tr)\n",
    "X_te_bad = scaler_bad.transform(X_te)\n",
    "\n",
    "m_bad = LogisticRegression(max_iter=600)\n",
    "m_bad.fit(X_tr_bad, y_tr)\n",
    "auc_bad = roc_auc_score(y_te, m_bad.predict_proba(X_te_bad)[:, 1])\n",
    "print('ROC-AUC (scaling نشت‌دار):', round(auc_bad, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea380922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (scaling صحیح): 0.832\n"
     ]
    }
   ],
   "source": [
    "# صحیح: fit فقط روی train\n",
    "scaler_ok = StandardScaler().fit(X_tr)\n",
    "X_tr_ok = scaler_ok.transform(X_tr)\n",
    "X_te_ok = scaler_ok.transform(X_te)\n",
    "\n",
    "m_ok = LogisticRegression(max_iter=600)\n",
    "m_ok.fit(X_tr_ok, y_tr)\n",
    "auc_ok = roc_auc_score(y_te, m_ok.predict_proba(X_te_ok)[:, 1])\n",
    "print('ROC-AUC (scaling صحیح):', round(auc_ok, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35ac7d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (pipeline): 0.832\n"
     ]
    }
   ],
   "source": [
    "# بهترین روش: Pipeline\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(max_iter=600))])\n",
    "pipe.fit(X_tr, y_tr)\n",
    "auc_pipe = roc_auc_score(y_te, pipe.predict_proba(X_te)[:, 1])\n",
    "print('ROC-AUC (pipeline):', round(auc_pipe, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0903c88",
   "metadata": {},
   "source": [
    "## ۶) Target encoding: جلوگیری از نشت با cross-fitting\n",
    "\n",
    "Target encoding برای دسته‌های با کاردینالیتی بالا مفید است، اما از پرخطرترین مسیرهای نشت محسوب می‌شود.\n",
    "\n",
    "Target encoding ساده:\n",
    "\n",
    "$$\\widehat{m}(c) = \\frac{1}{|\\{i : C_i=c\\}|}\\sum_{i:C_i=c} Y_i.$$\n",
    "\n",
    "اگر ردیف‌های test در $\\widehat{m}(c)$ اثر داشته باشند، ارزیابی خوش‌بینانه می‌شود.\n",
    "Cross-fitting یک encoding شبه خارج-از-نمونه برای ردیف‌های train می‌سازد.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c956d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode_crossfit(train_col: pd.Series, y: pd.Series, n_splits: int = 5, smoothing: float = 20.0, random_state: int = 42):\n",
    "    \"\"\"Cross-fitted target encoding for a single categorical column.\n",
    "    Returns: encoded_train (aligned to train_col index), enc_map (means on full train), global_mean\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    global_mean = float(y.mean())\n",
    "    enc = pd.Series(index=train_col.index, dtype=float)\n",
    "    for tr_idx, te_idx in kf.split(train_col):\n",
    "        tr_c = train_col.iloc[tr_idx]\n",
    "        tr_y = y.iloc[tr_idx]\n",
    "        stats = tr_y.groupby(tr_c).agg(['mean', 'count'])\n",
    "        smooth = (stats['count'] * stats['mean'] + smoothing * global_mean) / (stats['count'] + smoothing)\n",
    "        te_c = train_col.iloc[te_idx]\n",
    "        enc.iloc[te_idx] = te_c.map(smooth).fillna(global_mean).astype(float)\n",
    "    full_stats = y.groupby(train_col).agg(['mean', 'count'])\n",
    "    full_smooth = (full_stats['count'] * full_stats['mean'] + smoothing * global_mean) / (full_stats['count'] + smoothing)\n",
    "    return enc, full_smooth, global_mean\n",
    "\n",
    "def target_encode_apply(col: pd.Series, enc_map: pd.Series, global_mean: float):\n",
    "    return col.map(enc_map).fillna(global_mean).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "513833e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ردیف‌های train: 48000 | ردیف‌های test: 12000\n",
      "شرکت‌های یکتا در train: 1710\n"
     ]
    }
   ],
   "source": [
    "df_small = df_sorted.tail(60000).copy()\n",
    "df_small = df_small.dropna(subset=['Company', 'Timely Response'])\n",
    "y6 = (df_small['Timely Response'].astype(str).str.strip().str.lower() == 'yes').astype(int)\n",
    "X6 = df_small[['Company', 'State Name', 'Submitted via', 'Product Name']].copy()\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X6, y6, test_size=0.2, random_state=42, stratify=y6)\n",
    "print('ردیف‌های train:', len(X_tr), '| ردیف‌های test:', len(X_te))\n",
    "print('شرکت‌های یکتا در train:', X_tr['Company'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc7a706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (encoding نشت‌دار): 0.9417\n"
     ]
    }
   ],
   "source": [
    "# encoding نشت‌دار (در کار واقعی انجام ندهید)\n",
    "global_mean_all = float(pd.concat([y_tr, y_te]).mean())\n",
    "tmp = pd.DataFrame({'Company': pd.concat([X_tr['Company'], X_te['Company']]).values,\n",
    "                    'y': pd.concat([y_tr, y_te]).values})\n",
    "means_all = tmp.groupby('Company')['y'].mean()\n",
    "\n",
    "X_tr_leak = X_tr.copy(); X_te_leak = X_te.copy()\n",
    "X_tr_leak['Company_te'] = X_tr_leak['Company'].map(means_all).fillna(global_mean_all)\n",
    "X_te_leak['Company_te'] = X_te_leak['Company'].map(means_all).fillna(global_mean_all)\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    ('num', 'passthrough', ['Company_te']),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), ['State Name', 'Submitted via', 'Product Name']),\n",
    "])\n",
    "m = Pipeline([('pre', pre), ('lr', LogisticRegression(max_iter=300))])\n",
    "m.fit(X_tr_leak[['Company_te', 'State Name', 'Submitted via', 'Product Name']], y_tr)\n",
    "auc_leaky = roc_auc_score(y_te, m.predict_proba(X_te_leak[['Company_te', 'State Name', 'Submitted via', 'Product Name']])[:, 1])\n",
    "print('ROC-AUC (encoding نشت‌دار):', round(auc_leaky, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9c1cd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (encoding امن): 0.8669\n"
     ]
    }
   ],
   "source": [
    "# encoding امن با cross-fitting\n",
    "enc_tr, enc_map, gmean = target_encode_crossfit(X_tr['Company'], y_tr, n_splits=5, smoothing=50.0)\n",
    "X_tr_safe = X_tr.copy(); X_te_safe = X_te.copy()\n",
    "X_tr_safe['Company_te'] = enc_tr\n",
    "X_te_safe['Company_te'] = target_encode_apply(X_te_safe['Company'], enc_map, gmean)\n",
    "\n",
    "m2 = Pipeline([('pre', pre), ('lr', LogisticRegression(max_iter=300))])\n",
    "m2.fit(X_tr_safe[['Company_te', 'State Name', 'Submitted via', 'Product Name']], y_tr)\n",
    "auc_safe = roc_auc_score(y_te, m2.predict_proba(X_te_safe[['Company_te', 'State Name', 'Submitted via', 'Product Name']])[:, 1])\n",
    "print('ROC-AUC (encoding امن):', round(auc_safe, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3330f08d",
   "metadata": {},
   "source": [
    "## ۷) نشت اعتبارسنجی و انتخاب مدلِ صادقانه\n",
    "\n",
    "یک خطای فرایندی رایج این است که هنگام تکرارهای مدل‌سازی، مرتباً به test نگاه کنیم.\n",
    "این کار test را به validation تبدیل می‌کند و عدد نهایی خوش‌بینانه می‌شود.\n",
    "\n",
    "الگوی امن‌تر:\n",
    "\n",
    "1. یک test (زمان‌محور یا گروه‌محور) جدا کنید.\n",
    "2. روی بقیه داده‌ها، CV/validation برای جست‌وجوی هایپرپارامتر انجام دهید.\n",
    "3. مدل انتخاب‌شده را روی کل داده غیر-test fit کنید.\n",
    "4. فقط یک‌بار روی test ارزیابی کنید.\n",
    "\n",
    "در ادامه یک مثال کوچک روی دیتاست دیابت می‌بینید که در انتخاب پارامترها هرگز از برچسب‌های test استفاده نمی‌کند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63903a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بهترین AUC در CV: 0.8249\n",
      "بهترین پارامترها: {'lr__C': 0.05, 'lr__penalty': 'l2', 'lr__solver': 'lbfgs'}\n",
      "AUC روی test: 0.8301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ddf = pd.read_csv(diabetes_path)\n",
    "y7 = (ddf['classification'].astype(str).str.strip().str.lower() == 'diabetic').astype(int)\n",
    "X7 = ddf.drop(columns=['classification'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X7, y7, test_size=0.25, random_state=42, stratify=y7)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(max_iter=800))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'lr__C': [0.05, 0.1, 0.3, 1.0, 3.0, 10.0],\n",
    "    'lr__penalty': ['l2'],\n",
    "    'lr__solver': ['lbfgs'],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid=param_grid, scoring='roc_auc', cv=5, n_jobs=None)\n",
    "search.fit(X_train, y_train)\n",
    "print('بهترین AUC در CV:', round(search.best_score_, 4))\n",
    "print('بهترین پارامترها:', search.best_params_)\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "test_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "print('AUC روی test:', round(test_auc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29072a9c",
   "metadata": {},
   "source": [
    "## ۸) چک‌لیست عملی\n",
    "\n",
    "قبل از اعتماد به ارزیابی:\n",
    "\n",
    "### طراحی برش\n",
    "\n",
    "1. لحظه پیش‌بینی مشخص است.\n",
    "2. برش مطابق استقرار است:\n",
    "   - پیش‌بینی رو به آینده → برش زمانی / rolling CV\n",
    "   - موجودیت‌های جدید → برش گروهی\n",
    "   - داده پنلی → برش زمانی درون موجودیت (و شاید گَپ)\n",
    "\n",
    "### دفاع در برابر نشت\n",
    "\n",
    "3. نشت پیش‌پردازش ندارید (Pipeline).\n",
    "4. نشت هدف ندارید (حذف ویژگی‌های پس از رخداد).\n",
    "5. نشت اعتبارسنجی ندارید (test فقط یک‌بار).\n",
    "\n",
    "### فورنسیک\n",
    "\n",
    "6. هم‌پوشانی موجودیت‌ها صفر است وقتی باید باشد.\n",
    "7. هم‌پوشانی نزدیک-به-تکراری کم است.\n",
    "8. پایداری عملکرد روی foldها قابل قبول است.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0d8d0",
   "metadata": {},
   "source": [
    "## ۹) تمرین‌ها\n",
    "\n",
    "1. در دیتاست شکایات، برش زمانی ۷۰/۳۰ و ۹۰/۱۰ را هم امتحان کنید.\n",
    "2. در listings، هدف را به `availability_365 > 200` تغییر دهید و برش تصادفی را با برش میزبان‌-جدا مقایسه کنید.\n",
    "3. در دیتاست پنلی (`states_all.csv`)، به‌جای math، `AVG_READING_8_SCORE` را پیش‌بینی کنید.\n",
    "4. یک گَپ زمانی در برش پنلی اضافه کنید (مثلاً یک سال فاصله بین train و test) و اثر را ببینید.\n",
    "5. در ConsumerComplaints چند ستون پس از رخداد پیدا کنید که باید حذف شوند.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b52f61",
   "metadata": {},
   "source": [
    "### نکته کلیدی\n",
    "\n",
    "طراحی برش بخشی از مدل‌سازی است. برای عملکرد قابل اتکا باید در همان ساختار وابستگی و همان محدودیت‌های اطلاعاتی که در تولید وجود دارد، ارزیابی کنید.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
