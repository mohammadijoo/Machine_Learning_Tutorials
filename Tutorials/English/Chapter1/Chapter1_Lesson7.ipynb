{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc48f219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&display=swap');\n",
       "\n",
       "\n",
       "/* Text areas (Classic Notebook + JupyterLab) */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "div.rendered_html, .output_subarea {\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "/* RTL for rendered markdown/html content */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "h1, h2, h3, h4, h5, h6, p, strong, label, ol, ul, li {\n",
       "  line-height: 1.9;\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "h1 { font-size: 2rem; color: #070F2B; font-weight: 900}\n",
       "h2 { font-size: 1.8rem; color: #070F2B; font-weight: 800}\n",
       "h3 { font-size: 1.6rem; color: #070F2B; font-weight: 700}\n",
       "h4 { font-size: 1.4rem; color: #1E3E62; font-weight: 600}\n",
       "h5 { font-size: 1.2rem; color: #1E3E62}\n",
       "h6 { font-size: 1rem; color: #1E3E62}\n",
       "p { font-size: 1.1rem; ; font-weight: 400}\n",
       "ol, ul, li, th, td  { font-size: 1rem; }\n",
       "\n",
       "/* Keep code + outputs LTR and monospace */\n",
       ".CodeMirror, .CodeMirror *,\n",
       "pre, code,\n",
       ".jp-CodeCell .jp-InputArea, .jp-CodeCell .jp-InputArea *,\n",
       ".jp-OutputArea, .jp-OutputArea * {\n",
       "  direction: ltr !important;\n",
       "  text-align: left !important;\n",
       "  font-size: 1rem !important;\n",
       "  font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "css = Path(\"../../../css/custom.css\").read_text(encoding=\"utf-8\")\n",
    "display(HTML(f\"<style>{css}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af38db7",
   "metadata": {},
   "source": [
    "# Chapter 1 — Introduction to Machine Learning  \n",
    "## Lesson 7: Common Misconceptions and Challenges in ML\n",
    "\n",
    "### Learning objectives\n",
    "By the end of this lesson, you should be able to:\n",
    "\n",
    "1. Separate *misconceptions* (wrong mental models) from *challenges* (real constraints).\n",
    "2. Explain why seemingly “great” offline metrics frequently fail in production.\n",
    "3. Detect data leakage using concrete tests and red-flag heuristics.\n",
    "4. Choose evaluation splits and metrics that match the real deployment setting.\n",
    "5. Implement reproducible experiments (seeds, baselines, CV) and communicate uncertainty.\n",
    "\n",
    "### Why this lesson matters\n",
    "Machine learning is often presented as a linear recipe: load data → train model → deploy.  \n",
    "In practice, the majority of time is spent on **validating assumptions**:\n",
    "\n",
    "- Is the label meaningful and stable?\n",
    "- Is the data representative of the decision you will actually make?\n",
    "- Is the evaluation protocol aligned with the production environment?\n",
    "- Are you optimizing the right metric for the right cost?\n",
    "\n",
    "This lesson is intentionally “practice-driven”: we will run short experiments on several datasets to illustrate failure modes and their mitigations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b56910",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Misconceptions vs. challenges (a taxonomy)\n",
    "\n",
    "### Misconceptions (mental-model failures)\n",
    "Common examples:\n",
    "\n",
    "- **“Accuracy is enough.”** Ignores class imbalance, asymmetric costs, calibration, and decision thresholds.\n",
    "- **“More data fixes everything.”** Confuses quantity with label quality and representativeness.\n",
    "- **“A complex model is always better.”** Underestimates overfitting and operational fragility.\n",
    "- **“Feature importance proves causality.”** Confuses predictive association with causal effect.\n",
    "- **“Train/test split is a formality.”** Underestimates time, groups, duplicates, and leakage.\n",
    "\n",
    "### Challenges (reality constraints)\n",
    "Common examples:\n",
    "\n",
    "- **Label noise and ambiguity**: human labels disagree; business definitions evolve.\n",
    "- **Non-stationarity**: user behavior and policies drift over time.\n",
    "- **Sparse signals**: rare events; missing or delayed outcomes.\n",
    "- **Operational constraints**: latency, interpretability requirements, governance, privacy.\n",
    "\n",
    "A project fails when misconceptions cause you to “skip” work needed to address challenges.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Where failure happens: a risk-first view\n",
    "\n",
    "Instead of focusing on the algorithm, focus on risk:\n",
    "\n",
    "- **Measurement risk**: the label does not match what you care about.\n",
    "- **Selection risk**: training data is not representative of deployment.\n",
    "- **Evaluation risk**: your validation protocol overestimates true performance.\n",
    "- **Operational risk**: the model cannot be reliably served or monitored.\n",
    "\n",
    "A useful discipline is to articulate:\n",
    "\n",
    "- What decision will the model support?\n",
    "- What is the cost of false positives vs false negatives?\n",
    "- What data is available at decision time (and what is not)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c725f",
   "metadata": {},
   "source": [
    "\n",
    "## 3) The “offline vs online” gap\n",
    "\n",
    "Offline metrics are computed on historical data under your chosen split.  \n",
    "Production performance depends on:\n",
    "\n",
    "- What population arrives tomorrow (not what arrived last year).\n",
    "- What features are available at prediction time.\n",
    "- How humans respond to model outputs (feedback loops).\n",
    "- Whether the target is delayed or censored.\n",
    "\n",
    "This is why you should treat offline evaluation as an **estimate** with uncertainty, not as a guarantee.\n",
    "\n",
    "### A small but important formula\n",
    "For a metric $M$ measured on a test set, you should think in terms of:\n",
    "\n",
    "$$\n",
    "M_{\\text{prod}} \\approx M_{\\text{test}} - \\Delta_{\\text{shift}} - \\Delta_{\\text{leakage}} - \\Delta_{\\text{feedback}}\n",
    "$$\n",
    "\n",
    "where each $\\Delta$ term is nonnegative “degradation” caused by mismatch to production.  \n",
    "The goal is to make these deltas as small as possible by good experimental design.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Setup\n",
    "\n",
    "We will now run small experiments. Every experiment follows this discipline:\n",
    "\n",
    "1. **Define the question** (what misconception/challenge are we demonstrating?).\n",
    "2. **Choose a baseline** (dummy model or trivial rule).\n",
    "3. **Train a simple model** (often logistic/linear regression).\n",
    "4. **Inspect metrics + error structure** (confusion matrix, distribution of errors).\n",
    "5. **State the mitigation** (what you should do in real projects).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c63101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 2.1.2\n",
      "pandas: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,\n",
    "                             precision_recall_fscore_support, roc_auc_score, average_precision_score,\n",
    "                             r2_score)\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"pandas:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3fb9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: C:\\Users\\LENOVO.PIESC\\Desktop\\Machine_Learning_Tutorials\\Tutorials\\English\\Chapter1\n",
      "Example dataset exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def load_csv(rel_path: str) -> pd.DataFrame:\n",
    "    p = Path(rel_path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Expected file not found: {p.resolve()}\")\n",
    "    return pd.read_csv(p, low_memory=False)\n",
    "\n",
    "print(\"Working directory:\", Path.cwd())\n",
    "print(\"Example dataset exists:\", Path(\"../../../Datasets/Classification/diabetes.csv\").exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e68a358",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Misconception: “High accuracy means the model is good” (class imbalance + thresholds)\n",
    "\n",
    "Accuracy answers: “What fraction of predictions are correct?”  \n",
    "But decision-making usually cares about *which* errors occur.\n",
    "\n",
    "If positives are rare, predicting “negative” always can yield high accuracy.\n",
    "\n",
    "### What to look at instead\n",
    "- Confusion matrix\n",
    "- Precision/recall/F1\n",
    "- PR-AUC (Average Precision) for imbalanced problems\n",
    "- Threshold sweeps to reflect cost tradeoffs\n",
    "\n",
    "We will demonstrate this by intentionally increasing imbalance in the diabetes dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03600e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes shape: (768, 9)\n",
      " Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age classification\n",
      "           6      148             72             35        0 33.6                     0.627   50       Diabetic\n",
      "           1       85             66             29        0 26.6                     0.351   31   Non-Diabetic\n",
      "           8      183             64              0        0 23.3                     0.672   32       Diabetic\n",
      "           1       89             66             23       94 28.1                     0.167   21   Non-Diabetic\n",
      "           0      137             40             35      168 43.1                     2.288   33       Diabetic\n",
      "\n",
      "Class distribution (imbalanced):\n",
      "classification\n",
      "Non-Diabetic    500\n",
      "Diabetic         32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dummy (most frequent): accuracy=0.940, precision=0.000, recall=0.000, f1=0.000\n",
      "confusion matrix:\n",
      " [[125   0]\n",
      " [  8   0]]\n",
      "\n",
      "Logistic Regression: accuracy=0.940, precision=0.000, recall=0.000, f1=0.000\n",
      "confusion matrix:\n",
      " [[125   0]\n",
      " [  8   0]]\n",
      "ROC-AUC=0.843, PR-AUC(AP)=0.234\n",
      "\n",
      "Classification report (LogReg):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Diabetic       0.94      1.00      0.97       125\n",
      "    Diabetic       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.94       133\n",
      "   macro avg       0.47      0.50      0.48       133\n",
      "weighted avg       0.88      0.94      0.91       133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load diabetes dataset\n",
    "df = load_csv(\"../../../Datasets/Classification/diabetes.csv\")\n",
    "print(\"diabetes shape:\", df.shape)\n",
    "print(df.head(5).to_string(index=False))\n",
    "\n",
    "# Create a more imbalanced dataset: keep all Non-Diabetic, downsample Diabetic\n",
    "df_pos = df[df[\"classification\"] == \"Diabetic\"]\n",
    "df_neg = df[df[\"classification\"] == \"Non-Diabetic\"]\n",
    "\n",
    "df_pos_small = df_pos.sample(frac=0.12, random_state=RANDOM_STATE)\n",
    "df_imb = pd.concat([df_neg, df_pos_small], axis=0).sample(frac=1.0, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"\\nClass distribution (imbalanced):\")\n",
    "print(df_imb[\"classification\"].value_counts())\n",
    "\n",
    "X = df_imb.drop(columns=[\"classification\"])\n",
    "y = (df_imb[\"classification\"] == \"Diabetic\").astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Baseline: always predict majority class\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "\n",
    "# Logistic regression baseline\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "def summarize_binary(y_true, y_hat, y_score=None, name=\"model\"):\n",
    "    acc = accuracy_score(y_true, y_hat)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_hat, average=\"binary\", zero_division=0)\n",
    "    print(f\"\\n{name}: accuracy={acc:.3f}, precision={prec:.3f}, recall={rec:.3f}, f1={f1:.3f}\")\n",
    "    print(\"confusion matrix:\\n\", confusion_matrix(y_true, y_hat))\n",
    "    if y_score is not None:\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_score)\n",
    "            ap = average_precision_score(y_true, y_score)\n",
    "            print(f\"ROC-AUC={auc:.3f}, PR-AUC(AP)={ap:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(\"AUC computation issue:\", e)\n",
    "\n",
    "summarize_binary(y_test, y_pred_dummy, name=\"Dummy (most frequent)\")\n",
    "summarize_binary(y_test, y_pred, y_score=y_proba, name=\"Logistic Regression\")\n",
    "\n",
    "print(\"\\nClassification report (LogReg):\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Non-Diabetic\", \"Diabetic\"], zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df19edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " threshold  precision  recall       f1\n",
      "      0.05   0.152174   0.875 0.259259\n",
      "      0.10   0.100000   0.250 0.142857\n",
      "      0.15   0.200000   0.250 0.222222\n",
      "      0.20   0.333333   0.125 0.181818\n",
      "      0.25   0.500000   0.125 0.200000\n",
      "      0.30   0.000000   0.000 0.000000\n",
      "      0.35   0.000000   0.000 0.000000\n",
      "      0.40   0.000000   0.000 0.000000\n",
      "      0.45   0.000000   0.000 0.000000\n",
      "      0.50   0.000000   0.000 0.000000\n",
      "\n",
      "Best F1 threshold:\n",
      "threshold    0.050000\n",
      "precision    0.152174\n",
      "recall       0.875000\n",
      "f1           0.259259\n"
     ]
    }
   ],
   "source": [
    "# Threshold sweep: choosing a threshold is a cost decision\n",
    "thresholds = np.linspace(0.05, 0.95, 19)\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    y_hat = (y_proba >= t).astype(int)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_hat, average=\"binary\", zero_division=0)\n",
    "    rows.append((t, prec, rec, f1))\n",
    "tbl = pd.DataFrame(rows, columns=[\"threshold\", \"precision\", \"recall\", \"f1\"])\n",
    "\n",
    "print(tbl.head(10).to_string(index=False))\n",
    "best_f1 = tbl.iloc[tbl[\"f1\"].idxmax()]\n",
    "print(\"\\nBest F1 threshold:\")\n",
    "print(best_f1.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88b954",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Misconception: “If it fits training well, it will generalize” (overfitting)\n",
    "\n",
    "Overfitting is not a moral failure; it is a capacity–data mismatch.\n",
    "\n",
    "- When the hypothesis class is too flexible, you can fit noise.\n",
    "- In real projects, noise is unavoidable: measurement error, label noise, and unobserved confounders.\n",
    "\n",
    "A practical sign is when performance improves on train but stagnates or degrades on test as capacity increases.\n",
    "\n",
    "We will do a controlled capacity increase using polynomial features on the iris dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a357f1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris shape: (150, 5)\n",
      " sepal_length  sepal_width  petal_length  petal_width classification\n",
      "          5.4          3.7           1.5          0.2    Iris-setosa\n",
      "          4.8          3.4           1.6          0.2    Iris-setosa\n",
      "          4.8          3.0           1.4          0.1    Iris-setosa\n",
      "          4.3          3.0           1.1          0.1    Iris-setosa\n",
      "          5.8          4.0           1.2          0.2    Iris-setosa\n",
      " degree  train_accuracy  test_accuracy\n",
      "      1        0.980952       0.911111\n",
      "      2        0.980952       0.911111\n",
      "      3        0.990476       0.911111\n",
      "      4        0.990476       0.933333\n",
      "      5        1.000000       0.933333\n",
      "      6        1.000000       0.911111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20cfd7a01a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Overfitting demo on iris: increasing polynomial degree increases capacity\n",
    "iris = load_csv(\"../../../Datasets/Classification/iris.csv\")\n",
    "print(\"iris shape:\", iris.shape)\n",
    "print(iris.head(5).to_string(index=False))\n",
    "\n",
    "X = iris.drop(columns=[\"classification\"])\n",
    "y = iris[\"classification\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "degrees = [1, 2, 3, 4, 5, 6]\n",
    "results = []\n",
    "for d in degrees:\n",
    "    clf = Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=d, include_bias=False)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(max_iter=2000, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_acc = clf.score(X_train, y_train)\n",
    "    test_acc = clf.score(X_test, y_test)\n",
    "    results.append((d, train_acc, test_acc))\n",
    "\n",
    "res = pd.DataFrame(results, columns=[\"degree\", \"train_accuracy\", \"test_accuracy\"])\n",
    "print(res.to_string(index=False))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(res[\"degree\"], res[\"train_accuracy\"], marker=\"o\", label=\"train\")\n",
    "plt.plot(res[\"degree\"], res[\"test_accuracy\"], marker=\"o\", label=\"test\")\n",
    "plt.xlabel(\"Polynomial degree\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Overfitting pattern: train vs test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ba4c9",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Challenge: Data leakage (silent failure)\n",
    "\n",
    "Leakage is “silent” because it often produces *beautiful* validation results.\n",
    "\n",
    "### A leak is any feature you cannot compute at prediction time\n",
    "Examples:\n",
    "- Using “days since last payment” when last payment is recorded after the decision.\n",
    "- Aggregations computed across all users including the test users.\n",
    "- Target encoding without proper fold discipline.\n",
    "- Features that are proxies for labeling process rather than phenomenon.\n",
    "\n",
    "We will intentionally create a leaky feature in a house price regression example and show how it inflates $R^2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb02e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house-prices shape: (128, 8)\n",
      " Home  Price  SqFt  Bedrooms  Bathrooms  Offers Brick Neighborhood\n",
      "    1 114300  1790         2          2       2    No         East\n",
      "    2 114200  2030         4          2       3    No         East\n",
      "    3 114800  1740         3          2       1    No         East\n",
      "    4  94700  1980         3          2       3    No         East\n",
      "    5 119800  2130         3          3       3    No         East\n",
      "R2 with leakage (unrealistically high): 0.9997196501119279\n",
      "R2 without leakage (more realistic): 0.8412648590928408\n"
     ]
    }
   ],
   "source": [
    "# Leakage demo on house prices\n",
    "hp = load_csv(\"../../../Datasets/Regression/house-prices.csv\")\n",
    "print(\"house-prices shape:\", hp.shape)\n",
    "print(hp.head(5).to_string(index=False))\n",
    "\n",
    "y = hp[\"Price\"].values\n",
    "X = hp.drop(columns=[\"Price\"])\n",
    "\n",
    "# Add a leaky feature: almost the target (this simulates post-outcome information)\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "X_leaky = X.copy()\n",
    "X_leaky[\"Price_leak\"] = y + rng.normal(0, 500, size=len(y))\n",
    "\n",
    "cat_cols = [\"Brick\", \"Neighborhood\"]\n",
    "num_cols = [c for c in X_leaky.columns if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "])\n",
    "\n",
    "linreg = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "# Stratification for regression via quantile bins\n",
    "bins = pd.qcut(y, q=5, labels=False, duplicates=\"drop\")\n",
    "\n",
    "scores_leak = []\n",
    "for tr, te in StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE).split(X_leaky, bins):\n",
    "    linreg.fit(X_leaky.iloc[tr], y[tr])\n",
    "    pred = linreg.predict(X_leaky.iloc[te])\n",
    "    scores_leak.append(r2_score(y[te], pred))\n",
    "print(\"R2 with leakage (unrealistically high):\", float(np.mean(scores_leak)))\n",
    "\n",
    "# Fix: remove leaky feature\n",
    "X_clean = X.copy()\n",
    "num_cols_clean = [c for c in X_clean.columns if c not in cat_cols]\n",
    "\n",
    "preprocess_clean = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols_clean),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "])\n",
    "\n",
    "linreg_clean = Pipeline([\n",
    "    (\"prep\", preprocess_clean),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "scores_clean = []\n",
    "for tr, te in StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE).split(X_clean, bins):\n",
    "    linreg_clean.fit(X_clean.iloc[tr], y[tr])\n",
    "    pred = linreg_clean.predict(X_clean.iloc[te])\n",
    "    scores_clean.append(r2_score(y[te], pred))\n",
    "print(\"R2 without leakage (more realistic):\", float(np.mean(scores_clean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d91b81",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Misconception: “More data is always better” (quality, missingness, and label readiness)\n",
    "\n",
    "Large datasets can be low-signal because:\n",
    "- the useful field is mostly missing,\n",
    "- labels are inconsistent,\n",
    "- narratives are short, vague, or boilerplate,\n",
    "- data is collected for compliance, not prediction.\n",
    "\n",
    "We will quantify missingness and text length on Consumer Complaints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "287e498b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConsumerComplaints shape: (65499, 18)\n",
      "Date Received            Product Name      Sub Product                                   Issue Sub Issue Consumer Complaint Narrative Company Public Response               Company State Name Zip Code           Tags Consumer Consent Provided Submitted via Date Sent to Company Company Response to Consumer Timely Response Consumer Disputed  Complaint ID\n",
      "   2013-07-29           Consumer Loan     Vehicle loan              Managing the loan or lease       NaN                          NaN                     NaN Wells Fargo & Company         VA    24540            NaN                       NaN         Phone           2013-07-30      Closed with explanation             Yes                No        468882\n",
      "   2013-07-29 Bank account or service Checking account               Using a debit or ATM card       NaN                          NaN                     NaN Wells Fargo & Company         CA    95992 Older American                       NaN           Web           2013-07-31      Closed with explanation             Yes                No        468889\n",
      "   2013-07-29 Bank account or service Checking account Account opening, closing, or management       NaN                          NaN                     NaN     Santander Bank US         NY    10065            NaN                       NaN           Fax           2013-07-31                       Closed             Yes                No        468879\n",
      "\n",
      "Top missingness rates (%):\n",
      "Company Public Response         96.3\n",
      "Consumer Complaint Narrative    96.0\n",
      "Consumer Consent Provided       92.7\n",
      "Tags                            85.2\n",
      "Sub Issue                       53.2\n",
      "Sub Product                     28.3\n",
      "Consumer Disputed                1.7\n",
      "Zip Code                         0.7\n",
      "State Name                       0.7\n",
      "Date Received                    0.0\n",
      "\n",
      "Narrative missing (%): 96.0\n",
      "\n",
      "Narrative length summary (including missing as 0):\n",
      "count    65499.000000\n",
      "mean        42.178003\n",
      "std        274.377627\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max       3988.000000\n"
     ]
    }
   ],
   "source": [
    "# Data quality / missingness audit on Consumer Complaints\n",
    "cc = load_csv(\"../../../Datasets/Clustering/ConsumerComplaints.csv\")\n",
    "print(\"ConsumerComplaints shape:\", cc.shape)\n",
    "print(cc.head(3).to_string(index=False))\n",
    "\n",
    "cc2 = cc.replace({\"\": np.nan})\n",
    "missing_rate = (cc2.isna().mean().sort_values(ascending=False) * 100).round(1)\n",
    "\n",
    "print(\"\\nTop missingness rates (%):\")\n",
    "print(missing_rate.head(10).to_string())\n",
    "\n",
    "narr_col = \"Consumer Complaint Narrative\"\n",
    "print(\"\\nNarrative missing (%):\", float(missing_rate.loc[narr_col]))\n",
    "\n",
    "lengths = cc[narr_col].fillna(\"\").astype(str).str.len()\n",
    "print(\"\\nNarrative length summary (including missing as 0):\")\n",
    "print(lengths.describe().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046806d",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Challenge: Distribution shift (covariate shift demonstration)\n",
    "\n",
    "A random split assumes i.i.d. sampling, but deployment rarely is i.i.d.\n",
    "\n",
    "A “shifted” evaluation is often more realistic:\n",
    "- time-based split,\n",
    "- geography-based split,\n",
    "- product-version split,\n",
    "- user-cohort split.\n",
    "\n",
    "We simulate a covariate shift by training on lower alcohol wines and testing on higher alcohol wines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c50d1018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine shape: (4898, 12)\n",
      " fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  density   pH  sulphates  alcohol  quality\n",
      "           7.0              0.27         0.36            20.7      0.045                 45.0                 170.0   1.0010 3.00       0.45      8.8        6\n",
      "           6.3              0.30         0.34             1.6      0.049                 14.0                 132.0   0.9940 3.30       0.49      9.5        6\n",
      "           8.1              0.28         0.40             6.9      0.050                 30.0                  97.0   0.9951 3.26       0.44     10.1        6\n",
      "           7.2              0.23         0.32             8.5      0.058                 47.0                 186.0   0.9956 3.19       0.40      9.9        6\n",
      "           7.2              0.23         0.32             8.5      0.058                 47.0                 186.0   0.9956 3.19       0.40      9.9        6\n",
      "Train on low alcohol (<= 10.40), test on high alcohol (> 10.40)\n",
      "Accuracy=0.641, PR-AUC(AP)=0.359\n",
      "Confusion matrix:\n",
      " [[1485    2]\n",
      " [ 833    5]]\n",
      "\n",
      "Random i.i.d split baseline:\n",
      "Accuracy=0.807, PR-AUC(AP)=0.531\n"
     ]
    }
   ],
   "source": [
    "# Distribution shift demo with wine quality\n",
    "wine = load_csv(\"../../../Datasets/Classification/Wine_Quality.csv\")\n",
    "print(\"Wine shape:\", wine.shape)\n",
    "print(wine.head(5).to_string(index=False))\n",
    "\n",
    "wine[\"good\"] = (wine[\"quality\"] >= 7).astype(int)\n",
    "\n",
    "threshold = wine[\"alcohol\"].median()\n",
    "train_df = wine[wine[\"alcohol\"] <= threshold].copy()\n",
    "test_df  = wine[wine[\"alcohol\"] > threshold].copy()\n",
    "\n",
    "X_train = train_df.drop(columns=[\"quality\",\"good\"])\n",
    "y_train = train_df[\"good\"].values\n",
    "X_test  = test_df.drop(columns=[\"quality\",\"good\"])\n",
    "y_test  = test_df[\"good\"].values\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LogisticRegression(max_iter=2000, random_state=RANDOM_STATE))\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "ap = average_precision_score(y_test, proba)\n",
    "print(f\"Train on low alcohol (<= {threshold:.2f}), test on high alcohol (> {threshold:.2f})\")\n",
    "print(f\"Accuracy={acc:.3f}, PR-AUC(AP)={ap:.3f}\")\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, pred))\n",
    "\n",
    "# i.i.d. baseline\n",
    "X = wine.drop(columns=[\"quality\",\"good\"])\n",
    "y = wine[\"good\"].values\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y)\n",
    "clf.fit(Xtr, ytr)\n",
    "proba_iid = clf.predict_proba(Xte)[:, 1]\n",
    "pred_iid = (proba_iid >= 0.5).astype(int)\n",
    "acc_iid = accuracy_score(yte, pred_iid)\n",
    "ap_iid = average_precision_score(yte, proba_iid)\n",
    "print(\"\\nRandom i.i.d split baseline:\")\n",
    "print(f\"Accuracy={acc_iid:.3f}, PR-AUC(AP)={ap_iid:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cab137",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Misconception: “Feature importance tells the truth” (instability + correlation)\n",
    "\n",
    "Feature importance is model- and data-dependent.\n",
    "\n",
    "Even if your model is stable, correlated features can make importance unstable.  \n",
    "Tree ensembles also have randomness, which can change rankings.\n",
    "\n",
    "We will train multiple Random Forest models on the glass dataset and quantify how importances vary with random seed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "530f392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glass shape: (214, 10)\n",
      "     RI    Na   Mg   Al    Si    K   Ca  Ba  Fe                             Type\n",
      "1.52101 13.64 4.49 1.10 71.78 0.06 8.75 0.0 0.0 building_windows_float_processed\n",
      "1.51761 13.89 3.60 1.36 72.73 0.48 7.83 0.0 0.0 building_windows_float_processed\n",
      "1.51618 13.53 3.55 1.54 72.99 0.39 7.78 0.0 0.0 building_windows_float_processed\n",
      "1.51766 13.21 3.69 1.29 72.61 0.57 8.22 0.0 0.0 building_windows_float_processed\n",
      "1.51742 13.27 3.62 1.24 73.08 0.55 8.07 0.0 0.0 building_windows_float_processed\n",
      "\n",
      "Top features by mean importance (with std across seeds):\n",
      "    mean_importance  std_importance\n",
      "Mg         0.166897        0.004999\n",
      "Al         0.160251        0.008483\n",
      "RI         0.152071        0.005103\n",
      "Ca         0.128896        0.004476\n",
      "Ba         0.096759        0.006783\n",
      "Na         0.096607        0.006973\n",
      "K          0.082079        0.004214\n",
      "Si         0.077482        0.003725\n",
      "\n",
      "Top-1 feature frequency across seeds:\n",
      "Mg    8\n",
      "Al    2\n"
     ]
    }
   ],
   "source": [
    "# Feature importance instability demo (Random Forest) on glass\n",
    "glass = load_csv(\"../../../Datasets/Classification/glass.csv\")\n",
    "print(\"glass shape:\", glass.shape)\n",
    "print(glass.head(5).to_string(index=False))\n",
    "\n",
    "X = glass.drop(columns=[\"Type\"])\n",
    "y = glass[\"Type\"]\n",
    "\n",
    "seeds = list(range(10))\n",
    "importances = []\n",
    "for s in seeds:\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=120,\n",
    "        random_state=s,\n",
    "        n_jobs=1,\n",
    "        min_samples_leaf=2\n",
    "    )\n",
    "    rf.fit(X, y)\n",
    "    importances.append(rf.feature_importances_)\n",
    "\n",
    "imp = pd.DataFrame(importances, columns=X.columns)\n",
    "summary = pd.DataFrame({\n",
    "    \"mean_importance\": imp.mean(),\n",
    "    \"std_importance\": imp.std()\n",
    "}).sort_values(\"mean_importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop features by mean importance (with std across seeds):\")\n",
    "print(summary.head(8).to_string())\n",
    "\n",
    "top1 = imp.idxmax(axis=1).value_counts()\n",
    "print(\"\\nTop-1 feature frequency across seeds:\")\n",
    "print(top1.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accce66b",
   "metadata": {},
   "source": [
    "\n",
    "## 11) Challenge: Reproducibility (variance across splits and the value of CV)\n",
    "\n",
    "Small differences in random split can produce nontrivial differences in metrics.\n",
    "\n",
    "Mitigations:\n",
    "- Fix seeds\n",
    "- Use cross-validation for stable estimates\n",
    "- Report uncertainty (mean ± std)\n",
    "- Track experiments (data version + code version + parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72683ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five runs WITHOUT fixed split seed (accuracy, AP):\n",
      " run 1: acc=0.734, AP=0.712\n",
      " run 2: acc=0.766, AP=0.714\n",
      " run 3: acc=0.812, AP=0.760\n",
      " run 4: acc=0.766, AP=0.731\n",
      " run 5: acc=0.776, AP=0.740\n",
      "\n",
      "Three runs WITH fixed split seed=123:\n",
      " run 1: acc=0.781, AP=0.759\n",
      " run 2: acc=0.781, AP=0.759\n",
      " run 3: acc=0.781, AP=0.759\n",
      "\n",
      "5-fold CV average precision scores:\n",
      "[0.692 0.765 0.742 0.73  0.687]\n",
      "mean AP: 0.7232096366815528 std: 0.029608538088360357\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility demo: split variance vs fixed seed + CV\n",
    "df = load_csv(\"../../../Datasets/Classification/diabetes.csv\")\n",
    "X = df.drop(columns=[\"classification\"])\n",
    "y = (df[\"classification\"] == \"Diabetic\").astype(int).values\n",
    "\n",
    "def eval_once(split_seed=None):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, random_state=split_seed, stratify=y)\n",
    "    clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    clf.fit(Xtr, ytr)\n",
    "    proba = clf.predict_proba(Xte)[:, 1]\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "    return accuracy_score(yte, pred), average_precision_score(yte, proba)\n",
    "\n",
    "scores = [eval_once(split_seed=None) for _ in range(5)]\n",
    "print(\"Five runs WITHOUT fixed split seed (accuracy, AP):\")\n",
    "for i, (acc, ap) in enumerate(scores, 1):\n",
    "    print(f\" run {i}: acc={acc:.3f}, AP={ap:.3f}\")\n",
    "\n",
    "scores_fixed = [eval_once(split_seed=123) for _ in range(3)]\n",
    "print(\"\\nThree runs WITH fixed split seed=123:\")\n",
    "for i, (acc, ap) in enumerate(scores_fixed, 1):\n",
    "    print(f\" run {i}: acc={acc:.3f}, AP={ap:.3f}\")\n",
    "\n",
    "clf = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                (\"lr\", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "ap_scores = cross_val_score(clf, X, y, cv=cv, scoring=\"average_precision\")\n",
    "print(\"\\n5-fold CV average precision scores:\")\n",
    "print(np.round(ap_scores, 3))\n",
    "print(\"mean AP:\", float(np.mean(ap_scores)), \"std:\", float(np.std(ap_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932044aa",
   "metadata": {},
   "source": [
    "\n",
    "## 12) Communication challenge: setting expectations\n",
    "\n",
    "Many stakeholder misunderstandings are predictable. A few useful statements:\n",
    "\n",
    "- **“The model is a statistical estimate, not a guarantee.”**\n",
    "- **“Offline accuracy is not the same as production impact.”**\n",
    "- **“We need to validate that features are available at decision time.”**\n",
    "- **“We can trade off false positives and false negatives by adjusting thresholds.”**\n",
    "\n",
    "### A practical template for reporting results\n",
    "When reporting a model, include:\n",
    "\n",
    "1. Dataset description (time range, population, exclusions)\n",
    "2. Split strategy (random/time/group) and why\n",
    "3. Baselines (dummy + simple model)\n",
    "4. Metric suite (primary + secondary + calibration if relevant)\n",
    "5. Error analysis (where the model fails)\n",
    "6. Known risks and monitoring plan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ddb0a",
   "metadata": {},
   "source": [
    "\n",
    "## 13) Practical checklist (use this before trusting results)\n",
    "\n",
    "### Data checks\n",
    "- Are labels defined consistently and audited?\n",
    "- Are duplicates or near-duplicates crossing splits?\n",
    "- Do any features contain post-outcome information?\n",
    "- Is missingness correlated with the target?\n",
    "\n",
    "### Split checks\n",
    "- Should the split be time-based?\n",
    "- Should the split be group/entity-based?\n",
    "- Are you accidentally leaking future info?\n",
    "\n",
    "### Metric checks\n",
    "- Does the metric match business cost?\n",
    "- Do you inspect confusion matrices and PR curves?\n",
    "- Do you evaluate calibration if probabilities are used?\n",
    "\n",
    "### Baselines\n",
    "- Dummy model (most frequent / mean)\n",
    "- Simple linear/logistic model\n",
    "- Business rule baseline (if applicable)\n",
    "\n",
    "### Robustness and shift\n",
    "- Does performance hold across subgroups?\n",
    "- Does it degrade under plausible shift?\n",
    "\n",
    "### Reproducibility\n",
    "- Fixed seeds, recorded environment versions\n",
    "- Cross-validation\n",
    "- Saved artifacts (trained model, preprocessing)\n",
    "\n",
    "---\n",
    "\n",
    "## 14) Exercises (recommended)\n",
    "1. On diabetes, find a threshold that achieves recall ≥ 0.80 with the highest possible precision.\n",
    "2. On house prices, compare linear regression to a tree model and discuss bias/variance and interpretability.\n",
    "3. On wine, change the shift definition (e.g., split by density) and repeat.\n",
    "4. On glass, increase the number of trees and observe whether importance becomes more stable.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
