{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e717c18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap');\n",
       "@import url('https://cdnjs.cloudflare.com/ajax/libs/shabnam-font/5.0.1/font-face.css');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Amiri:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Mirza:wght@400;700&display=swap');\n",
       "\n",
       "\n",
       "\n",
       "/* Text areas (Classic Notebook + JupyterLab) */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "div.rendered_html, .output_subarea {\n",
       "  font-family: \"Vazirmatn\", \"Shabnam\", \"Mirza\", \"Amiri\", Tahoma, \"Segoe UI\", sans-serif !important;\n",
       "}\n",
       "\n",
       "/* RTL for rendered markdown/html content */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "h1, h2, h3, h4, h5, h6, p, strong, label, ol, ul, li {\n",
       "  direction: rtl !important;\n",
       "  text-align: right !important;\n",
       "  line-height: 1.9;\n",
       "  font-family: \"Vazirmatn\", \"Shabnam\", \"Mirza\", \"Amiri\", Tahoma, \"Segoe UI\", sans-serif !important;\n",
       "}\n",
       "\n",
       "h1 { font-size: 2rem; color: #070F2B; font-weight: 900}\n",
       "h2 { font-size: 1.8rem; color: #070F2B; font-weight: 800}\n",
       "h3 { font-size: 1.6rem; color: #070F2B; font-weight: 700}\n",
       "h4 { font-size: 1.4rem; color: #1E3E62; font-weight: 600}\n",
       "h5 { font-size: 1.2rem; color: #1E3E62}\n",
       "h6 { font-size: 1rem; color: #1E3E62}\n",
       "p { font-size: 1.1rem; ; font-weight: 400}\n",
       "ol, ul, li, th, td  { font-size: 1rem; }\n",
       "\n",
       "/* Keep code + outputs LTR and monospace */\n",
       ".CodeMirror, .CodeMirror *,\n",
       "pre, code,\n",
       ".jp-CodeCell .jp-InputArea, .jp-CodeCell .jp-InputArea *,\n",
       ".jp-OutputArea, .jp-OutputArea * {\n",
       "  direction: ltr !important;\n",
       "  text-align: left !important;\n",
       "  font-size: 1rem !important;\n",
       "  font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "css = Path(\"../../../css/rtl.css\").read_text(encoding=\"utf-8\")\n",
    "display(HTML(f\"<style>{css}</style>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e1c25a",
   "metadata": {},
   "source": [
    "# فصل ۲ — مبانی داده و پیش‌پردازش\n",
    "## درس ۴: مقیاس‌بندی ویژگی‌ها (نرمال‌سازی و استانداردسازی)\n",
    "\n",
    "### در این درس چه چیزهایی یاد می‌گیرید؟\n",
    "\n",
    "در پایان این نوت‌بوک می‌توانید:\n",
    "\n",
    "- توضیح دهید *چرا* مقیاس‌بندی ویژگی‌ها مهم است و *چه زمانی* اهمیت چندانی ندارد.\n",
    "- بین **استانداردسازی** (مقیاس z-score) و **نرمال‌سازی** (مقیاس min–max) و همچنین **نرمال‌سازی برداری** (یکه‌سازی طول بردار برای هر نمونه) تفاوت قائل شوید.\n",
    "- برای هر الگوریتم، اسکیلر مناسب را انتخاب کنید (kNN / SVM / رگرسیون لجستیک / PCA / k-means / مدل‌های خطی با منظم‌سازی).\n",
    "- مقیاس‌بندی را به‌درستی و **بدون نشت داده (data leakage)** با استفاده از `Pipeline` و `ColumnTransformer` پیاده‌سازی کنید.\n",
    "- مشکلات رایج مقیاس‌بندی را تشخیص دهید: داده‌های پرت، دُم‌های سنگین، ماتریس‌های تنک (sparse)، و انواع داده‌ی ترکیبی.\n",
    "- اسکیلر را مثل یک **هایپرپارامتر** ببینید و با cross-validation / grid search اعتبارسنجی کنید.\n",
    "- تصمیم‌های مربوط به مقیاس‌بندی را در چارچوب یک روند قابل بازتولید در ML مستندسازی کنید.\n",
    "\n",
    "---\n",
    "\n",
    "### چرا این موضوع برای سطح پیشرفته (Band 8–9) مهم است؟\n",
    "\n",
    "در سطح بالا، «Feature Scaling» یک کار مکانیکی نیست؛ یک *تصمیم مدل‌سازی* است که روی موارد زیر اثر می‌گذارد:\n",
    "\n",
    "- **هندسه‌ی بهینه‌سازی** (Conditioning مسئله و اندازه‌ی گام‌ها در گرادیان‌کاهشی).\n",
    "- **معنای منظم‌سازی** (جریمه‌های L1/L2 بدون کنترل مقیاس بین ویژگی‌ها قابل مقایسه نیستند).\n",
    "- **فاصله و شباهت** (kNN، k-means، روش‌های کرنلی، فاصله‌ی کسینوسی).\n",
    "- **پایداری عددی** (دامنه‌ی اعداد شناور؛ ویژگی‌های بد‌مقیاس می‌توانند باعث underflow/overflow یا ماتریس بدشرط شوند).\n",
    "- **تفسیرپذیری و حاکمیت مدل** (اگر یکی از ویژگی‌ها دلار باشد و دیگری میلی‌متر، ضریب مدل چه مفهومی دارد؟)\n",
    "\n",
    "در این درس یاد می‌گیرید مقیاس‌بندی را به‌عنوان بخشی از خط لوله‌ی مدل‌سازی ببینید، نه یک ترفند جداگانه.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa5a29a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions:\n",
      "  python: 3.13.0\n",
      "  sklearn: 1.5.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "pd.set_option(\"display.max_columns\", 60)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "print(\"Versions:\")\n",
    "import sklearn, sys\n",
    "print(\"  python:\", sys.version.split()[0])\n",
    "print(\"  sklearn:\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35db9677",
   "metadata": {},
   "source": [
    "\n",
    "## ۱) مفاهیم پایه و نمادگذاری\n",
    "\n",
    "فرض کنید داده‌ای با $n$ نمونه و $p$ ویژگی داریم. بردار ویژگی برای نمونه‌ی $i$ را به‌شکل زیر می‌نویسیم:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_i = [x_{i1}, x_{i2}, \\dots, x_{ip}]\n",
    "$$\n",
    "\n",
    "دو عملیات مقیاس‌بندی که دائماً با آن‌ها سروکار دارید:\n",
    "\n",
    "### استانداردسازی (مقیاس z-score)\n",
    "\n",
    "برای ویژگی $j$:\n",
    "\n",
    "$$\n",
    "z_{ij} = \\frac{x_{ij} - \\mu_j}{\\sigma_j}\n",
    "$$\n",
    "\n",
    "- $\\mu_j$ میانگین ویژگی $j$ است (فقط بر اساس داده‌ی **آموزش** محاسبه می‌شود).\n",
    "- $\\sigma_j$ انحراف معیار ویژگی $j$ است (فقط بر اساس داده‌ی **آموزش** محاسبه می‌شود).\n",
    "\n",
    "### نرمال‌سازی min–max\n",
    "\n",
    "برای ویژگی $j$:\n",
    "\n",
    "$$\n",
    "x'_{ij} = \\frac{x_{ij} - \\min_j}{\\max_j - \\min_j}\n",
    "$$\n",
    "\n",
    "این کار هر ویژگی را (تقریباً) به بازه‌ی $[0, 1]$ نگاشت می‌کند.\n",
    "\n",
    "### نرمال‌سازی برداری (یکه‌سازی طول بردار برای هر نمونه)\n",
    "\n",
    "در این روش، کل بردار ویژگی یک نمونه نرمال می‌شود:\n",
    "\n",
    "$$\n",
    "\\tilde{\\mathbf{x}}_i = \\frac{\\mathbf{x}_i}{\\lVert \\mathbf{x}_i \\rVert_2}\n",
    "$$\n",
    "\n",
    "این روش در بازیابی متن / شباهت کسینوسی رایج است و با min–max تفاوت دارد.\n",
    "\n",
    "---\n",
    "\n",
    "## ۲) چه زمانی مقیاس‌بندی مهم است (و چه زمانی نیست)\n",
    "\n",
    "مقیاس‌بندی زمانی مهم است که الگوریتم شما از موارد زیر استفاده کند:\n",
    "\n",
    "- **فاصله‌ها یا ضرب داخلی**: kNN، k-means، SVM (به‌ویژه کرنل RBF)، PCA، Kernel Ridge.\n",
    "- **جریمه‌های منظم‌سازی** که فرض می‌کنند مقیاس ضرایب قابل مقایسه است: Lasso، Ridge، Elastic Net.\n",
    "- **بهینه‌سازی مختصات‌به‌مختصات** که اندازه‌ی گام‌ها به مقیاس ویژگی وابسته است.\n",
    "\n",
    "مقیاس‌بندی معمولاً برای موارد زیر ضروری نیست:\n",
    "\n",
    "- **مدل‌های مبتنی بر درخت**: درخت تصمیم، جنگل تصادفی، گرادیان بوستینگ درختی  \n",
    "  (تقسیم‌ها بر اساس ترتیب هستند؛ مقیاس ترتیب را تغییر نمی‌دهد).\n",
    "- برخی سامانه‌های **قاعده‌محور** یا **شمارشی** که ویژگی‌ها از ابتدا هم‌مقیاس هستند.\n",
    "\n",
    "با این حال، «ضروری نبودن» به معنای «هرگز مفید نبودن» نیست. مدل‌های درختی ممکن است به‌طور غیرمستقیم سود ببرند (مثلاً وقتی PCA یا سایر گام‌های قبلی به مقیاس حساس‌اند).\n",
    "\n",
    "---\n",
    "\n",
    "### شهود هندسی (غلبه‌ی یک ویژگی بر فاصله)\n",
    "\n",
    "فاصله‌ی اقلیدسی را در نظر بگیرید:\n",
    "\n",
    "$$\n",
    "d(\\mathbf{x}, \\mathbf{y}) = \\sqrt{\\sum_{j=1}^{p} (x_j - y_j)^2}\n",
    "$$\n",
    "\n",
    "اگر یک ویژگی در بازه‌ی $[0, 10^6]$ و دیگری در بازه‌ی $[0, 1]$ باشد، ویژگی بزرگ‌دامنه تقریباً همیشه *بر فاصله غالب می‌شود*؛ حتی اگر اطلاعات چندانی نداشته باشد. مقیاس‌بندی در عمل یعنی تعریف این‌که «فاصله» برای مسئله‌ی شما چه معنایی دارد.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c5f01c",
   "metadata": {},
   "source": [
    "\n",
    "## ۳) چند دیتاست را بارگذاری می‌کنیم (و مقیاس ویژگی‌ها را می‌بینیم)\n",
    "\n",
    "در پروژه‌های واقعی، مقیاس‌بندی معمولاً «یک دیتاست، یک اسکیلر» نیست. اغلب یک سیاست قابل استفاده‌ی مجدد تعریف می‌کنید و سپس آن را روی منابع داده‌ی مختلف اعتبارسنجی می‌کنید.\n",
    "\n",
    "در این نوت‌بوک از چند دیتاست موجود در ریپوی شما استفاده می‌کنیم:\n",
    "\n",
    "- `diabetes.csv` (طبقه‌بندی دودویی؛ ویژگی‌های عددی با دامنه‌های متفاوت)\n",
    "- `iris.csv` (طبقه‌بندی چندکلاسه؛ نمونه‌ی کلاسیک برای روش‌های مبتنی بر فاصله)\n",
    "- `Wine_Quality.csv` (داده‌ی جدولی؛ برای سادگی کیفیت را دودویی می‌کنیم)\n",
    "- `drug200.csv` (ترکیبی از عددی و دسته‌ای؛ برای نمایش Pipeline ستونی)\n",
    "- `hw_200.csv` (خوشه‌بندی؛ برای نمایش اثر مقیاس‌بندی بر k-means و PCA)\n",
    "\n",
    "ابتدا دامنه‌ی خام ویژگی‌های عددی را بررسی می‌کنیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b5d275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shapes:\n",
      "  diabetes: (768, 9)\n",
      "  iris: (150, 5)\n",
      "  wine: (4898, 12)\n",
      "  drug: (200, 6)\n",
      "  hw_raw: (200, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>Non-Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>Non-Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  DiabetesPedigreeFunction  Age classification\n",
       "0            6      148             72             35        0  33.6                     0.627   50       Diabetic\n",
       "1            1       85             66             29        0  26.6                     0.351   31   Non-Diabetic\n",
       "2            8      183             64              0        0  23.3                     0.672   32       Diabetic\n",
       "3            1       89             66             23       94  28.1                     0.167   21   Non-Diabetic\n",
       "4            0      137             40             35      168  43.1                     2.288   33       Diabetic"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Paths are relative to: Tutorials/English/Chapter2 or Tutorials/Persian/Chapter2\n",
    "p_diabetes = Path(\"../../../Datasets/Classification/diabetes.csv\")\n",
    "p_iris     = Path(\"../../../Datasets/Classification/iris.csv\")\n",
    "p_wine     = Path(\"../../../Datasets/Classification/Wine_Quality.csv\")\n",
    "p_drug     = Path(\"../../../Datasets/Classification/drug200.csv\")\n",
    "p_hw       = Path(\"../../../Datasets/Clustering/hw_200.csv\")\n",
    "\n",
    "diabetes = pd.read_csv(p_diabetes)\n",
    "iris = pd.read_csv(p_iris)\n",
    "wine = pd.read_csv(p_wine)\n",
    "drug = pd.read_csv(p_drug)\n",
    "hw_raw = pd.read_csv(p_hw)\n",
    "\n",
    "print(\"Loaded shapes:\")\n",
    "print(\"  diabetes:\", diabetes.shape)\n",
    "print(\"  iris:\", iris.shape)\n",
    "print(\"  wine:\", wine.shape)\n",
    "print(\"  drug:\", drug.shape)\n",
    "print(\"  hw_raw:\", hw_raw.shape)\n",
    "\n",
    "display(diabetes.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea3e0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "diabetes: numeric scale summary (top by range)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>range</th>\n",
       "      <th>range_ratio_to_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>0.000</td>\n",
       "      <td>846.00</td>\n",
       "      <td>79.7995</td>\n",
       "      <td>115.1689</td>\n",
       "      <td>846.000</td>\n",
       "      <td>10.1866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.000</td>\n",
       "      <td>199.00</td>\n",
       "      <td>120.8945</td>\n",
       "      <td>31.9518</td>\n",
       "      <td>199.000</td>\n",
       "      <td>2.3961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>0.000</td>\n",
       "      <td>122.00</td>\n",
       "      <td>69.1055</td>\n",
       "      <td>19.3432</td>\n",
       "      <td>122.000</td>\n",
       "      <td>1.4690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>0.000</td>\n",
       "      <td>99.00</td>\n",
       "      <td>20.5365</td>\n",
       "      <td>15.9418</td>\n",
       "      <td>99.000</td>\n",
       "      <td>1.1921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.000</td>\n",
       "      <td>67.10</td>\n",
       "      <td>31.9926</td>\n",
       "      <td>7.8790</td>\n",
       "      <td>67.100</td>\n",
       "      <td>0.8079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>21.000</td>\n",
       "      <td>81.00</td>\n",
       "      <td>33.2409</td>\n",
       "      <td>11.7526</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.7225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>0.000</td>\n",
       "      <td>17.00</td>\n",
       "      <td>3.8451</td>\n",
       "      <td>3.3674</td>\n",
       "      <td>17.000</td>\n",
       "      <td>0.2047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>0.078</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.3311</td>\n",
       "      <td>2.342</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             min     max      mean       std    range  range_ratio_to_median\n",
       "Insulin                    0.000  846.00   79.7995  115.1689  846.000                10.1866\n",
       "Glucose                    0.000  199.00  120.8945   31.9518  199.000                 2.3961\n",
       "BloodPressure              0.000  122.00   69.1055   19.3432  122.000                 1.4690\n",
       "SkinThickness              0.000   99.00   20.5365   15.9418   99.000                 1.1921\n",
       "BMI                        0.000   67.10   31.9926    7.8790   67.100                 0.8079\n",
       "Age                       21.000   81.00   33.2409   11.7526   60.000                 0.7225\n",
       "Pregnancies                0.000   17.00    3.8451    3.3674   17.000                 0.2047\n",
       "DiabetesPedigreeFunction   0.078    2.42    0.4719    0.3311    2.342                 0.0282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iris: numeric scale summary (top by range)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>range</th>\n",
       "      <th>range_ratio_to_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>petal_length</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.7587</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.9667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal_length</th>\n",
       "      <td>4.3</td>\n",
       "      <td>7.9</td>\n",
       "      <td>5.8433</td>\n",
       "      <td>0.8253</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal_width</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0540</td>\n",
       "      <td>0.4321</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal_width</th>\n",
       "      <td>0.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.1987</td>\n",
       "      <td>0.7606</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              min  max    mean     std  range  range_ratio_to_median\n",
       "petal_length  1.0  6.9  3.7587  1.7585    5.9                 1.9667\n",
       "sepal_length  4.3  7.9  5.8433  0.8253    3.6                 1.2000\n",
       "sepal_width   2.0  4.4  3.0540  0.4321    2.4                 0.8000\n",
       "petal_width   0.1  2.5  1.1987  0.7606    2.4                 0.8000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "wine: numeric scale summary (top by range)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>range</th>\n",
       "      <th>range_ratio_to_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <td>9.00</td>\n",
       "      <td>440.00</td>\n",
       "      <td>138.3607</td>\n",
       "      <td>42.4937</td>\n",
       "      <td>431.00</td>\n",
       "      <td>112.5326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <td>2.00</td>\n",
       "      <td>289.00</td>\n",
       "      <td>35.3081</td>\n",
       "      <td>17.0054</td>\n",
       "      <td>287.00</td>\n",
       "      <td>74.9347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual sugar</th>\n",
       "      <td>0.60</td>\n",
       "      <td>65.80</td>\n",
       "      <td>6.3914</td>\n",
       "      <td>5.0715</td>\n",
       "      <td>65.20</td>\n",
       "      <td>17.0235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed acidity</th>\n",
       "      <td>3.80</td>\n",
       "      <td>14.20</td>\n",
       "      <td>6.8548</td>\n",
       "      <td>0.8438</td>\n",
       "      <td>10.40</td>\n",
       "      <td>2.7154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>8.00</td>\n",
       "      <td>14.20</td>\n",
       "      <td>10.5143</td>\n",
       "      <td>1.2305</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1.6188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>3.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>5.8779</td>\n",
       "      <td>0.8855</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.5666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric acid</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.3342</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.4334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>2.72</td>\n",
       "      <td>3.82</td>\n",
       "      <td>3.1883</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.2872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile acidity</th>\n",
       "      <td>0.08</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.2782</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>0.22</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.4898</td>\n",
       "      <td>0.1141</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.2245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       min     max      mean      std   range  range_ratio_to_median\n",
       "total sulfur dioxide  9.00  440.00  138.3607  42.4937  431.00               112.5326\n",
       "free sulfur dioxide   2.00  289.00   35.3081  17.0054  287.00                74.9347\n",
       "residual sugar        0.60   65.80    6.3914   5.0715   65.20                17.0235\n",
       "fixed acidity         3.80   14.20    6.8548   0.8438   10.40                 2.7154\n",
       "alcohol               8.00   14.20   10.5143   1.2305    6.20                 1.6188\n",
       "quality               3.00    9.00    5.8779   0.8855    6.00                 1.5666\n",
       "citric acid           0.00    1.66    0.3342   0.1210    1.66                 0.4334\n",
       "pH                    2.72    3.82    3.1883   0.1510    1.10                 0.2872\n",
       "volatile acidity      0.08    1.10    0.2782   0.1008    1.02                 0.2663\n",
       "sulphates             0.22    1.08    0.4898   0.1141    0.86                 0.2245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def scale_summary(df: pd.DataFrame, name: str, max_cols: int = 10):\n",
    "    num = df.select_dtypes(include=[np.number])\n",
    "    if num.empty:\n",
    "        print(f\"{name}: no numeric columns\")\n",
    "        return\n",
    "    s = pd.DataFrame({\n",
    "        \"min\": num.min(),\n",
    "        \"max\": num.max(),\n",
    "        \"mean\": num.mean(),\n",
    "        \"std\": num.std(ddof=0),\n",
    "    })\n",
    "    s[\"range\"] = s[\"max\"] - s[\"min\"]\n",
    "    s[\"range_ratio_to_median\"] = s[\"range\"] / (np.median(s[\"range\"]) + 1e-12)\n",
    "    s = s.sort_values(\"range\", ascending=False)\n",
    "    print(f\"\\n{name}: numeric scale summary (top by range)\")\n",
    "    display(s.head(max_cols).round(4))\n",
    "\n",
    "scale_summary(diabetes, \"diabetes\")\n",
    "scale_summary(iris, \"iris\")\n",
    "scale_summary(wine, \"wine\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d55c7",
   "metadata": {},
   "source": [
    "\n",
    "### تفسیر\n",
    "\n",
    "حتی اگر همه‌ی ستون‌ها «عددی» به نظر برسند، مقیاس‌ها یکسان نیستند:\n",
    "\n",
    "- در `diabetes`، ویژگی‌های **Insulin** و **Glucose** در دامنه‌ای بسیار بزرگ‌تر از **DiabetesPedigreeFunction** قرار دارند.\n",
    "- در `wine`، برخی شاخص‌های شیمیایی پراکندگی‌های بسیار متفاوتی دارند (مثلاً sulphates در برابر free sulfur dioxide).\n",
    "- در `iris` دامنه‌ها متوسط است، اما مقیاس‌بندی همچنان می‌تواند هندسه‌ی همسایگی را تغییر دهد.\n",
    "\n",
    "از همین‌جا تصمیم‌گیری درباره‌ی مقیاس‌بندی شروع می‌شود.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3998a8",
   "metadata": {},
   "source": [
    "\n",
    "## ۴) استانداردسازی در عمل (z-score) — و این‌که چرا به بهینه‌سازی کمک می‌کند\n",
    "\n",
    "بسیاری از الگوریتم‌ها در عمل یک مسئله‌ی بهینه‌سازی را حل می‌کنند. برای مثال، رگرسیون لجستیک (با منظم‌سازی L2) می‌تواند این‌گونه نوشته شود:\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{w}, b} \\; \\frac{1}{n}\\sum_{i=1}^n \\log\\left(1 + \\exp\\left(-y_i(\\mathbf{w}^\\top \\mathbf{x}_i + b)\\right)\\right) + \\lambda \\lVert \\mathbf{w} \\rVert_2^2\n",
    "$$\n",
    "\n",
    "اگر یک ویژگی ۱۰۰۰ برابر بزرگ‌تر از دیگری باشد، سطح تابع هزینه **بدشرط (ill-conditioned)** می‌شود؛ در نتیجه بهینه‌ساز ممکن است در یک جهت گام‌های بسیار کوچک و در جهت دیگر گام‌های بزرگ نیاز داشته باشد. استانداردسازی مسئله را به حالتی نزدیک‌تر به «کروی» می‌برد و رفتار همگرایی را بهبود می‌دهد.\n",
    "\n",
    "### مثال: رگرسیون لجستیک روی دیتاست diabetes\n",
    "\n",
    "مقایسه می‌کنیم:\n",
    "\n",
    "- مدل A: رگرسیون لجستیک **بدون** مقیاس‌بندی\n",
    "- مدل B: رگرسیون لجستیک با `StandardScaler` داخل یک `Pipeline`\n",
    "\n",
    "ارزیابی را روی یک تقسیم آموزش/آزمون انجام می‌دهیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbcaa78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Diabetic', 'Non-Diabetic']\n",
      "\n",
      "Accuracy (no scaling): 0.7812\n",
      "Accuracy (standardized): 0.7865\n",
      "\n",
      "Confusion matrix (no scaling):\n",
      " [[ 39  28]\n",
      " [ 14 111]]\n",
      "\n",
      "Confusion matrix (standardized):\n",
      " [[ 40  27]\n",
      " [ 14 111]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy (no scaling): 0.4933\n",
      "Accuracy (standardized): 0.5\n",
      "\n",
      "Confusion matrix (no scaling):\n",
      " [[59 23]\n",
      " [53 15]]\n",
      "\n",
      "Confusion matrix (standardized):\n",
      " [[63 19]\n",
      " [56 12]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = diabetes.drop(columns=[\"classification\"])\n",
    "y = diabetes[\"classification\"].copy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_bin = le.fit_transform(y)\n",
    "print(\"Classes:\", list(le.classes_))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_bin, test_size=0.25, random_state=42, stratify=y_bin\n",
    ")\n",
    "\n",
    "# A) No scaling\n",
    "lr_raw = LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
    "lr_raw.fit(X_train, y_train)\n",
    "pred_raw = lr_raw.predict(X_test)\n",
    "\n",
    "# B) With standardization\n",
    "lr_scaled = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "])\n",
    "lr_scaled.fit(X_train, y_train)\n",
    "pred_scaled = lr_scaled.predict(X_test)\n",
    "\n",
    "print(\"\\nAccuracy (no scaling):\", round(accuracy_score(y_test, pred_raw), 4))\n",
    "print(\"Accuracy (standardized):\", round(accuracy_score(y_test, pred_scaled), 4))\n",
    "\n",
    "print(\"\\nConfusion matrix (no scaling):\\n\", confusion_matrix(y_test, pred_raw))\n",
    "print(\"\\nConfusion matrix (standardized):\\n\", confusion_matrix(y_test, pred_scaled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8763e99",
   "metadata": {},
   "source": [
    "\n",
    "### ضرایب و تفسیرپذیری: مقیاس‌بندی معنای ضرایب را تغییر می‌دهد\n",
    "\n",
    "اگر یک مدل خطی را *بدون* مقیاس‌بندی برازش کنید، اندازه‌ی ضرایب به واحد اندازه‌گیری ویژگی‌ها وابسته می‌شود.\n",
    "\n",
    "استانداردسازی ضرایب را قابل مقایسه‌تر می‌کند؛ یعنی «اثر به ازای یک انحراف معیار» که در بسیاری از کاربردها به شهود *اهمیت نسبی* نزدیک‌تر است.\n",
    "\n",
    "بیایید ضرایب مدل استانداردشده را ببینیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fed6f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef (standardized)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>-1.1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>-0.6716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>-0.4667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>0.3129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>-0.2806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>0.1773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.1613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>-0.1089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          coef (standardized)\n",
       "Glucose                               -1.1240\n",
       "BMI                                   -0.6716\n",
       "Pregnancies                           -0.4667\n",
       "BloodPressure                          0.3129\n",
       "DiabetesPedigreeFunction              -0.2806\n",
       "Insulin                                0.1773\n",
       "Age                                   -0.1613\n",
       "SkinThickness                         -0.1089"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpretation: coefficients after StandardScaler are roughly 'effect per 1 std' of the feature.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "coef = lr_scaled.named_steps[\"clf\"].coef_.ravel()\n",
    "coef_s = pd.Series(coef, index=feature_names).sort_values(key=lambda s: np.abs(s), ascending=False)\n",
    "\n",
    "display(coef_s.to_frame(\"coef (standardized)\").head(10).round(4))\n",
    "print(\"Interpretation: coefficients after StandardScaler are roughly 'effect per 1 std' of the feature.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f59e79",
   "metadata": {},
   "source": [
    "\n",
    "## ۵) نرمال‌سازی min–max در برابر استانداردسازی — ملاحظات عملی\n",
    "\n",
    "### چه زمانی min–max مفید است؟\n",
    "\n",
    "مقیاس min–max رایج است وقتی:\n",
    "\n",
    "- می‌خواهید ویژگی‌ها در بازه‌ی محدود $[0, 1]$ قرار بگیرند.\n",
    "- مدل یا قیود/پیش‌فرض‌ها انتظار ورودی‌های محدود دارند.\n",
    "- می‌خواهید فاصله‌های نسبی حفظ شود اما دامنه کنترل گردد.\n",
    "\n",
    "### چه زمانی استانداردسازی مقاوم‌تر است؟\n",
    "\n",
    "استانداردسازی معمولاً بهتر کار می‌کند وقتی:\n",
    "\n",
    "- ویژگی‌ها تقریباً زنگوله‌ای‌اند یا می‌خواهید با آن‌ها چنین برخورد کنید.\n",
    "- از مدل‌های خطی منظم‌سازی‌شده، SVM یا PCA استفاده می‌کنید.\n",
    "- مرکز کردن حول صفر اهمیت دارد.\n",
    "\n",
    "### هشدار مهم (داده‌های پرت)\n",
    "\n",
    "min–max به داده‌های پرت حساس است: یک مقدار بسیار بزرگ/کوچک می‌تواند کل ویژگی را در بازه‌ای بسیار فشرده قرار دهد. در داده‌های دُم‌سنگین، RobustScaler اغلب انتخاب بهتری است.\n",
    "\n",
    "---\n",
    "\n",
    "## ۶) نمایش عملی: kNN روی دیتاست Iris (بدون مقیاس‌بندی vs min–max vs استانداردسازی)\n",
    "\n",
    "kNN یک روش مبتنی بر فاصله است. اگر یک ویژگی دامنه‌ی بزرگ‌تری داشته باشد، به‌طور ضمنی وزن بیشتری می‌گیرد.\n",
    "\n",
    "مقایسه می‌کنیم:\n",
    "\n",
    "- kNN روی ویژگی‌های خام\n",
    "- kNN با `MinMaxScaler`\n",
    "- kNN با `StandardScaler`\n",
    "\n",
    "برای جلوگیری از نشت داده، مقیاس‌بندی را داخل `Pipeline` قرار می‌دهیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bcedba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     raw  accuracy = 0.9474\n",
      "  minmax  accuracy = 0.9737\n",
      "standard  accuracy = 0.9474\n",
      "\n",
      "A short classification report for the standardized pipeline:\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        12\n",
      "Iris-versicolor       0.87      1.00      0.93        13\n",
      " Iris-virginica       1.00      0.85      0.92        13\n",
      "\n",
      "       accuracy                           0.95        38\n",
      "      macro avg       0.96      0.95      0.95        38\n",
      "   weighted avg       0.95      0.95      0.95        38\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  minmax  accuracy = 0.9737\n",
      "standard  accuracy = 0.9474\n",
      "\n",
      "A short classification report for the standardized pipeline:\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        12\n",
      "Iris-versicolor       0.87      1.00      0.93        13\n",
      " Iris-virginica       1.00      0.85      0.92        13\n",
      "\n",
      "       accuracy                           0.95        38\n",
      "      macro avg       0.96      0.95      0.95        38\n",
      "   weighted avg       0.95      0.95      0.95        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = iris.drop(columns=[\"classification\"])\n",
    "y = iris[\"classification\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "pipelines = {\n",
    "    \"raw\": Pipeline([(\"knn\", KNeighborsClassifier(n_neighbors=7))]),\n",
    "    \"minmax\": Pipeline([(\"scaler\", MinMaxScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=7))]),\n",
    "    \"standard\": Pipeline([(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=7))]),\n",
    "}\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    print(f\"{name:>8}  accuracy = {acc:.4f}\")\n",
    "\n",
    "print(\"\\nA short classification report for the standardized pipeline:\\n\")\n",
    "pred_std = pipelines[\"standard\"].predict(X_test)\n",
    "print(classification_report(y_test, pred_std))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a597d6a",
   "metadata": {},
   "source": [
    "\n",
    "### بحث (kNN)\n",
    "\n",
    "در عمل، عملکرد kNN بعد از مقیاس‌بندی می‌تواند تغییر معناداری داشته باشد؛ اما توجه کنید:\n",
    "\n",
    "- «بهترین اسکیلر» به $k$، معیار فاصله، و دیتاست وابسته است.\n",
    "- هدف مقیاس‌بندی این نیست که *همیشه* نتیجه را بهتر کند؛ هدف این است که الگوریتم مطابق تعریف مورد انتظار رفتار کند.\n",
    "- روند درست این است که اسکیلر را مانند یک هایپرپارامتر در نظر بگیرید و اعتبارسنجی کنید.\n",
    "\n",
    "بیایید این ایده را با cross-validation نشان دهیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "636b5dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     raw  mean=0.9600  std=0.0389  scores=[1.     0.9667 0.9    1.     0.9333]\n",
      "  minmax  mean=0.9533  std=0.0452  scores=[1.     0.9667 0.9    1.     0.9   ]\n",
      "standard  mean=0.9600  std=0.0327  scores=[0.9667 0.9667 0.9    1.     0.9667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  minmax  mean=0.9533  std=0.0452  scores=[1.     0.9667 0.9    1.     0.9   ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard  mean=0.9600  std=0.0327  scores=[0.9667 0.9667 0.9    1.     0.9667]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"accuracy\")\n",
    "    print(f\"{name:>8}  mean={scores.mean():.4f}  std={scores.std():.4f}  scores={np.round(scores,4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac35cf",
   "metadata": {},
   "source": [
    "\n",
    "## ۷) داده‌های پرت و دُم‌های سنگین: RobustScaler، PowerTransformer، QuantileTransformer\n",
    "\n",
    "داده‌های واقعی معمولاً «تمیز و نرمال» نیستند. داده‌های پرت می‌توانند انحراف معیار را ناپایدار کنند و min–max را هم خراب کنند. چند گزینه‌ی مقاوم وجود دارد:\n",
    "\n",
    "### RobustScaler\n",
    "از میانه و دامنه‌ی بین‌چارکی (IQR) استفاده می‌کند:\n",
    "\n",
    "$$\n",
    "x' = \\frac{x - \\text{median}(x)}{\\text{IQR}(x)}\n",
    "$$\n",
    "\n",
    "### PowerTransformer (Yeo–Johnson / Box–Cox)\n",
    "داده را طوری تبدیل می‌کند که بیشتر شبیه توزیع نرمال شود و گاهی رفتار مدل‌های خطی را بهتر می‌کند.\n",
    "\n",
    "### QuantileTransformer\n",
    "بر اساس کوانتایل‌ها داده را به یک توزیع هدف (یکنواخت یا نرمال) نگاشت می‌کند. می‌تواند مفید باشد، اما ممکن است فاصله‌ها را تغییر شکل دهد؛ بنابراین باید با اعتبارسنجی همراه باشد.\n",
    "\n",
    "نمایش را با دیتاست wine انجام می‌دهیم که برخی ویژگی‌ها می‌توانند چولگی داشته باشند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cf39d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             raw  accuracy=0.8090  positive_rate_train=0.216\n",
      "        standard  accuracy=0.8073  positive_rate_train=0.216\n",
      "          robust  accuracy=0.8024  positive_rate_train=0.216\n",
      "power_yeojohnson  accuracy=0.8049  positive_rate_train=0.216\n",
      " quantile_normal  accuracy=0.8049  positive_rate_train=0.216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        standard  accuracy=0.7367  positive_rate_train=0.266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          robust  accuracy=0.7367  positive_rate_train=0.266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power_yeojohnson  accuracy=0.7367  positive_rate_train=0.266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " quantile_normal  accuracy=0.7367  positive_rate_train=0.266\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wine_y = (wine[\"quality\"] >= 7).astype(int)\n",
    "wine_X = wine.drop(columns=[\"quality\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    wine_X, wine_y, test_size=0.25, random_state=42, stratify=wine_y\n",
    ")\n",
    "\n",
    "scaler_pipes = {\n",
    "    \"raw\": Pipeline([(\"clf\", LogisticRegression(max_iter=4000))]),\n",
    "    \"standard\": Pipeline([(\"scaler\", StandardScaler()), (\"clf\", LogisticRegression(max_iter=4000))]),\n",
    "    \"robust\": Pipeline([(\"scaler\", RobustScaler()), (\"clf\", LogisticRegression(max_iter=4000))]),\n",
    "    \"power_yeojohnson\": Pipeline([(\"scaler\", PowerTransformer(method=\"yeo-johnson\", standardize=True)), (\"clf\", LogisticRegression(max_iter=4000))]),\n",
    "    \"quantile_normal\": Pipeline([(\"scaler\", QuantileTransformer(output_distribution=\"normal\", n_quantiles=200, random_state=42)), (\"clf\", LogisticRegression(max_iter=4000))]),\n",
    "}\n",
    "\n",
    "for name, pipe in scaler_pipes.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    print(f\"{name:>16}  accuracy={acc:.4f}  positive_rate_train={y_train.mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a2faf",
   "metadata": {},
   "source": [
    "\n",
    "### نتیجه‌گیری (robust / power / quantile)\n",
    "\n",
    "- RobustScaler زمانی که داده‌های پرت وجود دارند یک انتخاب پیش‌فرض بسیار خوب است.\n",
    "- تبدیل‌های توان (Power) وقتی چولگی زیاد است می‌توانند مفید باشند.\n",
    "- QuantileTransformer گاهی عملکرد بسیار خوبی می‌دهد، اما چون ساختار فاصله‌ها را تغییر می‌دهد باید با cross-validation بررسی شود.\n",
    "\n",
    "---\n",
    "\n",
    "## ۸) مقیاس‌بندی و SVM: چرا هایپرپارامترهای «C» و «gamma» به مقیاس وابسته‌اند؟\n",
    "\n",
    "برای SVM با کرنل RBF داریم:\n",
    "\n",
    "$$\n",
    "K(\\mathbf{x}, \\mathbf{y}) = \\exp(-\\gamma \\lVert \\mathbf{x} - \\mathbf{y} \\rVert_2^2)\n",
    "$$\n",
    "\n",
    "اگر ویژگی‌ها را مقیاس‌بندی کنید، فاصله‌ها تغییر می‌کنند و بنابراین معنای «موثر» $\\gamma$ نیز تغییر می‌کند.\n",
    "\n",
    "به همین دلیل **SVM تقریباً همیشه با مقیاس‌بندی استفاده می‌شود** و جست‌وجوی هایپرپارامتر باید با مقیاس‌بندی داخل pipeline انجام شود.\n",
    "\n",
    "این موضوع را روی `iris` نشان می‌دهیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41f0e2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (no scaling) accuracy: 0.9737\n",
      "SVM (standardized) accuracy: 0.9474\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = iris.drop(columns=[\"classification\"])\n",
    "y = iris[\"classification\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "svm_raw = SVC(kernel=\"rbf\", C=3.0, gamma=\"scale\")\n",
    "svm_scaled = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(kernel=\"rbf\", C=3.0, gamma=\"scale\"))\n",
    "])\n",
    "\n",
    "svm_raw.fit(X_train, y_train)\n",
    "svm_scaled.fit(X_train, y_train)\n",
    "\n",
    "pred_raw = svm_raw.predict(X_test)\n",
    "pred_scaled = svm_scaled.predict(X_test)\n",
    "\n",
    "print(\"SVM (no scaling) accuracy:\", round(accuracy_score(y_test, pred_raw), 4))\n",
    "print(\"SVM (standardized) accuracy:\", round(accuracy_score(y_test, pred_scaled), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5eb1e7",
   "metadata": {},
   "source": [
    "\n",
    "## ۹) نشت داده (Data Leakage): رایج‌ترین اشتباه در مقیاس‌بندی\n",
    "\n",
    "**Leakage** زمانی رخ می‌دهد که اطلاعات مجموعه‌ی آزمون به‌نوعی وارد فرآیند آموزش شود.\n",
    "\n",
    "یک نشت ظریف در مقیاس‌بندی این‌گونه است:\n",
    "\n",
    "1. `StandardScaler` را روی *کل داده* fit کنید\n",
    "2. روی train و test transform انجام دهید\n",
    "3. ارزیابی کنید\n",
    "\n",
    "این کار اشتباه است؛ چون میانگین و انحراف معیار اسکیلر از داده‌ی آزمون هم اطلاع گرفته است.\n",
    "\n",
    "تفاوت را بین:\n",
    "\n",
    "- مقیاس‌بندی غلط (fit روی کل داده)\n",
    "- مقیاس‌بندی درست (fit فقط روی train) با `Pipeline`\n",
    "\n",
    "نشان می‌دهیم. مثال را دوباره روی دیتاست diabetes انجام می‌دهیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7357132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with leakage (wrong): 0.7865\n",
      "Accuracy without leakage (right): 0.7865\n",
      "\n",
      "Correct scaler mean (first 3 features): [  3.856 121.705  69.559]\n",
      "Correct scaler var  (first 3 features): [  11.991 1056.913  356.729]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = diabetes.drop(columns=[\"classification\"])\n",
    "y = le.fit_transform(diabetes[\"classification\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# WRONG: fit scaler on all data, then split transformed data\n",
    "scaler_wrong = StandardScaler()\n",
    "X_all_scaled = scaler_wrong.fit_transform(X)\n",
    "\n",
    "Xa_train, Xa_test, ya_train, ya_test = train_test_split(\n",
    "    X_all_scaled, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "lr_wrong = LogisticRegression(max_iter=2000)\n",
    "lr_wrong.fit(Xa_train, ya_train)\n",
    "pred_wrong = lr_wrong.predict(Xa_test)\n",
    "acc_wrong = accuracy_score(ya_test, pred_wrong)\n",
    "\n",
    "# RIGHT: scaler inside pipeline fitted on training only\n",
    "lr_right = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "lr_right.fit(X_train, y_train)\n",
    "pred_right = lr_right.predict(X_test)\n",
    "acc_right = accuracy_score(y_test, pred_right)\n",
    "\n",
    "print(\"Accuracy with leakage (wrong):\", round(acc_wrong, 4))\n",
    "print(\"Accuracy without leakage (right):\", round(acc_right, 4))\n",
    "\n",
    "# Additional sanity check: show that correct scaler stats come ONLY from training\n",
    "sc = lr_right.named_steps[\"scaler\"]\n",
    "print(\"\\nCorrect scaler mean (first 3 features):\", np.round(sc.mean_[:3], 3))\n",
    "print(\"Correct scaler var  (first 3 features):\", np.round(sc.var_[:3], 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db8ec4",
   "metadata": {},
   "source": [
    "\n",
    "### قانون حرفه‌ای (غیرقابل مذاکره)\n",
    "\n",
    "اگر قرار است مقیاس‌بندی انجام شود، باید **داخل** فرآیند آموزش fit شود:\n",
    "\n",
    "- از `Pipeline` استفاده کنید و با cross-validation اعتبارسنجی کنید.\n",
    "- در محیط عملیاتی (production)، اسکیلر fit‌شده را همراه مدل ذخیره کنید.\n",
    "\n",
    "---\n",
    "\n",
    "## ۱۰) انواع داده‌ی ترکیبی: مقیاس‌بندی عددی، کدگذاری دسته‌ای (مثال drug200)\n",
    "\n",
    "در ML جدولی معمولاً داریم:\n",
    "\n",
    "- ویژگی‌های عددی که به مقیاس‌بندی نیاز دارند (مثل `Age` و `Na_to_K`)\n",
    "- ویژگی‌های دسته‌ای که به کدگذاری نیاز دارند (`Sex`، `BP`، `Cholesterol`)\n",
    "\n",
    "رویکرد درست این است که یک pipeline **ستون‌به‌ستون** بسازید:\n",
    "\n",
    "- عددی: `SimpleImputer` → `StandardScaler`\n",
    "- دسته‌ای: `SimpleImputer` → `OneHotEncoder`\n",
    "- مدل: یک طبقه‌بند (مثلاً رگرسیون لجستیک)\n",
    "\n",
    "در این مثال برچسب `Drug` چندکلاسه است.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43917f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "\n",
      "Class distribution (test):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DrugY</th>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugX</th>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugA</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugC</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugB</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       share\n",
       "Drug        \n",
       "DrugY   0.46\n",
       "drugX   0.26\n",
       "drugA   0.12\n",
       "drugC   0.08\n",
       "drugB   0.08"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       DrugY       0.88      0.96      0.92        23\n",
      "       drugA       1.00      1.00      1.00         6\n",
      "       drugB       1.00      0.50      0.67         4\n",
      "       drugC       1.00      1.00      1.00         4\n",
      "       drugX       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.92        50\n",
      "   macro avg       0.96      0.88      0.90        50\n",
      "weighted avg       0.92      0.92      0.92        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = drug.drop(columns=[\"Drug\"])\n",
    "y = drug[\"Drug\"]\n",
    "\n",
    "numeric_features = [\"Age\", \"Na_to_K\"]\n",
    "categorical_features = [\"Sex\", \"BP\", \"Cholesterol\"]\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, numeric_features),\n",
    "        (\"cat\", categorical_pipe, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(max_iter=4000)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", clf)\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, pred), 4))\n",
    "print(\"\\nClass distribution (test):\")\n",
    "display(pd.Series(y_test).value_counts(normalize=True).to_frame(\"share\").round(3))\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a00d8c",
   "metadata": {},
   "source": [
    "\n",
    "## ۱۱) ماتریس‌های تنک و مقیاس‌بندی: StandardScaler در برابر MaxAbsScaler\n",
    "\n",
    "کدگذاری One-Hot معمولاً یک ماتریس طراحی تنک (sparse) ایجاد می‌کند. دو نکته‌ی مهم:\n",
    "\n",
    "- `StandardScaler(with_mean=True)` را نمی‌توان مستقیم روی ماتریس تنک اعمال کرد (چون مرکز کردن باعث densify شدن می‌شود).\n",
    "- برای ویژگی‌های تنک، گزینه‌های بهتر:\n",
    "  - `StandardScaler(with_mean=False)` (تنکی حفظ می‌شود)، یا\n",
    "  - `MaxAbsScaler` (بر اساس بیشینه‌ی قدر مطلق مقیاس می‌کند و sparsity را حفظ می‌کند).\n",
    "\n",
    "در این بخش یک ماتریس «عمدتاً تنک» با one-hot می‌سازیم و اسکیلرها را مقایسه می‌کنیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1062ff7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed shape: (120, 7)\n",
      "Sparse output: False\n",
      "Sparsity (nnz / total): 360 / 840\n",
      "\n",
      "StandardScaler(with_mean=True) succeeded (likely dense input).\n",
      "\n",
      "After StandardScaler(with_mean=False):\n",
      "  is_sparse: False\n",
      "\n",
      "After MaxAbsScaler:\n",
      "  is_sparse: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler(with_mean=True) succeeded (likely dense input).\n",
      "\n",
      "After StandardScaler(with_mean=False):\n",
      "  is_sparse: False\n",
      "\n",
      "After MaxAbsScaler:\n",
      "  is_sparse: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy import sparse\n",
    "\n",
    "toy = drug.sample(120, random_state=0).reset_index(drop=True)\n",
    "X = toy.drop(columns=[\"Drug\"])\n",
    "\n",
    "# Force sparse output for compatibility across scikit-learn versions\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
    "\n",
    "pre_cat_only = ColumnTransformer(\n",
    "    transformers=[(\"cat\", ohe, [\"Sex\",\"BP\",\"Cholesterol\"])],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_sparse = pre_cat_only.fit_transform(X)\n",
    "\n",
    "is_sp = sparse.issparse(X_sparse)\n",
    "nnz = X_sparse.nnz if is_sp else int(np.count_nonzero(X_sparse))\n",
    "total = int(X_sparse.shape[0] * X_sparse.shape[1])\n",
    "\n",
    "print(\"Transformed shape:\", X_sparse.shape)\n",
    "print(\"Sparse output:\", is_sp)\n",
    "print(\"Sparsity (nnz / total):\", nnz, \"/\", total)\n",
    "\n",
    "# Demonstrate why centering is problematic for sparse matrices\n",
    "try:\n",
    "    _ = StandardScaler(with_mean=True).fit_transform(X_sparse)\n",
    "    print(\"\\nStandardScaler(with_mean=True) succeeded (likely dense input).\")\n",
    "except Exception as e:\n",
    "    print(\"\\nStandardScaler(with_mean=True) on sparse -> error type:\", type(e).__name__)\n",
    "    print(\"Message (short):\", str(e).splitlines()[0][:140])\n",
    "\n",
    "X_std_no_mean = StandardScaler(with_mean=False).fit_transform(X_sparse)\n",
    "X_maxabs = MaxAbsScaler().fit_transform(X_sparse)\n",
    "\n",
    "print(\"\\nAfter StandardScaler(with_mean=False):\")\n",
    "print(\"  is_sparse:\", sparse.issparse(X_std_no_mean))\n",
    "\n",
    "print(\"\\nAfter MaxAbsScaler:\")\n",
    "print(\"  is_sparse:\", sparse.issparse(X_maxabs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ec1473",
   "metadata": {},
   "source": [
    "\n",
    "## ۱۲) مقیاس‌بندی برای PCA و k-means (مثال خوشه‌بندی با hw_200)\n",
    "\n",
    "PCA و k-means هر دو به هندسه‌ی اقلیدسی وابسته‌اند:\n",
    "\n",
    "- PCA جهت‌هایی را پیدا می‌کند که واریانس بیشینه دارند. اگر واحد یکی از ویژگی‌ها بزرگ‌تر باشد، مؤلفه‌های اصلی را غالب می‌کند.\n",
    "- k-means مجموع مربعات درون‌خوشه‌ای را کمینه می‌کند که مستقیماً به مقیاس ویژگی‌ها وابسته است.\n",
    "\n",
    "از دیتاست `hw_200.csv` (قد/وزن) استفاده می‌کنیم. این فایل عمداً نام ستون‌های نامرتب دارد.\n",
    "\n",
    "گام‌ها:\n",
    "\n",
    "1. بارگذاری داده\n",
    "2. تمیز کردن نام ستون‌ها\n",
    "3. مقایسه‌ی رفتار PCA و k-means با و بدون مقیاس‌بندی\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eef06712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns: ['Index', ' Height(Inches)\"', ' \"Weight(Pounds)\"']\n",
      "Cleaned columns: ['Index', 'Height(Inches)', 'Weight(Pounds)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Height(Inches)</th>\n",
       "      <th>Weight(Pounds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65.78</td>\n",
       "      <td>112.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>71.52</td>\n",
       "      <td>136.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>69.40</td>\n",
       "      <td>153.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>68.22</td>\n",
       "      <td>142.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>67.79</td>\n",
       "      <td>144.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  Height(Inches)  Weight(Pounds)\n",
       "0      1           65.78          112.99\n",
       "1      2           71.52          136.49\n",
       "2      3           69.40          153.03\n",
       "3      4           68.22          142.34\n",
       "4      5           67.79          144.30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_hw shape: (200, 2)\n",
      "Feature means (raw): [ 67.9498 127.222 ]\n",
      "Feature stds  (raw): [ 1.9355 11.931 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "hw = hw_raw.copy()\n",
    "print(\"Original columns:\", list(hw.columns))\n",
    "\n",
    "hw.columns = [c.replace('\"', '').strip() for c in hw.columns]\n",
    "hw.columns = [re.sub(r\"\\s+\", \" \", c).strip() for c in hw.columns]\n",
    "print(\"Cleaned columns:\", list(hw.columns))\n",
    "\n",
    "display(hw.head())\n",
    "\n",
    "# robustly pick height/weight columns\n",
    "hw_cols = [c for c in hw.columns if \"Height\" in c or \"Weight\" in c]\n",
    "X_hw = hw[hw_cols].astype(float).values\n",
    "\n",
    "print(\"\\nX_hw shape:\", X_hw.shape)\n",
    "print(\"Feature means (raw):\", np.round(X_hw.mean(axis=0), 4))\n",
    "print(\"Feature stds  (raw):\", np.round(X_hw.std(axis=0), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b52d3089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio (PCA raw): [0.9825 0.0175]\n",
      "Explained variance ratio (PCA scaled): [0.7784 0.2216]\n",
      "\n",
      "Cluster sizes (raw): [93 44 63]\n",
      "Cluster sizes (scaled): [51 59 90]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>raw_c0</th>\n",
       "      <td>67.59</td>\n",
       "      <td>126.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_c1</th>\n",
       "      <td>66.66</td>\n",
       "      <td>110.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_c2</th>\n",
       "      <td>69.37</td>\n",
       "      <td>140.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaled_c0_back</th>\n",
       "      <td>70.30</td>\n",
       "      <td>139.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaled_c1_back</th>\n",
       "      <td>65.99</td>\n",
       "      <td>114.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaled_c2_back</th>\n",
       "      <td>67.90</td>\n",
       "      <td>128.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Height  Weight\n",
       "raw_c0           67.59  126.05\n",
       "raw_c1           66.66  110.46\n",
       "raw_c2           69.37  140.66\n",
       "scaled_c0_back   70.30  139.28\n",
       "scaled_c1_back   65.99  114.42\n",
       "scaled_c2_back   67.90  128.78"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>raw_c0</th>\n",
       "      <td>69.50</td>\n",
       "      <td>165.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_c1</th>\n",
       "      <td>66.54</td>\n",
       "      <td>125.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_c2</th>\n",
       "      <td>68.53</td>\n",
       "      <td>144.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaled_c0_back</th>\n",
       "      <td>71.38</td>\n",
       "      <td>159.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaled_c1_back</th>\n",
       "      <td>66.46</td>\n",
       "      <td>130.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaled_c2_back</th>\n",
       "      <td>66.79</td>\n",
       "      <td>155.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Height  Weight\n",
       "raw_c0           69.50  165.66\n",
       "raw_c1           66.54  125.63\n",
       "raw_c2           68.53  144.99\n",
       "scaled_c0_back   71.38  159.98\n",
       "scaled_c1_back   66.46  130.81\n",
       "scaled_c2_back   66.79  155.81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# PCA without scaling\n",
    "pca_raw = PCA(n_components=2, random_state=0)\n",
    "Z_raw = pca_raw.fit_transform(X_hw)\n",
    "\n",
    "# PCA with scaling\n",
    "X_hw_scaled = scaler.fit_transform(X_hw)\n",
    "pca_scaled = PCA(n_components=2, random_state=0)\n",
    "Z_scaled = pca_scaled.fit_transform(X_hw_scaled)\n",
    "\n",
    "print(\"Explained variance ratio (PCA raw):\", np.round(pca_raw.explained_variance_ratio_, 4))\n",
    "print(\"Explained variance ratio (PCA scaled):\", np.round(pca_scaled.explained_variance_ratio_, 4))\n",
    "\n",
    "km_raw = KMeans(n_clusters=3, random_state=0, n_init=10)\n",
    "labels_raw = km_raw.fit_predict(X_hw)\n",
    "\n",
    "km_scaled = KMeans(n_clusters=3, random_state=0, n_init=10)\n",
    "labels_scaled = km_scaled.fit_predict(X_hw_scaled)\n",
    "\n",
    "print(\"\\nCluster sizes (raw):\", np.bincount(labels_raw))\n",
    "print(\"Cluster sizes (scaled):\", np.bincount(labels_scaled))\n",
    "\n",
    "centers_raw = km_raw.cluster_centers_\n",
    "centers_scaled_back = scaler.inverse_transform(km_scaled.cluster_centers_)\n",
    "\n",
    "centers_df = pd.DataFrame(\n",
    "    np.vstack([centers_raw, centers_scaled_back]),\n",
    "    columns=[c.replace(\"(Inches)\", \"\").replace(\"(Pounds)\", \"\") for c in hw_cols]\n",
    ")\n",
    "centers_df.index = [\"raw_c0\",\"raw_c1\",\"raw_c2\",\"scaled_c0_back\",\"scaled_c1_back\",\"scaled_c2_back\"]\n",
    "display(centers_df.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a99019",
   "metadata": {},
   "source": [
    "\n",
    "## ۱۳) مقیاس‌بندی و منظم‌سازی: چرا Ridge به واحدها وابسته است؟\n",
    "\n",
    "رگرسیون Ridge:\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{w}} \\; \\frac{1}{n}\\sum_{i=1}^n (y_i - \\mathbf{w}^\\top \\mathbf{x}_i)^2 + \\lambda \\lVert \\mathbf{w} \\rVert_2^2\n",
    "$$\n",
    "\n",
    "مقیاس‌بندی باعث می‌شود ترم منظم‌سازی بین ویژگی‌ها «منصفانه‌تر» عمل کند.\n",
    "\n",
    "### مثال: Ridge regression روی house prices\n",
    "\n",
    "یک pipeline با داده‌ی ترکیبی می‌سازیم (مقیاس‌بندی عددی + one-hot دسته‌ای) و Ridge را با و بدون مقیاس‌بندی عددی مقایسه می‌کنیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4edd5e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed alpha=10.0\n",
      "  Ridge (no numeric scaling):  RMSE = 11290.03   R2 = 0.7921\n",
      "  Ridge (with scaling):       RMSE = 10347.16   R2 = 0.8253\n",
      "\n",
      "After tuning alpha (fair comparison):\n",
      "  No scaling (tuned alpha): best_alpha=0.3511  CV_RMSE=9992.95  Test_RMSE=10334.16  Test_R2=0.8258\n",
      "  Scaled numeric (tuned alpha): best_alpha=0.3511  CV_RMSE=9992.66  Test_RMSE=10291.81  Test_R2=0.8272\n"
     ]
    }
   ],
   "source": [
    "\n",
    "house = pd.read_csv(Path(\"../../../Datasets/Regression/house-prices.csv\"))\n",
    "X = house.drop(columns=[\"Price\"])\n",
    "y = house[\"Price\"].astype(float)\n",
    "\n",
    "numeric_features = [\"SqFt\",\"Bedrooms\",\"Bathrooms\",\"Offers\"]\n",
    "categorical_features = [\"Brick\",\"Neighborhood\"]\n",
    "\n",
    "numeric_no_scale = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "numeric_scaled = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "pre_A = ColumnTransformer([\n",
    "    (\"num\", numeric_no_scale, numeric_features),\n",
    "    (\"cat\", cat_pipe, categorical_features)\n",
    "])\n",
    "\n",
    "pre_B = ColumnTransformer([\n",
    "    (\"num\", numeric_scaled, numeric_features),\n",
    "    (\"cat\", cat_pipe, categorical_features)\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# RMSE helper (compatible across scikit-learn versions)\n",
    "try:\n",
    "    from sklearn.metrics import root_mean_squared_error\n",
    "    def rmse(y_true, y_pred):\n",
    "        return root_mean_squared_error(y_true, y_pred)\n",
    "except Exception:\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "    def rmse(y_true, y_pred):\n",
    "        return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "# (A) Same alpha for both pipelines: shows alpha depends on feature scale\n",
    "alpha_fixed = 10.0\n",
    "pipe_A_fixed = Pipeline([(\"prep\", pre_A), (\"model\", Ridge(alpha=alpha_fixed, random_state=0))])\n",
    "pipe_B_fixed = Pipeline([(\"prep\", pre_B), (\"model\", Ridge(alpha=alpha_fixed, random_state=0))])\n",
    "\n",
    "pipe_A_fixed.fit(X_train, y_train)\n",
    "pipe_B_fixed.fit(X_train, y_train)\n",
    "\n",
    "pred_A = pipe_A_fixed.predict(X_test)\n",
    "pred_B = pipe_B_fixed.predict(X_test)\n",
    "\n",
    "rmse_A = rmse(y_test, pred_A)\n",
    "rmse_B = rmse(y_test, pred_B)\n",
    "r2_A = r2_score(y_test, pred_A)\n",
    "r2_B = r2_score(y_test, pred_B)\n",
    "\n",
    "print(f\"Fixed alpha={alpha_fixed}\")\n",
    "print(\"  Ridge (no numeric scaling):  RMSE =\", round(rmse_A, 2), \"  R2 =\", round(r2_A, 4))\n",
    "print(\"  Ridge (with scaling):       RMSE =\", round(rmse_B, 2), \"  R2 =\", round(r2_B, 4))\n",
    "\n",
    "# (B) Fair comparison: tune alpha separately\n",
    "alphas = np.logspace(-3, 4, 12)\n",
    "\n",
    "def tune_ridge(preprocessor, name):\n",
    "    pipe = Pipeline([(\"prep\", preprocessor), (\"model\", Ridge(random_state=0))])\n",
    "    gs = GridSearchCV(pipe, {\"model__alpha\": alphas}, cv=5, scoring=\"neg_root_mean_squared_error\")\n",
    "    gs.fit(X_train, y_train)\n",
    "    best = gs.best_estimator_\n",
    "    pred = best.predict(X_test)\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"best_alpha\": gs.best_params_[\"model__alpha\"],\n",
    "        \"test_rmse\": rmse(y_test, pred),\n",
    "        \"test_r2\": r2_score(y_test, pred),\n",
    "        \"cv_rmse\": -gs.best_score_,\n",
    "    }\n",
    "\n",
    "res_A = tune_ridge(pre_A, \"No scaling (tuned alpha)\")\n",
    "res_B = tune_ridge(pre_B, \"Scaled numeric (tuned alpha)\")\n",
    "\n",
    "print(\"\\nAfter tuning alpha (fair comparison):\")\n",
    "for r in [res_A, res_B]:\n",
    "    print(f\"  {r['name']}: best_alpha={r['best_alpha']:.4g}  CV_RMSE={r['cv_rmse']:.2f}  Test_RMSE={r['test_rmse']:.2f}  Test_R2={r['test_r2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488faa28",
   "metadata": {},
   "source": [
    "\n",
    "## ۱۴) اسکیلر به‌عنوان هایپرپارامتر: یک Grid Search کوچک (Iris + kNN)\n",
    "\n",
    "در سطح پیشرفته، بهتر است *انتخاب اسکیلر* را اعتبارسنجی کنید و فرض نکنید که همیشه یک گزینه بهترین است.\n",
    "\n",
    "در این مثال مقایسه می‌کنیم:\n",
    "\n",
    "- بدون اسکیلر\n",
    "- min–max\n",
    "- استانداردسازی\n",
    "- robust scaling\n",
    "\n",
    "یک `GridSearchCV` کوچک انجام می‌دهیم که در آن اسکیلر بخشی از pipeline است.\n",
    "\n",
    "این الگو در بسیاری از مدل‌ها قابل استفاده است.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43aa29ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy: 0.9733\n",
      "Best params:\n",
      "  knn__n_neighbors = 11\n",
      "  knn__weights = uniform\n",
      "  scaler = passthrough\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\".*invalid value encountered in cast.*\")\n",
    "\n",
    "\n",
    "X = iris.drop(columns=[\"classification\"])\n",
    "y = iris[\"classification\"]\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", \"passthrough\"),\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"scaler\": [\"passthrough\", StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "    \"knn__n_neighbors\": [3,5,7,9,11],\n",
    "    \"knn__weights\": [\"uniform\", \"distance\"]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gs = GridSearchCV(pipe, param_grid=param_grid, cv=cv, scoring=\"accuracy\", n_jobs=None)\n",
    "gs.fit(X, y)\n",
    "\n",
    "print(\"Best CV accuracy:\", round(gs.best_score_, 4))\n",
    "print(\"Best params:\")\n",
    "for k, v in gs.best_params_.items():\n",
    "    print(\" \", k, \"=\", v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bdda78",
   "metadata": {},
   "source": [
    "\n",
    "## ۱۵) انتخاب اسکیلر: یک جدول تصمیم‌گیری عملی\n",
    "\n",
    "هیچ اسکیلر «بهترینِ مطلق» وجود ندارد. انتخاب را بر اساس موارد زیر انجام دهید:\n",
    "\n",
    "### حساسیت الگوریتم\n",
    "- kNN، k-means، SVM، PCA: مقیاس‌بندی معمولاً ضروری است.\n",
    "- رگرسیون لجستیک/خطی با منظم‌سازی: مقیاس‌بندی به‌شدت توصیه می‌شود.\n",
    "- مدل‌های درختی: اغلب لازم نیست، اما می‌تواند جزئی از یک pipeline یکپارچه باشد.\n",
    "\n",
    "### توزیع داده\n",
    "- تقریباً متقارن، پرت‌های کم → `StandardScaler`\n",
    "- پرت/دُم‌سنگین → `RobustScaler`\n",
    "- نیاز به بازه‌ی محدود → `MinMaxScaler`\n",
    "- ویژگی‌های تنک → `MaxAbsScaler` یا `StandardScaler(with_mean=False)`\n",
    "- چولگی زیاد → `PowerTransformer` یا `QuantileTransformer` (حتماً اعتبارسنجی شود)\n",
    "\n",
    "### حاکمیت مدل و استقرار\n",
    "- اسکیلر فقط باید روی داده‌ی آموزش fit شود.\n",
    "- پیش‌پردازش + مدل را به‌صورت یک آرتیفکت واحد (pipeline) ذخیره کنید.\n",
    "- انتخاب اسکیلر را در کنار مدل مستند کنید.\n",
    "\n",
    "---\n",
    "\n",
    "## ۱۶) تمرین‌ها (پیشنهادی)\n",
    "\n",
    "1. روی دیتاست `diabetes`، `StandardScaler` و `RobustScaler` را برای `LogisticRegression` با CV پنج‌تایی مقایسه کنید.\n",
    "2. روی `wine`، یک SVM با و بدون مقیاس‌بندی اجرا کنید و حساسیت به `gamma` را مشاهده کنید.\n",
    "3. روی `hw_200`، `MinMaxScaler` و `StandardScaler` را برای k-means امتحان کنید و مراکز خوشه‌ها را مقایسه کنید.\n",
    "4. یک جست‌وجوی کوچک هایپرپارامتر بسازید که خودِ اسکیلر هم بخشی از فضای جست‌وجو باشد.\n",
    "\n",
    "---\n",
    "\n",
    "### جمع‌بندی\n",
    "\n",
    "مقیاس‌بندی ظاهری نیست. مقیاس‌بندی ساختار متریک را تعریف می‌کند، منصفانه بودن منظم‌سازی را کنترل می‌کند، و می‌تواند از ناپایداری عددی جلوگیری کند. از pipeline استفاده کنید، از نشت داده پرهیز کنید، و انتخاب اسکیلر را مثل هر هایپرپارامتر دیگر اعتبارسنجی کنید.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
