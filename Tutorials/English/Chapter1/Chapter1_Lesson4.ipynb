{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca56763",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&display=swap');\n",
       "\n",
       "\n",
       "/* Text areas (Classic Notebook + JupyterLab) */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "div.rendered_html, .output_subarea {\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "/* RTL for rendered markdown/html content */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "h1, h2, h3, h4, h5, h6, p, strong, label, ol, ul, li {\n",
       "  line-height: 1.9;\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "h1 { font-size: 2rem; color: #070F2B; font-weight: 900}\n",
       "h2 { font-size: 1.8rem; color: #070F2B; font-weight: 800}\n",
       "h3 { font-size: 1.6rem; color: #070F2B; font-weight: 700}\n",
       "h4 { font-size: 1.4rem; color: #1E3E62; font-weight: 600}\n",
       "h5 { font-size: 1.2rem; color: #1E3E62}\n",
       "h6 { font-size: 1rem; color: #1E3E62}\n",
       "p { font-size: 1.1rem; ; font-weight: 400}\n",
       "ol, ul, li, th, td  { font-size: 1rem; }\n",
       "\n",
       "/* Keep code + outputs LTR and monospace */\n",
       ".CodeMirror, .CodeMirror *,\n",
       "pre, code,\n",
       ".jp-CodeCell .jp-InputArea, .jp-CodeCell .jp-InputArea *,\n",
       ".jp-OutputArea, .jp-OutputArea * {\n",
       "  direction: ltr !important;\n",
       "  text-align: left !important;\n",
       "  font-size: 1rem !important;\n",
       "  font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "css = Path(\"../../../css/custom.css\").read_text(encoding=\"utf-8\")\n",
    "display(HTML(f\"<style>{css}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b90042",
   "metadata": {},
   "source": [
    "# Chapter 1 — Lesson 4: ML Workflow (Data, Model, Evaluation, Deployment)\n",
    "\n",
    "This notebook is a practical, end-to-end walkthrough of a classical Machine Learning workflow. The focus is not on any single algorithm; it is on the engineering discipline that turns data into a **reliable** model and then into a **usable** artifact.\n",
    "\n",
    "You will see the same workflow patterns across three tasks:\n",
    "\n",
    "- **Classification**: predict a binary label (diabetic vs non-diabetic).\n",
    "- **Regression**: predict a numeric target (diamond price).\n",
    "- **Clustering**: discover structure without labels (airport coordinates).\n",
    "\n",
    "The code uses dataset paths consistent with your repository layout, such as:\n",
    "\n",
    "- `../../../Datasets/Classification/diabetes.csv`\n",
    "- `../../../Datasets/Regression/diamonds.csv`\n",
    "- `../../../Datasets/Clustering/airports.csv`\n",
    "\n",
    "If a dataset file is not present in the runtime environment, the notebook synthesizes a dataset with a compatible schema so that every section remains runnable.\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow overview\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "A[Data] --> B[Problem formulation]\n",
    "B --> C[Split strategy]\n",
    "C --> D[Preprocess & Feature engineering]\n",
    "D --> E[Model training]\n",
    "E --> F[Evaluation & error analysis]\n",
    "F --> G{Good enough?}\n",
    "G -- No --> D\n",
    "G -- Yes --> H[Package & Deploy]\n",
    "H --> I[Monitoring & Feedback]\n",
    "I --> D\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## A compact mathematical view\n",
    "\n",
    "Training is often written as empirical risk minimization:\n",
    "\n",
    "$$\n",
    "\\hat{f} = \\arg\\min_{f \\in \\mathcal{F}} \\frac{1}{n}\\sum_{i=1}^{n} \\ell\\big(y_i, f(x_i)\\big) + \\lambda \\Omega(f)\n",
    "$$\n",
    "\n",
    "- $x_i$ are features, $y_i$ are targets.\n",
    "- $\\ell$ is a loss (log-loss, squared error, etc.).\n",
    "- $\\Omega$ is a regularizer.\n",
    "- $\\mathcal{F}$ is a hypothesis class (linear models, trees, kernels, …).\n",
    "\n",
    "In real work, the *workflow around* this objective determines whether the model generalizes.\n",
    "\n",
    "---\n",
    "\n",
    "## 0) Problem formulation (what you must decide before modeling)\n",
    "\n",
    "### 0.1 Unit of prediction\n",
    "\n",
    "Define what a single row represents. For example:\n",
    "\n",
    "- one patient snapshot\n",
    "- one loan application\n",
    "- one transaction\n",
    "- one listing\n",
    "\n",
    "This choice affects leakage, splitting, and interpretability.\n",
    "\n",
    "### 0.2 Target definition and timing\n",
    "\n",
    "A target definition must be unambiguous:\n",
    "\n",
    "- What is the event you predict?\n",
    "- When does the event occur relative to the available features?\n",
    "- How are labels produced? (manual, automated, delayed, noisy)\n",
    "- Are there edge cases or ambiguous labels?\n",
    "\n",
    "If your label is “did the user churn in the next 30 days”, then features must reflect only information available **at the prediction time**, not after churn.\n",
    "\n",
    "### 0.3 Constraints and success criteria\n",
    "\n",
    "List constraints explicitly:\n",
    "\n",
    "- latency (e.g., < 50 ms)\n",
    "- memory/model size\n",
    "- interpretability/auditability\n",
    "- privacy and retention constraints\n",
    "- fairness goals\n",
    "- cost of false positives/negatives\n",
    "\n",
    "Define success criteria:\n",
    "\n",
    "- primary metric (ROC-AUC, RMSE, …)\n",
    "- acceptable operating point (precision/recall at a threshold)\n",
    "- stability requirement (variance across folds and slices)\n",
    "\n",
    "### 0.4 Split strategy\n",
    "\n",
    "Split strategy is a modeling choice:\n",
    "\n",
    "- random split for i.i.d. tabular data\n",
    "- stratified split to preserve class balance\n",
    "- group split to avoid entity leakage\n",
    "- time split to mimic deployment conditions\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Data stage: ingest, validate, and understand\n",
    "\n",
    "### 1.1 Ingest\n",
    "\n",
    "Good habits:\n",
    "\n",
    "- load from known paths\n",
    "- log dataset version / snapshot\n",
    "- inspect shape and column names\n",
    "- store quick summaries (min/max, missingness)\n",
    "\n",
    "### 1.2 Validate (minimal data contract)\n",
    "\n",
    "At a minimum:\n",
    "\n",
    "- required columns exist\n",
    "- numeric ranges are plausible\n",
    "- categorical values are known or handled safely\n",
    "- missingness is within expected bounds\n",
    "\n",
    "This prevents silent failures in training and in production.\n",
    "\n",
    "### 1.3 Understand\n",
    "\n",
    "You should always look for:\n",
    "\n",
    "- class balance (classification prevalence)\n",
    "- target noise\n",
    "- duplicates\n",
    "- suspicious “too informative” features (potential leakage)\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Modeling stage: pipelines and baselines\n",
    "\n",
    "### 2.1 Pipelines prevent leakage\n",
    "\n",
    "All preprocessing must be inside a pipeline. Otherwise you risk contaminating validation/test data with statistics computed from the full dataset.\n",
    "\n",
    "We will use:\n",
    "\n",
    "- `ColumnTransformer` for column-wise preprocessing\n",
    "- `Pipeline` for preprocessing → model\n",
    "\n",
    "### 2.2 Baselines first\n",
    "\n",
    "A baseline model answers:\n",
    "\n",
    "- is there real signal?\n",
    "- how hard is the task?\n",
    "- what performance level is realistic?\n",
    "\n",
    "We use logistic regression as a strong baseline for tabular classification, then compare to a small random forest.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Evaluation stage: metrics, thresholds, slices\n",
    "\n",
    "### 3.1 Global metrics\n",
    "\n",
    "Binary classification:\n",
    "\n",
    "- Accuracy, Precision, Recall, F1\n",
    "- ROC-AUC (threshold-free ranking quality)\n",
    "\n",
    "Regression:\n",
    "\n",
    "- MAE, RMSE, $R^2$\n",
    "\n",
    "### 3.2 Threshold tuning under costs\n",
    "\n",
    "Deployment requires a threshold. If FN costs 5× FP, choose a threshold minimizing:\n",
    "\n",
    "$$\n",
    "\\text{Cost}(t) = c_{FP}\\cdot FP(t) + c_{FN}\\cdot FN(t)\n",
    "$$\n",
    "\n",
    "### 3.3 Slice analysis\n",
    "\n",
    "Compute metrics by subgroups (age bands, cohorts, regions). A model can look “good” overall and still be unacceptable on critical slices.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Deployment stage (minimal, but real)\n",
    "\n",
    "You should be able to:\n",
    "\n",
    "- save the entire pipeline\n",
    "- load it back\n",
    "- run inference on new rows\n",
    "- document required input schema\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Monitoring stage (minimum viable)\n",
    "\n",
    "Monitoring typically includes:\n",
    "\n",
    "- feature drift\n",
    "- performance decay\n",
    "- operational health\n",
    "\n",
    "We compute PSI for a feature as a simple drift indicator.\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Leakage (the classic workflow failure)\n",
    "\n",
    "Leakage frequently produces unrealistically high metrics. We create an intentionally leaky feature (a proxy for the target) to demonstrate how metrics can be misleading.\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Unsupervised workflow (clustering)\n",
    "\n",
    "Even without labels, workflow discipline remains:\n",
    "\n",
    "- define the goal (segmentation vs anomaly detection vs compression)\n",
    "- standardize features\n",
    "- choose $k$ (elbow/inertia, stability, business constraints)\n",
    "- interpret clusters and validate with domain checks\n",
    "\n",
    "---\n",
    "\n",
    "## Practical checklists\n",
    "\n",
    "### Data checklist\n",
    "- [ ] Target definition includes timing constraints\n",
    "- [ ] Split strategy matches real deployment\n",
    "- [ ] Schema validation implemented\n",
    "- [ ] Leakage candidates reviewed\n",
    "- [ ] Data snapshot/version tracked\n",
    "\n",
    "### Modeling checklist\n",
    "- [ ] Baseline established\n",
    "- [ ] Preprocessing is inside pipeline\n",
    "- [ ] Reproducibility controls in place (seeds, environment)\n",
    "- [ ] Hyperparameters tuned without test leakage\n",
    "\n",
    "### Evaluation checklist\n",
    "- [ ] Global metrics and uncertainty (CV)\n",
    "- [ ] Threshold chosen under costs\n",
    "- [ ] Slice analysis performed\n",
    "- [ ] Error examples inspected manually\n",
    "\n",
    "### Deployment checklist\n",
    "- [ ] Artifact saved and load-tested\n",
    "- [ ] Input schema documented\n",
    "- [ ] Monitoring and retraining triggers defined\n",
    "\n",
    "This notebook demonstrates a minimal version of each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca248bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import joblib\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6030ad3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification_iris': '../../../Datasets/Classification/iris.csv',\n",
       " 'classification_wine': '../../../Datasets/Classification/Wine_Quality.csv',\n",
       " 'classification_diabetes': '../../../Datasets/Classification/diabetes.csv'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = [\n",
    "    (\"classification_diabetes\", \"../../../Datasets/Classification/diabetes.csv\"),\n",
    "    (\"classification_iris\", \"../../../Datasets/Classification/iris.csv\"),\n",
    "    (\"classification_wine\", \"../../../Datasets/Classification/Wine_Quality.csv\"),\n",
    "    (\"regression_diamonds\", \"../../../Datasets/Regression/diamonds.csv\"),\n",
    "    (\"regression_house_prices\", \"../../../Datasets/Regression/house-prices.csv\"),\n",
    "    (\"clustering_airports\", \"../../../Datasets/Clustering/airports.csv\"),\n",
    "    (\"clustering_hw200\", \"../../../Datasets/Clustering/hw_200.csv\"),\n",
    "]\n",
    "\n",
    "random.seed(4)  # fixed for stable lesson content\n",
    "chosen = dict(random.sample(candidates, k=3))\n",
    "chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932c2679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader functions ready.\n"
     ]
    }
   ],
   "source": [
    "def _exists(path_str: str) -> bool:\n",
    "    try:\n",
    "        return Path(path_str).exists()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "DIABETES_SAMPLE = r'''Pregnancies,Glucose,BloodPressure,SkinThickness,Insulin,BMI,DiabetesPedigreeFunction,Age,classification\n",
    "6,148,72,35,0,33.6,0.627,50,Diabetic\n",
    "1,85,66,29,0,26.6,0.351,31,Non-Diabetic\n",
    "8,183,64,0,0,23.3,0.672,32,Diabetic\n",
    "1,89,66,23,94,28.1,0.167,21,Non-Diabetic\n",
    "0,137,40,35,168,43.1,2.288,33,Diabetic\n",
    "'''\n",
    "\n",
    "AIRPORTS_SAMPLE = r'''\"latitude_deg\",\"longitude_deg\",\"elevation_ft\"\n",
    "40.070985,-74.933689,11\n",
    "38.704022,-101.473911,3435\n",
    "59.947733,-151.692524,450\n",
    "'''\n",
    "\n",
    "def load_or_synthesize_diabetes(path: str, n: int = 420, seed: int = 42) -> pd.DataFrame:\n",
    "    if _exists(path):\n",
    "        return pd.read_csv(path)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df0 = pd.read_csv(pd.io.common.StringIO(DIABETES_SAMPLE))\n",
    "    cols = [c for c in df0.columns if c != \"classification\"]\n",
    "    mu = df0[cols].mean()\n",
    "    sd = df0[cols].std().replace(0, 1.0).fillna(1.0)\n",
    "\n",
    "    X = rng.normal(loc=mu.values, scale=sd.values, size=(n, len(cols)))\n",
    "    X = pd.DataFrame(X, columns=cols)\n",
    "\n",
    "    X[\"Pregnancies\"] = np.clip(np.round(X[\"Pregnancies\"]), 0, 20)\n",
    "    X[\"Glucose\"] = np.clip(X[\"Glucose\"], 50, 250)\n",
    "    X[\"BloodPressure\"] = np.clip(X[\"BloodPressure\"], 30, 140)\n",
    "    X[\"SkinThickness\"] = np.clip(X[\"SkinThickness\"], 0, 100)\n",
    "    X[\"Insulin\"] = np.clip(X[\"Insulin\"], 0, 600)\n",
    "    X[\"BMI\"] = np.clip(X[\"BMI\"], 15, 60)\n",
    "    X[\"DiabetesPedigreeFunction\"] = np.clip(X[\"DiabetesPedigreeFunction\"], 0.05, 3.0)\n",
    "    X[\"Age\"] = np.clip(X[\"Age\"], 18, 85)\n",
    "\n",
    "    score = (\n",
    "        0.03 * (X[\"Glucose\"] - 120)\n",
    "        + 0.06 * (X[\"BMI\"] - 30)\n",
    "        + 0.02 * (X[\"Age\"] - 35)\n",
    "        + 0.15 * (X[\"DiabetesPedigreeFunction\"] - 0.5)\n",
    "    )\n",
    "    p = 1 / (1 + np.exp(-score))\n",
    "    y = rng.binomial(1, np.clip(p, 0.05, 0.95), size=n)\n",
    "    X[\"classification\"] = np.where(y == 1, \"Diabetic\", \"Non-Diabetic\")\n",
    "    return X\n",
    "\n",
    "def load_or_synthesize_diamonds(path: str, n: int = 600, seed: int = 42) -> pd.DataFrame:\n",
    "    if _exists(path):\n",
    "        return pd.read_csv(path)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    cuts = [\"Fair\", \"Good\", \"Very Good\", \"Premium\", \"Ideal\"]\n",
    "    colors = list(\"DEFGHIJ\")\n",
    "    clarities = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]\n",
    "\n",
    "    carat = np.clip(rng.lognormal(mean=-0.4, sigma=0.5, size=n), 0.2, 2.5)\n",
    "    cut = rng.choice(cuts, size=n, p=[0.03, 0.10, 0.25, 0.30, 0.32])\n",
    "    color = rng.choice(colors, size=n, p=[0.15, 0.18, 0.17, 0.15, 0.13, 0.12, 0.10])\n",
    "    clarity = rng.choice(clarities, size=n, p=[0.02, 0.10, 0.18, 0.20, 0.18, 0.15, 0.10, 0.07])\n",
    "\n",
    "    depth = np.clip(rng.normal(61.5, 1.5, size=n), 55, 70)\n",
    "    table = np.clip(rng.normal(57.0, 2.0, size=n), 50, 70)\n",
    "\n",
    "    x = np.clip(3.0 + 2.2 * np.sqrt(carat) + rng.normal(0, 0.15, size=n), 3.0, 10.0)\n",
    "    y = np.clip(x + rng.normal(0, 0.08, size=n), 3.0, 10.0)\n",
    "    z = np.clip(2.0 + 1.4 * np.sqrt(carat) + rng.normal(0, 0.12, size=n), 1.5, 6.5)\n",
    "\n",
    "    base = 800 * (carat ** 1.7)\n",
    "    noise = rng.normal(0, 250, size=n)\n",
    "    price = np.clip(base + noise, 200, None)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"id\": np.arange(1, n+1).astype(str),\n",
    "        \"carat\": carat,\n",
    "        \"cut\": cut,\n",
    "        \"color\": color,\n",
    "        \"clarity\": clarity,\n",
    "        \"depth\": depth,\n",
    "        \"table\": table,\n",
    "        \"price\": price.round(0).astype(int),\n",
    "        \"x\": x.round(2),\n",
    "        \"y\": y.round(2),\n",
    "        \"z\": z.round(2),\n",
    "    })\n",
    "\n",
    "def load_or_synthesize_airports(path: str, n: int = 240, seed: int = 42) -> pd.DataFrame:\n",
    "    if _exists(path):\n",
    "        return pd.read_csv(path)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df0 = pd.read_csv(pd.io.common.StringIO(AIRPORTS_SAMPLE))\n",
    "    centers = df0[[\"latitude_deg\", \"longitude_deg\", \"elevation_ft\"]].to_numpy()\n",
    "    cluster = rng.integers(0, len(centers), size=n)\n",
    "    base = centers[cluster]\n",
    "    lat = base[:, 0] + rng.normal(0, 1.0, size=n)\n",
    "    lon = base[:, 1] + rng.normal(0, 1.6, size=n)\n",
    "    elev = np.clip(base[:, 2] + rng.normal(0, 800, size=n), 0, 12000).astype(int)\n",
    "    return pd.DataFrame({\"latitude_deg\": lat, \"longitude_deg\": lon, \"elevation_ft\": elev})\n",
    "\n",
    "print(\"Loader functions ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "652d629b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes: (768, 9)  Diamonds: (53940, 11)  Airports: (83125, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>Non-Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>Non-Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age classification  \n",
       "0                     0.627   50       Diabetic  \n",
       "1                     0.351   31   Non-Diabetic  \n",
       "2                     0.672   32       Diabetic  \n",
       "3                     0.167   21   Non-Diabetic  \n",
       "4                     2.288   33       Diabetic  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetes_path = chosen.get(\"classification_diabetes\", \"../../../Datasets/Classification/diabetes.csv\")\n",
    "diamonds_path = chosen.get(\"regression_diamonds\", \"../../../Datasets/Regression/diamonds.csv\")\n",
    "airports_path = chosen.get(\"clustering_airports\", \"../../../Datasets/Clustering/airports.csv\")\n",
    "\n",
    "df_diabetes = load_or_synthesize_diabetes(diabetes_path, n=420, seed=SEED)\n",
    "df_diamonds = load_or_synthesize_diamonds(diamonds_path, n=600, seed=SEED)\n",
    "df_airports = load_or_synthesize_airports(airports_path, n=240, seed=SEED)\n",
    "\n",
    "print(\"Diabetes:\", df_diabetes.shape, \" Diamonds:\", df_diamonds.shape, \" Airports:\", df_airports.shape)\n",
    "display(df_diabetes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb80f329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation OK? True\n"
     ]
    }
   ],
   "source": [
    "def validate_input(df: pd.DataFrame, required_cols, numeric_ranges=None):\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "    if numeric_ranges:\n",
    "        for c, (lo, hi) in numeric_ranges.items():\n",
    "            if c in df.columns:\n",
    "                bad = df[(df[c] < lo) | (df[c] > hi)]\n",
    "                if len(bad) > 0:\n",
    "                    raise ValueError(f\"Column {c} has values outside [{lo}, {hi}] (n_bad={len(bad)})\")\n",
    "    return True\n",
    "\n",
    "required = [\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"BMI\",\"Age\",\"classification\"]\n",
    "ranges = {\"Age\": (0, 120), \"Glucose\": (0, 400), \"BMI\": (0, 100)}\n",
    "print(\"Validation OK?\", validate_input(df_diabetes, required, ranges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbe2ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (576, 8) Test: (192, 8)\n",
      "Positive rate (train/test): 0.349 0.349\n"
     ]
    }
   ],
   "source": [
    "target = \"classification\"\n",
    "X = df_diabetes.drop(columns=[target]).copy()\n",
    "y = df_diabetes[target].map({\"Non-Diabetic\": 0, \"Diabetic\": 1}).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
    "print(\"Positive rate (train/test):\", round(y_train.mean(), 3), round(y_test.mean(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1574f473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy     0.7344\n",
       "precision    0.6481\n",
       "recall       0.5224\n",
       "f1           0.5785\n",
       "roc_auc      0.8320\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = X_train.columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), numeric_features)]\n",
    ")\n",
    "\n",
    "lr = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=250, random_state=SEED))\n",
    "])\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "proba_lr = lr.predict_proba(X_test)[:, 1]\n",
    "pred_lr = (proba_lr >= 0.5).astype(int)\n",
    "\n",
    "metrics_lr = {\n",
    "    \"accuracy\": accuracy_score(y_test, pred_lr),\n",
    "    \"precision\": precision_score(y_test, pred_lr, zero_division=0),\n",
    "    \"recall\": recall_score(y_test, pred_lr, zero_division=0),\n",
    "    \"f1\": f1_score(y_test, pred_lr, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(y_test, proba_lr),\n",
    "}\n",
    "\n",
    "pd.Series(metrics_lr).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e7f9303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.7344</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.5224</td>\n",
       "      <td>0.5785</td>\n",
       "      <td>0.8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.7037</td>\n",
       "      <td>0.5672</td>\n",
       "      <td>0.6281</td>\n",
       "      <td>0.8192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  precision  recall      f1  roc_auc\n",
       "LogReg          0.7344     0.6481  0.5224  0.5785   0.8320\n",
       "RandomForest    0.7656     0.7037  0.5672  0.6281   0.8192"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=40, random_state=SEED, n_jobs=-1,\n",
    "        max_depth=7, min_samples_leaf=2\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "pred_rf = (proba_rf >= 0.5).astype(int)\n",
    "\n",
    "metrics_rf = {\n",
    "    \"accuracy\": accuracy_score(y_test, pred_rf),\n",
    "    \"precision\": precision_score(y_test, pred_rf, zero_division=0),\n",
    "    \"recall\": recall_score(y_test, pred_rf, zero_division=0),\n",
    "    \"f1\": f1_score(y_test, pred_rf, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(y_test, proba_rf),\n",
    "}\n",
    "\n",
    "pd.DataFrame([metrics_lr, metrics_rf], index=[\"LogReg\", \"RandomForest\"]).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd0ed41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline LR CV ROC-AUC: [0.8206 0.8086]  mean: 0.8146\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=SEED)\n",
    "cv_auc = cross_val_score(lr, X_train, y_train, scoring=\"roc_auc\", cv=skf)\n",
    "print(\"Baseline LR CV ROC-AUC:\", np.round(cv_auc, 4), \" mean:\", round(cv_auc.mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24de4cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>53</td>\n",
       "      <td>44</td>\n",
       "      <td>81</td>\n",
       "      <td>14</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>98</td>\n",
       "      <td>22</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "      <td>109</td>\n",
       "      <td>29</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>38</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>46</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>58</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>67</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  TP  FP   TN  FN   cost\n",
       "0        0.1  65  78   47   2   88.0\n",
       "1        0.2  58  60   65   9  105.0\n",
       "2        0.3  53  44   81  14  114.0\n",
       "3        0.4  45  27   98  22  137.0\n",
       "4        0.5  38  16  109  29  161.0\n",
       "5        0.6  29  10  115  38  200.0\n",
       "6        0.7  21   4  121  46  234.0\n",
       "7        0.8   9   0  125  58  290.0\n",
       "8        0.9   0   0  125  67  335.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold by cost:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  TP  FP  TN  FN  cost\n",
       "0        0.1  65  78  47   2  88.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost_fp = 1.0\n",
    "cost_fn = 5.0\n",
    "\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    p = (proba_rf >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, p).ravel()\n",
    "    cost = cost_fp * fp + cost_fn * fn\n",
    "    rows.append((t, tp, fp, tn, fn, cost))\n",
    "\n",
    "df_thr = pd.DataFrame(rows, columns=[\"threshold\", \"TP\", \"FP\", \"TN\", \"FN\", \"cost\"])\n",
    "display(df_thr)\n",
    "print(\"Best threshold by cost:\")\n",
    "display(df_thr.sort_values(\"cost\").head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca9713b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO.PIESC\\AppData\\Local\\Temp\\ipykernel_25496\\1229140657.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_eval.groupby(\"age_band\", observed=True).apply(slice_metrics).reset_index().round(4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_band</th>\n",
       "      <th>n</th>\n",
       "      <th>pos_rate</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(17.999, 30.0]</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(30.0, 40.0]</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.6286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(40.0, 50.0]</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.8667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(50.0, 60.0]</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.4615</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(60.0, 85.0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age_band      n  pos_rate  recall  precision      f1\n",
       "0  (17.999, 30.0]  114.0    0.2105  0.3750     0.6000  0.4615\n",
       "1    (30.0, 40.0]   33.0    0.6364  0.5238     0.7857  0.6286\n",
       "2    (40.0, 50.0]   27.0    0.5556  0.8667     0.8667  0.8667\n",
       "3    (50.0, 60.0]   13.0    0.4615  0.6667     0.5000  0.5714\n",
       "4    (60.0, 85.0]    5.0    0.2000  1.0000     0.5000  0.6667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = X_test.copy()\n",
    "df_eval[\"y_true\"] = y_test.values\n",
    "df_eval[\"y_pred\"] = pred_rf\n",
    "\n",
    "df_eval[\"age_band\"] = pd.cut(df_eval[\"Age\"], bins=[18, 30, 40, 50, 60, 85], include_lowest=True)\n",
    "\n",
    "def slice_metrics(g):\n",
    "    yt = g[\"y_true\"].values\n",
    "    yp = g[\"y_pred\"].values\n",
    "    return pd.Series({\n",
    "        \"n\": len(g),\n",
    "        \"pos_rate\": yt.mean(),\n",
    "        \"recall\": recall_score(yt, yp, zero_division=0),\n",
    "        \"precision\": precision_score(yt, yp, zero_division=0),\n",
    "        \"f1\": f1_score(yt, yp, zero_division=0),\n",
    "    })\n",
    "\n",
    "df_eval.groupby(\"age_band\", observed=True).apply(slice_metrics).reset_index().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59669973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC with leakage: 1.0\n"
     ]
    }
   ],
   "source": [
    "X_leaky = X.copy()\n",
    "rng = np.random.default_rng(SEED)\n",
    "X_leaky[\"leaky_target_proxy\"] = y + rng.normal(0, 0.02, size=len(y))\n",
    "\n",
    "Xl_train, Xl_test, yl_train, yl_test = train_test_split(\n",
    "    X_leaky, y, test_size=0.25, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "pre_leaky = ColumnTransformer(\n",
    "    transformers=[(\"num\", Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), Xl_train.columns.tolist())]\n",
    ")\n",
    "\n",
    "leaky = Pipeline(steps=[\n",
    "    (\"preprocess\", pre_leaky),\n",
    "    (\"model\", LogisticRegression(max_iter=250, random_state=SEED))\n",
    "])\n",
    "\n",
    "leaky.fit(Xl_train, yl_train)\n",
    "proba = leaky.predict_proba(Xl_test)[:, 1]\n",
    "print(\"ROC-AUC with leakage:\", round(roc_auc_score(yl_test, proba), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "960e02ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>13</td>\n",
       "      <td>104</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.465</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "635           13      104             72              0        0  31.2   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "635                     0.465   38  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(diabetic) = 0.3655  -> class = 0\n"
     ]
    }
   ],
   "source": [
    "artifact_dir = Path(\"./_artifacts\")\n",
    "artifact_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = artifact_dir / \"chapter1_lesson4_diabetes_rf_pipeline.joblib\"\n",
    "joblib.dump(rf, model_path)\n",
    "\n",
    "loaded = joblib.load(model_path)\n",
    "\n",
    "one = X_test.iloc[[0]].copy()\n",
    "display(one)\n",
    "\n",
    "p1 = loaded.predict_proba(one)[:, 1][0]\n",
    "print(\"P(diabetic) =\", round(float(p1), 4), \" -> class =\", int(p1 >= 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fea625fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSI(Glucose): 0.291\n"
     ]
    }
   ],
   "source": [
    "def psi(expected: np.ndarray, actual: np.ndarray, bins: int = 10, eps: float = 1e-6) -> float:\n",
    "    q = np.linspace(0, 1, bins + 1)\n",
    "    cuts = np.quantile(expected, q)\n",
    "    cuts[0], cuts[-1] = -np.inf, np.inf\n",
    "    e_counts, _ = np.histogram(expected, bins=cuts)\n",
    "    a_counts, _ = np.histogram(actual, bins=cuts)\n",
    "    e = np.clip(e_counts / max(e_counts.sum(), 1), eps, 1)\n",
    "    a = np.clip(a_counts / max(a_counts.sum(), 1), eps, 1)\n",
    "    return float(np.sum((a - e) * np.log(a / e)))\n",
    "\n",
    "future = X_test.copy()\n",
    "future[\"Glucose\"] = future[\"Glucose\"] + 15  # simulate shift\n",
    "print(\"PSI(Glucose):\", round(psi(X_train[\"Glucose\"].to_numpy(), future[\"Glucose\"].to_numpy()), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c576b132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 12.32  RMSE: 63.21  R^2: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>559.0</td>\n",
       "      <td>555.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2201.0</td>\n",
       "      <td>2202.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1238.0</td>\n",
       "      <td>1241.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1304.0</td>\n",
       "      <td>1294.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6901.0</td>\n",
       "      <td>6901.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3011.0</td>\n",
       "      <td>3014.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1765.0</td>\n",
       "      <td>1764.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1679.0</td>\n",
       "      <td>1675.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_true   y_pred\n",
       "0   559.0   555.48\n",
       "1  2201.0  2202.37\n",
       "2  1238.0  1241.60\n",
       "3  1304.0  1294.37\n",
       "4  6901.0  6901.72\n",
       "5  3011.0  3014.04\n",
       "6  1765.0  1764.63\n",
       "7  1679.0  1675.78"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df_diamonds.copy()\n",
    "y_r = df[\"price\"].astype(float)\n",
    "X_r = df.drop(columns=[\"price\"]).copy()\n",
    "\n",
    "cat_cols = [c for c in X_r.columns if X_r[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X_r.columns if c not in cat_cols]\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_r, y_r, test_size=0.25, random_state=SEED)\n",
    "\n",
    "preprocess_r = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]), num_cols),\n",
    "        (\"cat\", Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reg = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_r),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=40, random_state=SEED, n_jobs=-1,\n",
    "        max_depth=10, min_samples_leaf=2\n",
    "    ))\n",
    "])\n",
    "\n",
    "reg.fit(X_train_r, y_train_r)\n",
    "pred = reg.predict(X_test_r)\n",
    "\n",
    "mae = mean_absolute_error(y_test_r, pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test_r, pred))\n",
    "r2 = r2_score(y_test_r, pred)\n",
    "\n",
    "print(\"MAE:\", round(mae, 2), \" RMSE:\", round(rmse, 2), \" R^2:\", round(r2, 4))\n",
    "display(pd.DataFrame({\"y_true\": y_test_r.values[:8], \"y_pred\": pred[:8]}).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "626fb969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>inertia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>171305.319500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>123707.639589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>80408.774662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>64335.499902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>54530.896375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k        inertia\n",
       "0  2  171305.319500\n",
       "1  3  123707.639589\n",
       "2  4   80408.774662\n",
       "3  5   64335.499902\n",
       "4  6   54530.896375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    55872\n",
       "1    19937\n",
       "2     7316\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Robust clustering prep: handle missing values and enforce numeric types ---\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "dfc = df_airports.copy()\n",
    "\n",
    "cols = [\"latitude_deg\", \"longitude_deg\", \"elevation_ft\"]\n",
    "missing_cols = [c for c in cols if c not in dfc.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(\n",
    "        f\"Expected columns not found in airports data: {missing_cols}\\n\"\n",
    "        f\"Available columns (first 40): {list(dfc.columns)[:40]}\"\n",
    "    )\n",
    "\n",
    "Xc = dfc[cols].copy()\n",
    "\n",
    "# Coerce to numeric (some CSVs store these as strings); invalid parses become NaN\n",
    "for c in cols:\n",
    "    Xc[c] = pd.to_numeric(Xc[c], errors=\"coerce\")\n",
    "\n",
    "# Impute NaNs (KMeans cannot handle NaN)\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_imp = imputer.fit_transform(Xc)\n",
    "\n",
    "# Standardize\n",
    "Xs = StandardScaler().fit_transform(X_imp)\n",
    "\n",
    "# --- Model selection proxy: inertia for a small k grid (fast) ---\n",
    "ks = [2, 3, 4, 5, 6]\n",
    "rows = []\n",
    "models = {}\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, random_state=SEED, n_init=10)\n",
    "    km.fit(Xs)\n",
    "    rows.append((k, float(km.inertia_)))\n",
    "    models[k] = km\n",
    "\n",
    "inertia_df = pd.DataFrame(rows, columns=[\"k\", \"inertia\"]).sort_values(\"k\")\n",
    "display(inertia_df)\n",
    "\n",
    "best_k = 3  # for demonstration; in practice use elbow + stability + constraints\n",
    "km = models[best_k]\n",
    "dfc[\"cluster\"] = km.predict(Xs)\n",
    "display(dfc[\"cluster\"].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dceb23",
   "metadata": {},
   "source": [
    "## Exercises (recommended)\n",
    "\n",
    "1. **Split strategy stress test**  \n",
    "   Replace the random split with a time-based split (simulate time by sorting on Age or another feature) and compare metrics. Explain why metrics change.\n",
    "\n",
    "2. **Cost-aware thresholding**  \n",
    "   Change the cost ratio to FN 10× FP and re-compute the best threshold. What happens to precision and recall?\n",
    "\n",
    "3. **Schema enforcement**  \n",
    "   Extend `validate_input` to enforce:\n",
    "   - no extra columns (strict schema)\n",
    "   - allowed ranges for multiple features\n",
    "   - rejection or imputation rules for missing values\n",
    "\n",
    "4. **Leakage forensics**  \n",
    "   Try adding an “ID-like” feature (e.g., row index) and see whether metrics change. Discuss when IDs leak information and when they do not.\n",
    "\n",
    "5. **Model governance notes**  \n",
    "   Write a short “model card” (one page) describing:\n",
    "   - intended use\n",
    "   - training data\n",
    "   - metrics\n",
    "   - limitations\n",
    "   - monitoring plan\n",
    "\n",
    "6. **Clustering interpretation**  \n",
    "   For each cluster, compute mean/median latitude/longitude/elevation and write a short interpretation. What might those clusters represent?\n",
    "\n",
    "7. **Reproducibility**  \n",
    "   Run the notebook twice and confirm that:\n",
    "   - chosen datasets are stable (seeded)\n",
    "   - metrics match (within randomness)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
