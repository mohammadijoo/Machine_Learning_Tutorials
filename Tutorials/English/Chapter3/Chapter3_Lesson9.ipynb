{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a90e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&display=swap');\n",
       "\n",
       "\n",
       "/* Text areas (Classic Notebook + JupyterLab) */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "div.rendered_html, .output_subarea {\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "/* RTL for rendered markdown/html content */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "h1, h2, h3, h4, h5, h6, p, strong, label, ol, ul, li {\n",
       "  line-height: 1.9;\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "h1 { font-size: 2rem; color: #070F2B; font-weight: 900}\n",
       "h2 { font-size: 1.8rem; color: #070F2B; font-weight: 800}\n",
       "h3 { font-size: 1.6rem; color: #070F2B; font-weight: 700}\n",
       "h4 { font-size: 1.4rem; color: #1E3E62; font-weight: 600}\n",
       "h5 { font-size: 1.2rem; color: #1E3E62}\n",
       "h6 { font-size: 1rem; color: #1E3E62}\n",
       "p { font-size: 1.1rem; ; font-weight: 400}\n",
       "ol, ul, li, th, td  { font-size: 1rem; }\n",
       "\n",
       "/* Keep code + outputs LTR and monospace */\n",
       ".CodeMirror, .CodeMirror *,\n",
       "pre, code,\n",
       ".jp-CodeCell .jp-InputArea, .jp-CodeCell .jp-InputArea *,\n",
       ".jp-OutputArea, .jp-OutputArea * {\n",
       "  direction: ltr !important;\n",
       "  text-align: left !important;\n",
       "  font-size: 1rem !important;\n",
       "  font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "css = Path(\"../../../css/custom.css\").read_text(encoding=\"utf-8\")\n",
    "display(HTML(f\"<style>{css}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e7b247",
   "metadata": {},
   "source": [
    "# Chapter 3 — Exploratory Data Analysis (EDA)\n",
    "## Lesson 9: Leakage Forensics in EDA (Suspicious Features, Post-Outcome Variables)\n",
    "\n",
    "**What you will learn in this lesson**\n",
    "\n",
    "- Define data leakage precisely and distinguish it from “legitimate signal.”\n",
    "- Use EDA to surface leakage *before* modeling decisions become expensive to unwind.\n",
    "- Detect suspicious features using quick, repeatable diagnostics (single-feature screens, leakage scores, split-sensitivity tests).\n",
    "- Recognize post-outcome variables and enforce an “as-of time” contract for features.\n",
    "- Validate suspicion with controlled experiments: swap splits, remove columns, and confirm performance drops are consistent with leakage.\n",
    "- Establish a reusable leakage-forensics checklist that you can apply to any new dataset.\n",
    "\n",
    "**Datasets used in this lesson (from the repository)**\n",
    "\n",
    "We will use multiple datasets to practice leakage forensics across different contexts:\n",
    "\n",
    "- Classification: `../../../Datasets/Classification/diabetes.csv`\n",
    "- Regression: `../../../Datasets/Regression/house-prices.csv`\n",
    "- Real-world tabular with temporal/process columns: `../../../Datasets/Regression/listings.csv`\n",
    "- Process/workflow dataset (complaints): `../../../Datasets/Clustering/ConsumerComplaints.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10d8273",
   "metadata": {},
   "source": [
    "## 1) Leakage: a precise definition that is actually useful\n",
    "\n",
    "In machine learning practice, **leakage** means that your training data (features, preprocessing, or evaluation protocol) contains information that would **not** be available at the moment you intend to make a prediction in the real world.\n",
    "\n",
    "A practical way to formalize this is to define an **availability boundary**:\n",
    "\n",
    "- Let $t_0$ be the “prediction time” (the time at which you want to score a new example).\n",
    "- A feature $x_j$ is valid only if it can be computed using information available at or before $t_0$.\n",
    "- Leakage occurs when any part of $x$ (or the pipeline that produces $x$) uses information from **after** $t_0$, or otherwise from outside the allowed causal/process boundary.\n",
    "\n",
    "If you train a model $\\hat{y} = f(x)$, leakage can be understood as a violation of the contract:\n",
    "$$x = g(\\text{information available at } t \\le t_0).$$\n",
    "\n",
    "**Why EDA matters:** EDA is where you learn what the columns *really* mean. Many leakage failures happen because the dataset has columns that look “reasonable” but are actually derived from outcomes, operational decisions, or post-hoc measurements.\n",
    "\n",
    "### Leakage vs. “strong signal”\n",
    "A feature can legitimately be highly predictive. So “high correlation” alone is not proof. The difference is about *availability* and *process*:\n",
    "\n",
    "- **Legitimate signal:** available at $t_0$ and causally/process-wise upstream of the outcome.\n",
    "- **Leakage signal:** created after the outcome (or after key decisions), or directly encodes the label.\n",
    "\n",
    "In this lesson, you will learn to combine **semantic checks** (column meaning) and **statistical checks** (suspicious predictive strength + split sensitivity) to decide which case you are dealing with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654b21a1",
   "metadata": {},
   "source": [
    "## 2) A leakage taxonomy you can audit\n",
    "\n",
    "Leakage shows up in several recurring forms. During EDA, you should actively search for these patterns:\n",
    "\n",
    "1. **Target leakage (label leakage):** a feature is a direct function of the target (or a near-proxy).  \n",
    "   Examples: `is_fraud_reviewed`, `chargeback_flag`, `final_grade`, `approved_amount` when predicting approval.\n",
    "\n",
    "2. **Post-outcome variables:** features recorded after the outcome is known, often as part of a workflow.  \n",
    "   Examples: `resolution_code`, `time_to_close`, `refund_amount`, `response_status`.\n",
    "\n",
    "3. **Temporal leakage:** the training split uses future information relative to the test split (time series, cohorts).  \n",
    "   Example: mixing 2025 data into training for predicting 2024 outcomes.\n",
    "\n",
    "4. **Group/entity leakage:** the same entity appears in both train and test, leaking identity-specific information.  \n",
    "   Examples: the same user, patient, device, host, store, or student appearing in both sets.\n",
    "\n",
    "5. **Duplicate leakage / near-duplicates:** exact or nearly identical rows cross the split boundary.\n",
    "\n",
    "6. **Preprocessing leakage:** fitting scalers, imputers, encoders, feature selection, or PCA on the full dataset before splitting.\n",
    "\n",
    "7. **Evaluation leakage:** repeated tuning on the test set, or using the test set to choose features/hyperparameters.\n",
    "\n",
    "**In EDA, you cannot “prove” leakage with a single plot.** Instead, you build a case using:\n",
    "- column semantics and process knowledge, plus\n",
    "- quantitative “suspicion signals,” plus\n",
    "- controlled experiments that isolate the effect of a suspected leak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523f16ac",
   "metadata": {},
   "source": [
    "## 3) Toolkit: fast, repeatable diagnostics (code you can reuse)\n",
    "\n",
    "We will build a small set of helper functions:\n",
    "\n",
    "- `load_csv(path)`: robust loading (types, missing values).\n",
    "- `summarize(df)`: EDA summary (types, missingness, cardinality).\n",
    "- `single_feature_screen(...)`: cross-validated performance using one feature at a time.\n",
    "- `split_sensitivity_test(...)`: compare performance under different splitting strategies (random vs group vs time).\n",
    "- `suspicious_name_scan(...)`: catch columns that look like post-outcome proxies by naming patterns.\n",
    "\n",
    "The goal is not to be perfect; the goal is to quickly identify *which columns deserve investigation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c44e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.base import clone\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def load_csv(path, **kwargs):\n",
    "    \"\"\"Load CSV using a repository-relative path.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"File not found: {path}\\nCheck the repository structure and your working directory.\")\n",
    "    # Try a couple of safe defaults for messy CSVs.\n",
    "    defaults = dict(low_memory=False)\n",
    "    defaults.update(kwargs)\n",
    "    return pd.read_csv(path, **defaults)\n",
    "\n",
    "def summarize(df, max_unique=20):\n",
    "    \"\"\"Basic EDA summary focused on leakage forensics.\"\"\"\n",
    "    out = []\n",
    "    for c in df.columns:\n",
    "        s = df[c]\n",
    "        n = len(s)\n",
    "        n_missing = int(s.isna().sum())\n",
    "        miss_rate = n_missing / max(n, 1)\n",
    "        nunique = int(s.nunique(dropna=True))\n",
    "        dtype = str(s.dtype)\n",
    "        example = s.dropna().iloc[0] if s.dropna().shape[0] else np.nan\n",
    "        out.append({\n",
    "            \"column\": c,\n",
    "            \"dtype\": dtype,\n",
    "            \"missing_rate\": round(miss_rate, 4),\n",
    "            \"nunique\": nunique,\n",
    "            \"example_value\": example if isinstance(example, (int, float, str)) else str(example),\n",
    "            \"low_cardinality\": nunique <= max_unique\n",
    "        })\n",
    "    return pd.DataFrame(out).sort_values([\"missing_rate\", \"nunique\"], ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "def _infer_task(y):\n",
    "    # Heuristic: small number of unique values -> classification\n",
    "    n_unique = y.nunique(dropna=True)\n",
    "    if n_unique <= 20 and (y.dtype == \"object\" or y.dtype.name.startswith(\"int\") or y.dtype.name.startswith(\"bool\")):\n",
    "        return \"classification\"\n",
    "    return \"regression\"\n",
    "\n",
    "def _build_preprocessor(X):\n",
    "    # Drop columns that are entirely missing (common in public CSVs and avoids imputer warnings)\n",
    "    non_empty_cols = [c for c in X.columns if not X[c].isna().all()]\n",
    "    if len(non_empty_cols) == 0:\n",
    "        raise ValueError(\"All feature columns are entirely missing; cannot build a usable preprocessing pipeline.\")\n",
    "    Xn = X[non_empty_cols]\n",
    "\n",
    "    num_cols = Xn.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    cat_cols = [c for c in Xn.columns if c not in num_cols]\n",
    "\n",
    "    numeric = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    ])\n",
    "    categorical = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", min_frequency=5)),\n",
    "    ])\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric, num_cols),\n",
    "            (\"cat\", categorical, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=0.3\n",
    "    )\n",
    "    return pre, num_cols, cat_cols\n",
    "\n",
    "def single_feature_screen(df, target_col, task=None, max_cat_unique=50, cv_splits=5, random_state=42):\n",
    "    \"\"\"Cross-validated performance using one feature at a time. High scores can indicate leakage.\"\"\"\n",
    "    y = df[target_col]\n",
    "    X_all = df.drop(columns=[target_col]).copy()\n",
    "\n",
    "    if task is None:\n",
    "        task = _infer_task(y)\n",
    "\n",
    "    results = []\n",
    "    # Ignore very high-cardinality text/id-like columns to keep the screen fast.\n",
    "    for col in X_all.columns:\n",
    "        s = X_all[col]\n",
    "        nunique = s.nunique(dropna=True)\n",
    "        if s.dtype == \"object\" and nunique > max_cat_unique:\n",
    "            continue\n",
    "\n",
    "        X = X_all[[col]].copy()\n",
    "\n",
    "        pre, _, _ = _build_preprocessor(X)\n",
    "\n",
    "        if task == \"classification\":\n",
    "            # Use a robust linear baseline\n",
    "            model = LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
    "            pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "            cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
    "            scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"roc_auc\")\n",
    "            metric_name = \"roc_auc\"\n",
    "        else:\n",
    "            model = Ridge(alpha=1.0, random_state=random_state)\n",
    "            pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "            cv = KFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
    "            scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"r2\")\n",
    "            metric_name = \"r2\"\n",
    "\n",
    "        results.append({\n",
    "            \"feature\": col,\n",
    "            metric_name: float(np.mean(scores)),\n",
    "            \"std\": float(np.std(scores)),\n",
    "            \"nunique\": int(nunique),\n",
    "            \"dtype\": str(s.dtype)\n",
    "        })\n",
    "\n",
    "    if not results:\n",
    "        return pd.DataFrame(columns=[\"feature\", \"score\", \"std\", \"nunique\", \"dtype\"])\n",
    "\n",
    "    res = pd.DataFrame(results)\n",
    "    score_col = \"roc_auc\" if task == \"classification\" else \"r2\"\n",
    "    return res.sort_values(score_col, ascending=False).reset_index(drop=True)\n",
    "\n",
    "def split_sensitivity_test(df, target_col, drop_cols=None, group_col=None, time_col=None, task=None, cv_splits=5, random_state=42):\n",
    "    \"\"\"Compare performance across splitting strategies. Large deltas can indicate leakage.\"\"\"\n",
    "    drop_cols = drop_cols or []\n",
    "    y = df[target_col]\n",
    "    X = df.drop(columns=[target_col] + drop_cols).copy()\n",
    "\n",
    "    if task is None:\n",
    "        task = _infer_task(y)\n",
    "\n",
    "    pre, _, _ = _build_preprocessor(X)\n",
    "\n",
    "    if task == \"classification\":\n",
    "        model = LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
    "        scoring = \"roc_auc\"\n",
    "    else:\n",
    "        model = Ridge(alpha=1.0, random_state=random_state)\n",
    "        scoring = \"r2\"\n",
    "\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    # Random CV\n",
    "    if task == \"classification\":\n",
    "        cv_random = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
    "    else:\n",
    "        cv_random = KFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
    "    scores[\"random_cv\"] = float(np.mean(cross_val_score(pipe, X, y, cv=cv_random, scoring=scoring)))\n",
    "\n",
    "    # Group CV (if provided)\n",
    "    if group_col is not None:\n",
    "        groups = df[group_col].values\n",
    "        cv_group = GroupKFold(n_splits=min(cv_splits, len(np.unique(groups))))\n",
    "        scores[\"group_cv\"] = float(np.mean(cross_val_score(pipe, X, y, cv=cv_group, groups=groups, scoring=scoring)))\n",
    "\n",
    "    # Time CV (if provided)\n",
    "    if time_col is not None:\n",
    "        # Sort by time and use expanding splits\n",
    "        order = pd.to_datetime(df[time_col], errors=\"coerce\").sort_values().index\n",
    "        X_t = X.loc[order]\n",
    "        y_t = y.loc[order]\n",
    "        tscv = TimeSeriesSplit(n_splits=cv_splits)\n",
    "        scores[\"time_cv\"] = float(np.mean(cross_val_score(pipe, X_t, y_t, cv=tscv, scoring=scoring)))\n",
    "\n",
    "    return scores\n",
    "\n",
    "def suspicious_name_scan(columns):\n",
    "    \"\"\"Flag column names that often correlate with leakage in real projects.\"\"\"\n",
    "    patterns = [\n",
    "        r\"label\", r\"target\", r\"outcome\", r\"response\", r\"resolved\", r\"resolution\", r\"closed\", r\"approved\",\n",
    "        r\"final\", r\"post\", r\"after\", r\"future\", r\"leak\", r\"score\", r\"status\", r\"decision\", r\"payout\",\n",
    "        r\"refund\", r\"chargeback\", r\"dispute\"\n",
    "    ]\n",
    "    rx = re.compile(\"|\".join(patterns), flags=re.IGNORECASE)\n",
    "    flagged = [c for c in columns if rx.search(c)]\n",
    "    return flagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6fd2ec",
   "metadata": {},
   "source": [
    "## 4) Case study A — Diabetes classification: “too good to be true” features\n",
    "\n",
    "We will load the diabetes dataset and run a standard EDA summary. Then we will **simulate** a common leakage failure: a feature that is (directly or indirectly) created from the label.\n",
    "\n",
    "This simulation is intentional: in real projects, leakage often hides inside columns that appear “reasonable” (e.g., codes, derived flags, post-hoc measurements). By creating a leaky feature ourselves, we can verify that our diagnostics actually catch it.\n",
    "\n",
    "**Target:** `classification` (Diabetic vs Non-Diabetic)\n",
    "\n",
    "**Key forensics questions**\n",
    "- Are any columns suspicious by name?\n",
    "- Does any single feature achieve extremely high ROC-AUC by itself?\n",
    "- Does overall performance collapse if the suspicious feature is removed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa866644",
   "metadata": {},
   "source": [
    "### 4.1 Load and summarize\n",
    "\n",
    "Start by inspecting missingness, data types, and cardinality. Leakage often correlates with:\n",
    "- columns that are IDs (high cardinality),\n",
    "- workflow/status fields,\n",
    "- timestamps or “final outcome” fields,\n",
    "- post-processed aggregates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c53534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>Non-Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>Non-Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age classification  \n",
       "0                     0.627   50       Diabetic  \n",
       "1                     0.351   31   Non-Diabetic  \n",
       "2                     0.672   32       Diabetic  \n",
       "3                     0.167   21   Non-Diabetic  \n",
       "4                     2.288   33       Diabetic  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>missing_rate</th>\n",
       "      <th>nunique</th>\n",
       "      <th>example_value</th>\n",
       "      <th>low_cardinality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>517</td>\n",
       "      <td>0.627</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248</td>\n",
       "      <td>33.6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136</td>\n",
       "      <td>148</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Age</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>72</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>classification</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Diabetic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     column    dtype  missing_rate  nunique example_value  \\\n",
       "0  DiabetesPedigreeFunction  float64           0.0      517         0.627   \n",
       "1                       BMI  float64           0.0      248          33.6   \n",
       "2                   Insulin    int64           0.0      186             0   \n",
       "3                   Glucose    int64           0.0      136           148   \n",
       "4                       Age    int64           0.0       52            50   \n",
       "5             SkinThickness    int64           0.0       51            35   \n",
       "6             BloodPressure    int64           0.0       47            72   \n",
       "7               Pregnancies    int64           0.0       17             6   \n",
       "8            classification   object           0.0        2      Diabetic   \n",
       "\n",
       "   low_cardinality  \n",
       "0            False  \n",
       "1            False  \n",
       "2            False  \n",
       "3            False  \n",
       "4            False  \n",
       "5            False  \n",
       "6            False  \n",
       "7             True  \n",
       "8             True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagged by name patterns: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>std</th>\n",
       "      <th>nunique</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leaky_proxy</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>768</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.787365</td>\n",
       "      <td>0.026682</td>\n",
       "      <td>136</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.688052</td>\n",
       "      <td>0.032472</td>\n",
       "      <td>248</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.685324</td>\n",
       "      <td>0.037894</td>\n",
       "      <td>52</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.619985</td>\n",
       "      <td>0.037818</td>\n",
       "      <td>17</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.603836</td>\n",
       "      <td>0.052310</td>\n",
       "      <td>517</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.587046</td>\n",
       "      <td>0.037250</td>\n",
       "      <td>47</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.553768</td>\n",
       "      <td>0.049009</td>\n",
       "      <td>51</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.536359</td>\n",
       "      <td>0.070975</td>\n",
       "      <td>186</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature   roc_auc       std  nunique    dtype\n",
       "0               leaky_proxy  1.000000  0.000000      768  float64\n",
       "1                   Glucose  0.787365  0.026682      136    int64\n",
       "2                       BMI  0.688052  0.032472      248  float64\n",
       "3                       Age  0.685324  0.037894       52    int64\n",
       "4               Pregnancies  0.619985  0.037818       17    int64\n",
       "5  DiabetesPedigreeFunction  0.603836  0.052310      517  float64\n",
       "6             BloodPressure  0.587046  0.037250       47    int64\n",
       "7             SkinThickness  0.553768  0.049009       51    int64\n",
       "8                   Insulin  0.536359  0.070975      186    int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores WITH leaky feature: {'random_cv': 1.0}\n",
      "Scores WITHOUT leaky feature: {'random_cv': 0.8303878406708595}\n"
     ]
    }
   ],
   "source": [
    "# --- Case study A: diabetes.csv ---\n",
    "diabetes_path = \"../../../Datasets/Classification/diabetes.csv\"\n",
    "df_diabetes = load_csv(diabetes_path)\n",
    "\n",
    "display(df_diabetes.head())\n",
    "summary_diabetes = summarize(df_diabetes)\n",
    "display(summary_diabetes)\n",
    "\n",
    "# Suspicious name scan\n",
    "flagged = suspicious_name_scan(df_diabetes.columns)\n",
    "print(\"Flagged by name patterns:\", flagged)\n",
    "\n",
    "# Ensure target is binary for ROC-AUC\n",
    "df_diabetes = df_diabetes.copy()\n",
    "df_diabetes[\"y\"] = (df_diabetes[\"classification\"].astype(str).str.lower() == \"diabetic\").astype(int)\n",
    "\n",
    "# Inject a leaky proxy: label plus tiny noise (mimics a post-outcome proxy)\n",
    "rng = np.random.default_rng(42)\n",
    "df_diabetes[\"leaky_proxy\"] = df_diabetes[\"y\"] + rng.normal(0, 0.03, size=len(df_diabetes))\n",
    "\n",
    "# Build a modeling frame\n",
    "df_d = df_diabetes.drop(columns=[\"classification\"]).copy()\n",
    "\n",
    "# Single-feature screen\n",
    "screen_d = single_feature_screen(df_d, target_col=\"y\", task=\"classification\", max_cat_unique=50, cv_splits=5)\n",
    "display(screen_d.head(15))\n",
    "\n",
    "# Split sensitivity with and without the leaky feature\n",
    "scores_with = split_sensitivity_test(df_d, target_col=\"y\", task=\"classification\", cv_splits=5)\n",
    "scores_without = split_sensitivity_test(df_d.drop(columns=[\"leaky_proxy\"]), target_col=\"y\", task=\"classification\", cv_splits=5)\n",
    "print(\"Scores WITH leaky feature:\", scores_with)\n",
    "print(\"Scores WITHOUT leaky feature:\", scores_without)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70295724",
   "metadata": {},
   "source": [
    "### 4.2 Inject a leaky proxy and detect it\n",
    "\n",
    "We create a synthetic feature `leaky_proxy` that encodes the label with small noise.\n",
    "In a real dataset, this could correspond to a “post-diagnosis treatment code” or a “billing class” that effectively reveals the target.\n",
    "\n",
    "Your diagnostics should rank this feature near the top in the single-feature screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04ee9ad",
   "metadata": {},
   "source": [
    "### 4.3 Interpreting results (how to reason, not just compute)\n",
    "\n",
    "If you see a feature with **ROC-AUC close to 1.0** in a single-feature screen, treat it as a red alert:\n",
    "\n",
    "- It might be a direct encoding of the target.\n",
    "- It might be a deterministic consequence of the target (post-outcome).\n",
    "- It might be an ID that indirectly reveals the target because of data collection artifacts.\n",
    "\n",
    "The correct next step is not “drop it immediately,” but to ask:\n",
    "\n",
    "1. **When is this feature available?** (Define $t_0$.)\n",
    "2. **Who/what generates it?** (Operational workflow? Human review? Billing?)\n",
    "3. **Can it be computed without knowing the target?** (If not, it is leakage.)\n",
    "\n",
    "In real projects, these questions are answered with domain experts, data lineage, and system logs. In EDA, your job is to *surface the candidates*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de1824",
   "metadata": {},
   "source": [
    "## 5) Case study B — House prices regression: leakage via “derived from target” features\n",
    "\n",
    "In regression, leakage often happens when someone creates “helpful” features that are algebraic rearrangements of the target. For example:\n",
    "\n",
    "- predicting `Price` and adding a feature `Price_per_sqft = Price / SqFt`  \n",
    "  This is effectively giving the model the answer.\n",
    "\n",
    "We will:\n",
    "- load `house-prices.csv`,\n",
    "- build a baseline model to estimate performance,\n",
    "- inject two leaky engineered features,\n",
    "- confirm that the leakage shows up in the single-feature screen and in performance inflation.\n",
    "\n",
    "**Target:** `Price`\n",
    "\n",
    "**Red flag heuristic:** if a feature is *mathematically constrained* by the target, $x_j = h(y, \\cdot)$, then it is not a valid feature for predicting $y$ at scoring time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ba6faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home</th>\n",
       "      <th>Price</th>\n",
       "      <th>SqFt</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Offers</th>\n",
       "      <th>Brick</th>\n",
       "      <th>Neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114300</td>\n",
       "      <td>1790</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>114200</td>\n",
       "      <td>2030</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>114800</td>\n",
       "      <td>1740</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>94700</td>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>119800</td>\n",
       "      <td>2130</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Home   Price  SqFt  Bedrooms  Bathrooms  Offers Brick Neighborhood\n",
       "0     1  114300  1790         2          2       2    No         East\n",
       "1     2  114200  2030         4          2       3    No         East\n",
       "2     3  114800  1740         3          2       1    No         East\n",
       "3     4   94700  1980         3          2       3    No         East\n",
       "4     5  119800  2130         3          3       3    No         East"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>missing_rate</th>\n",
       "      <th>nunique</th>\n",
       "      <th>example_value</th>\n",
       "      <th>low_cardinality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Price</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123</td>\n",
       "      <td>114300</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SqFt</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61</td>\n",
       "      <td>1790</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Offers</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bedrooms</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bathrooms</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>East</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Brick</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         column   dtype  missing_rate  nunique example_value  low_cardinality\n",
       "0          Home   int64           0.0      128             1            False\n",
       "1         Price   int64           0.0      123        114300            False\n",
       "2          SqFt   int64           0.0       61          1790            False\n",
       "3        Offers   int64           0.0        6             2             True\n",
       "4      Bedrooms   int64           0.0        4             2             True\n",
       "5     Bathrooms   int64           0.0        3             2             True\n",
       "6  Neighborhood  object           0.0        3          East             True\n",
       "7         Brick  object           0.0        2            No             True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>std</th>\n",
       "      <th>nunique</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_price_leak</td>\n",
       "      <td>0.977711</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>123</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>price_per_sqft_leak</td>\n",
       "      <td>0.683828</td>\n",
       "      <td>0.083864</td>\n",
       "      <td>128</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>0.450231</td>\n",
       "      <td>0.126492</td>\n",
       "      <td>3</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SqFt</td>\n",
       "      <td>0.228876</td>\n",
       "      <td>0.100532</td>\n",
       "      <td>61</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bedrooms</td>\n",
       "      <td>0.227696</td>\n",
       "      <td>0.182803</td>\n",
       "      <td>4</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bathrooms</td>\n",
       "      <td>0.120441</td>\n",
       "      <td>0.232334</td>\n",
       "      <td>3</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brick</td>\n",
       "      <td>0.092262</td>\n",
       "      <td>0.104749</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Offers</td>\n",
       "      <td>-0.016599</td>\n",
       "      <td>0.113085</td>\n",
       "      <td>6</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Home</td>\n",
       "      <td>-0.104937</td>\n",
       "      <td>0.113642</td>\n",
       "      <td>128</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature        r2       std  nunique    dtype\n",
       "0       log_price_leak  0.977711  0.007256      123  float64\n",
       "1  price_per_sqft_leak  0.683828  0.083864      128  float64\n",
       "2         Neighborhood  0.450231  0.126492        3   object\n",
       "3                 SqFt  0.228876  0.100532       61    int64\n",
       "4             Bedrooms  0.227696  0.182803        4    int64\n",
       "5            Bathrooms  0.120441  0.232334        3    int64\n",
       "6                Brick  0.092262  0.104749        2   object\n",
       "7               Offers -0.016599  0.113085        6    int64\n",
       "8                 Home -0.104937  0.113642      128    int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression scores WITH leaky features: {'random_cv': 0.9895991548830227}\n",
      "Regression scores WITHOUT leaky features: {'random_cv': 0.8275952075387714}\n"
     ]
    }
   ],
   "source": [
    "# --- Case study B: house-prices.csv ---\n",
    "house_path = \"../../../Datasets/Regression/house-prices.csv\"\n",
    "df_house = load_csv(house_path)\n",
    "\n",
    "display(df_house.head())\n",
    "display(summarize(df_house))\n",
    "\n",
    "# Baseline: predict Price\n",
    "df_h = df_house.copy()\n",
    "\n",
    "# Inject leaky engineered features\n",
    "df_h[\"price_per_sqft_leak\"] = df_h[\"Price\"] / df_h[\"SqFt\"].replace(0, np.nan)\n",
    "df_h[\"log_price_leak\"] = np.log1p(df_h[\"Price\"])\n",
    "\n",
    "# Screen single features for regression\n",
    "screen_h = single_feature_screen(df_h, target_col=\"Price\", task=\"regression\", max_cat_unique=50, cv_splits=5)\n",
    "display(screen_h.head(15))\n",
    "\n",
    "# Compare performance with and without leaky columns\n",
    "scores_with = split_sensitivity_test(df_h, target_col=\"Price\", task=\"regression\", cv_splits=5)\n",
    "scores_without = split_sensitivity_test(df_h.drop(columns=[\"price_per_sqft_leak\", \"log_price_leak\"]), target_col=\"Price\", task=\"regression\", cv_splits=5)\n",
    "\n",
    "print(\"Regression scores WITH leaky features:\", scores_with)\n",
    "print(\"Regression scores WITHOUT leaky features:\", scores_without)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6b368b",
   "metadata": {},
   "source": [
    "## 6) Case study C — Listings data: post-outcome columns and split sensitivity\n",
    "\n",
    "Real-world datasets often contain columns that are only known **after** some operational history has occurred.\n",
    "For listings data, common post-outcome-ish columns include:\n",
    "- `number_of_reviews`, `reviews_per_month`, `last_review` (depend on future bookings/reviews)\n",
    "- `availability_365` (depends on future calendar occupancy)\n",
    "\n",
    "Suppose your intended prediction is: “Estimate the listing price at the time the listing is created.”\n",
    "Then review-related columns may violate the $t_0$ contract.\n",
    "\n",
    "In addition, listings have natural **groups** (e.g., `host_id`). If the same host appears in both train and test, random CV can look overly optimistic.\n",
    "\n",
    "We will demonstrate:\n",
    "- name-based suspicion scan,\n",
    "- group split vs random split,\n",
    "- time-aware split (when a usable time column exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec6e735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13913</td>\n",
       "      <td>Holiday London DB Room Let-on going</td>\n",
       "      <td>54730</td>\n",
       "      <td>Alina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Islington</td>\n",
       "      <td>51.56861</td>\n",
       "      <td>-0.11270</td>\n",
       "      <td>Private room</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2025-02-09</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3</td>\n",
       "      <td>344</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15400</td>\n",
       "      <td>Bright Chelsea  Apartment. Chelsea!</td>\n",
       "      <td>60302</td>\n",
       "      <td>Philippa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kensington and Chelsea</td>\n",
       "      <td>51.48780</td>\n",
       "      <td>-0.16813</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>2024-04-28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17402</td>\n",
       "      <td>Very Central Modern 3-Bed/2 Bath By Oxford St W1</td>\n",
       "      <td>67564</td>\n",
       "      <td>Liz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>51.52195</td>\n",
       "      <td>-0.14094</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>510.0</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>5</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24328</td>\n",
       "      <td>Battersea live/work artist house</td>\n",
       "      <td>41759</td>\n",
       "      <td>Joe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>51.47072</td>\n",
       "      <td>-0.16266</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>213.0</td>\n",
       "      <td>90</td>\n",
       "      <td>94</td>\n",
       "      <td>2022-07-19</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31036</td>\n",
       "      <td>Bright  compact 1 Bedroom Apartment Brick Lane</td>\n",
       "      <td>133271</td>\n",
       "      <td>Hendryks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>51.52425</td>\n",
       "      <td>-0.06997</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              name  host_id host_name  \\\n",
       "0  13913               Holiday London DB Room Let-on going    54730     Alina   \n",
       "1  15400               Bright Chelsea  Apartment. Chelsea!    60302  Philippa   \n",
       "2  17402  Very Central Modern 3-Bed/2 Bath By Oxford St W1    67564       Liz   \n",
       "3  24328                  Battersea live/work artist house    41759       Joe   \n",
       "4  31036    Bright  compact 1 Bedroom Apartment Brick Lane   133271  Hendryks   \n",
       "\n",
       "   neighbourhood_group           neighbourhood  latitude  longitude  \\\n",
       "0                  NaN               Islington  51.56861   -0.11270   \n",
       "1                  NaN  Kensington and Chelsea  51.48780   -0.16813   \n",
       "2                  NaN             Westminster  51.52195   -0.14094   \n",
       "3                  NaN              Wandsworth  51.47072   -0.16266   \n",
       "4                  NaN           Tower Hamlets  51.52425   -0.06997   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room   57.0               1                 51  2025-02-09   \n",
       "1  Entire home/apt    NaN               4                 96  2024-04-28   \n",
       "2  Entire home/apt  510.0               3                 56  2024-02-19   \n",
       "3  Entire home/apt  213.0              90                 94  2022-07-19   \n",
       "4  Entire home/apt  100.0               2                126  2025-02-20   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \\\n",
       "0               0.29                               3               344   \n",
       "1               0.52                               1                11   \n",
       "2               0.33                               5               293   \n",
       "3               0.54                               1               194   \n",
       "4               0.70                               8               353   \n",
       "\n",
       "   number_of_reviews_ltm  license  \n",
       "0                     10      NaN  \n",
       "1                      2      NaN  \n",
       "2                      0      NaN  \n",
       "3                      0      NaN  \n",
       "4                      3      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>missing_rate</th>\n",
       "      <th>nunique</th>\n",
       "      <th>example_value</th>\n",
       "      <th>low_cardinality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neighbourhood_group</td>\n",
       "      <td>float64</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>license</td>\n",
       "      <td>float64</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>price</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.3619</td>\n",
       "      <td>1239</td>\n",
       "      <td>57.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>last_review</td>\n",
       "      <td>object</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>3444</td>\n",
       "      <td>2025-02-09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reviews_per_month</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>868</td>\n",
       "      <td>0.29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>host_name</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>16416</td>\n",
       "      <td>Alina</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>94559</td>\n",
       "      <td>13913</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>name</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>90942</td>\n",
       "      <td>Holiday London DB Room Let-on going</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>longitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>61792</td>\n",
       "      <td>-0.1127</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>host_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>55395</td>\n",
       "      <td>54730</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>latitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>52417</td>\n",
       "      <td>51.56861</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>number_of_reviews</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>552</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>availability_365</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>366</td>\n",
       "      <td>344</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>number_of_reviews_ltm</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>139</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>minimum_nights</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>calculated_host_listings_count</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>neighbourhood</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>33</td>\n",
       "      <td>Islington</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>room_type</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>Private room</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            column    dtype  missing_rate  nunique  \\\n",
       "0              neighbourhood_group  float64        1.0000        0   \n",
       "1                          license  float64        1.0000        0   \n",
       "2                            price  float64        0.3619     1239   \n",
       "3                      last_review   object        0.2564     3444   \n",
       "4                reviews_per_month  float64        0.2564      868   \n",
       "5                        host_name   object        0.0006    16416   \n",
       "6                               id    int64        0.0000    94559   \n",
       "7                             name   object        0.0000    90942   \n",
       "8                        longitude  float64        0.0000    61792   \n",
       "9                          host_id    int64        0.0000    55395   \n",
       "10                        latitude  float64        0.0000    52417   \n",
       "11               number_of_reviews    int64        0.0000      552   \n",
       "12                availability_365    int64        0.0000      366   \n",
       "13           number_of_reviews_ltm    int64        0.0000      139   \n",
       "14                  minimum_nights    int64        0.0000      138   \n",
       "15  calculated_host_listings_count    int64        0.0000       95   \n",
       "16                   neighbourhood   object        0.0000       33   \n",
       "17                       room_type   object        0.0000        4   \n",
       "\n",
       "                          example_value  low_cardinality  \n",
       "0                                   NaN             True  \n",
       "1                                   NaN             True  \n",
       "2                                  57.0            False  \n",
       "3                            2025-02-09            False  \n",
       "4                                  0.29            False  \n",
       "5                                 Alina            False  \n",
       "6                                 13913            False  \n",
       "7   Holiday London DB Room Let-on going            False  \n",
       "8                               -0.1127            False  \n",
       "9                                 54730            False  \n",
       "10                             51.56861            False  \n",
       "11                                   51            False  \n",
       "12                                  344            False  \n",
       "13                                   10            False  \n",
       "14                                    1            False  \n",
       "15                                    3            False  \n",
       "16                            Islington            False  \n",
       "17                         Private room             True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential post-outcome columns present: ['number_of_reviews', 'last_review', 'reviews_per_month', 'number_of_reviews_ltm', 'availability_365']\n",
      "Flagged by name patterns: []\n",
      "Scores (random/group/time if available): {'random_cv': 0.9994904216839016, 'group_cv': 0.9994761209249441, 'time_cv': 0.9973845805463218}\n",
      "Scores after dropping suspected post-outcome columns: {'random_cv': 0.9997040883162702, 'group_cv': 0.9996974451218641}\n"
     ]
    }
   ],
   "source": [
    "# --- Case study C: listings.csv ---\n",
    "listings_path = \"../../../Datasets/Regression/listings.csv\"\n",
    "df_listings = load_csv(listings_path)\n",
    "\n",
    "display(df_listings.head())\n",
    "display(summarize(df_listings))\n",
    "\n",
    "# Define a simple target to keep the tutorial self-contained:\n",
    "# Predict whether a listing is \"high price\" (binary classification).\n",
    "# (We ignore rows with missing price.)\n",
    "dfl = df_listings.copy()\n",
    "dfl[\"price\"] = pd.to_numeric(dfl[\"price\"], errors=\"coerce\")\n",
    "dfl = dfl.dropna(subset=[\"price\"]).reset_index(drop=True)\n",
    "\n",
    "# Median-based label (robust and easy to explain)\n",
    "median_price = float(dfl[\"price\"].median())\n",
    "dfl[\"y_high_price\"] = (dfl[\"price\"] >= median_price).astype(int)\n",
    "\n",
    "# Columns that may be post-outcome relative to listing creation time\n",
    "suspected_post_outcome = [\"number_of_reviews\", \"last_review\", \"reviews_per_month\", \"number_of_reviews_ltm\", \"availability_365\"]\n",
    "present_suspects = [c for c in suspected_post_outcome if c in dfl.columns]\n",
    "print(\"Potential post-outcome columns present:\", present_suspects)\n",
    "\n",
    "# Quick name scan\n",
    "flagged = suspicious_name_scan(dfl.columns)\n",
    "print(\"Flagged by name patterns:\", flagged)\n",
    "\n",
    "# Compare random CV vs group CV (host_id)\n",
    "drop_cols = []\n",
    "for c in [\"id\", \"name\", \"host_name\", \"license\"]:\n",
    "    if c in dfl.columns:\n",
    "        drop_cols.append(c)\n",
    "\n",
    "# Include suspects first, then compare when we drop them\n",
    "scores_random_vs_group = split_sensitivity_test(\n",
    "    dfl.drop(columns=drop_cols),\n",
    "    target_col=\"y_high_price\",\n",
    "    task=\"classification\",\n",
    "    group_col=\"host_id\" if \"host_id\" in dfl.columns else None,\n",
    "    time_col=\"last_review\" if \"last_review\" in dfl.columns else None,\n",
    "    cv_splits=5\n",
    ")\n",
    "print(\"Scores (random/group/time if available):\", scores_random_vs_group)\n",
    "\n",
    "# Now drop suspected post-outcome features and re-test\n",
    "cols_to_drop = [c for c in present_suspects if c in dfl.columns]\n",
    "dfl_noleak = dfl.drop(columns=cols_to_drop + drop_cols, errors=\"ignore\")\n",
    "scores_no_post = split_sensitivity_test(\n",
    "    dfl_noleak,\n",
    "    target_col=\"y_high_price\",\n",
    "    task=\"classification\",\n",
    "    group_col=\"host_id\" if \"host_id\" in dfl_noleak.columns else None,\n",
    "    time_col=\"last_review\" if \"last_review\" in dfl_noleak.columns else None,\n",
    "    cv_splits=5\n",
    ")\n",
    "print(\"Scores after dropping suspected post-outcome columns:\", scores_no_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac11c6",
   "metadata": {},
   "source": [
    "### 6.1 How to interpret split sensitivity\n",
    "\n",
    "When **random CV** is much higher than **group CV**, a typical explanation is entity leakage:\n",
    "\n",
    "- The model learns host-specific patterns (or neighborhood identity proxies).\n",
    "- The test fold contains the same hosts, making the problem easier than real deployment.\n",
    "\n",
    "When **time-aware CV** is worse than random CV, a typical explanation is temporal leakage and distribution shift:\n",
    "\n",
    "- future patterns leak into training when you ignore time,\n",
    "- the data-generating process changes across time (concept drift).\n",
    "\n",
    "Split sensitivity does not *prove* leakage. It tells you **where to investigate**:\n",
    "- Which columns are effectively “ID-like”?\n",
    "- Which columns require an as-of-time policy?\n",
    "- Are you accidentally learning a cohort artifact rather than a generalizable relationship?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda82f0",
   "metadata": {},
   "source": [
    "## 7) Case study D — Consumer complaints: post-outcome workflow columns\n",
    "\n",
    "The complaints dataset is an excellent leakage playground because it contains both:\n",
    "- early-stage intake information (what is known when a complaint arrives), and\n",
    "- later-stage workflow outcomes (what happens after the complaint is processed).\n",
    "\n",
    "To make the “as-of time” boundary explicit, define a realistic prediction:\n",
    "\n",
    "**Prediction objective:** predict whether a consumer will dispute the resolution (`Consumer Disputed`) *at the time the complaint is received*.\n",
    "\n",
    "At that moment, many columns are **not** available yet:\n",
    "- `Company Response to Consumer`\n",
    "- `Timely Response`\n",
    "- `Date Sent to Company`\n",
    "- `Company Public Response`\n",
    "- sometimes even internal status codes\n",
    "\n",
    "Using these columns can create severe leakage: you are using the resolution process to predict whether the consumer disputes it.\n",
    "\n",
    "We will:\n",
    "- load the dataset,\n",
    "- build two feature sets (intake-only vs intake+workflow),\n",
    "- compare performance,\n",
    "- and identify the columns that create the biggest inflation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e57a625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Received</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sub Product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub Issue</th>\n",
       "      <th>Consumer Complaint Narrative</th>\n",
       "      <th>Company Public Response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State Name</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer Consent Provided</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date Sent to Company</th>\n",
       "      <th>Company Response to Consumer</th>\n",
       "      <th>Timely Response</th>\n",
       "      <th>Consumer Disputed</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Vehicle loan</td>\n",
       "      <td>Managing the loan or lease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>VA</td>\n",
       "      <td>24540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phone</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>468882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>Checking account</td>\n",
       "      <td>Using a debit or ATM card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>CA</td>\n",
       "      <td>95992</td>\n",
       "      <td>Older American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>468889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>Checking account</td>\n",
       "      <td>Account opening, closing, or management</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Santander Bank US</td>\n",
       "      <td>NY</td>\n",
       "      <td>10065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fax</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>468879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>Checking account</td>\n",
       "      <td>Deposits and withdrawals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>GA</td>\n",
       "      <td>30084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>468949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Conventional fixed mortgage</td>\n",
       "      <td>Loan servicing, payments, escrow account</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Franklin Credit Management</td>\n",
       "      <td>CT</td>\n",
       "      <td>6106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>475823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date Received             Product Name                  Sub Product  \\\n",
       "0    2013-07-29            Consumer Loan                 Vehicle loan   \n",
       "1    2013-07-29  Bank account or service             Checking account   \n",
       "2    2013-07-29  Bank account or service             Checking account   \n",
       "3    2013-07-29  Bank account or service             Checking account   \n",
       "4    2013-07-29                 Mortgage  Conventional fixed mortgage   \n",
       "\n",
       "                                      Issue Sub Issue  \\\n",
       "0                Managing the loan or lease       NaN   \n",
       "1                 Using a debit or ATM card       NaN   \n",
       "2   Account opening, closing, or management       NaN   \n",
       "3                  Deposits and withdrawals       NaN   \n",
       "4  Loan servicing, payments, escrow account       NaN   \n",
       "\n",
       "  Consumer Complaint Narrative Company Public Response  \\\n",
       "0                          NaN                     NaN   \n",
       "1                          NaN                     NaN   \n",
       "2                          NaN                     NaN   \n",
       "3                          NaN                     NaN   \n",
       "4                          NaN                     NaN   \n",
       "\n",
       "                      Company State Name Zip Code            Tags  \\\n",
       "0       Wells Fargo & Company         VA    24540             NaN   \n",
       "1       Wells Fargo & Company         CA    95992  Older American   \n",
       "2           Santander Bank US         NY    10065             NaN   \n",
       "3       Wells Fargo & Company         GA    30084             NaN   \n",
       "4  Franklin Credit Management         CT     6106             NaN   \n",
       "\n",
       "  Consumer Consent Provided Submitted via Date Sent to Company  \\\n",
       "0                       NaN         Phone           2013-07-30   \n",
       "1                       NaN           Web           2013-07-31   \n",
       "2                       NaN           Fax           2013-07-31   \n",
       "3                       NaN           Web           2013-07-30   \n",
       "4                       NaN           Web           2013-07-30   \n",
       "\n",
       "  Company Response to Consumer Timely Response Consumer Disputed  Complaint ID  \n",
       "0      Closed with explanation             Yes                No        468882  \n",
       "1      Closed with explanation             Yes                No        468889  \n",
       "2                       Closed             Yes                No        468879  \n",
       "3      Closed with explanation             Yes                No        468949  \n",
       "4      Closed with explanation             Yes                No        475823  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>missing_rate</th>\n",
       "      <th>nunique</th>\n",
       "      <th>example_value</th>\n",
       "      <th>low_cardinality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company Public Response</td>\n",
       "      <td>object</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>9</td>\n",
       "      <td>Company chooses not to provide a public response</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consumer Complaint Narrative</td>\n",
       "      <td>object</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>2592</td>\n",
       "      <td>Received Capital One charge card offer XXXX. A...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consumer Consent Provided</td>\n",
       "      <td>object</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>3</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tags</td>\n",
       "      <td>object</td>\n",
       "      <td>0.8522</td>\n",
       "      <td>3</td>\n",
       "      <td>Older American</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sub Issue</td>\n",
       "      <td>object</td>\n",
       "      <td>0.5319</td>\n",
       "      <td>67</td>\n",
       "      <td>Debt is not mine</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sub Product</td>\n",
       "      <td>object</td>\n",
       "      <td>0.2834</td>\n",
       "      <td>45</td>\n",
       "      <td>Vehicle loan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Consumer Disputed</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zip Code</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>14851</td>\n",
       "      <td>24540</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>State Name</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>59</td>\n",
       "      <td>VA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Complaint ID</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>65499</td>\n",
       "      <td>468882</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Company</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1878</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Date Sent to Company</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>717</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Date Received</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>683</td>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Issue</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>91</td>\n",
       "      <td>Managing the loan or lease</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Product Name</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Submitted via</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6</td>\n",
       "      <td>Phone</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Company Response to Consumer</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timely Response</td>\n",
       "      <td>object</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          column   dtype  missing_rate  nunique  \\\n",
       "0        Company Public Response  object        0.9626        9   \n",
       "1   Consumer Complaint Narrative  object        0.9601     2592   \n",
       "2      Consumer Consent Provided  object        0.9273        3   \n",
       "3                           Tags  object        0.8522        3   \n",
       "4                      Sub Issue  object        0.5319       67   \n",
       "5                    Sub Product  object        0.2834       45   \n",
       "6              Consumer Disputed  object        0.0169        2   \n",
       "7                       Zip Code  object        0.0073    14851   \n",
       "8                     State Name  object        0.0073       59   \n",
       "9                   Complaint ID   int64        0.0000    65499   \n",
       "10                       Company  object        0.0000     1878   \n",
       "11          Date Sent to Company  object        0.0000      717   \n",
       "12                 Date Received  object        0.0000      683   \n",
       "13                         Issue  object        0.0000       91   \n",
       "14                  Product Name  object        0.0000       11   \n",
       "15                 Submitted via  object        0.0000        6   \n",
       "16  Company Response to Consumer  object        0.0000        5   \n",
       "17               Timely Response  object        0.0000        2   \n",
       "\n",
       "                                        example_value  low_cardinality  \n",
       "0    Company chooses not to provide a public response             True  \n",
       "1   Received Capital One charge card offer XXXX. A...            False  \n",
       "2                                    Consent provided             True  \n",
       "3                                      Older American             True  \n",
       "4                                    Debt is not mine            False  \n",
       "5                                        Vehicle loan            False  \n",
       "6                                                  No             True  \n",
       "7                                               24540            False  \n",
       "8                                                  VA            False  \n",
       "9                                              468882            False  \n",
       "10                              Wells Fargo & Company            False  \n",
       "11                                         2013-07-30            False  \n",
       "12                                         2013-07-29            False  \n",
       "13                         Managing the loan or lease            False  \n",
       "14                                      Consumer Loan             True  \n",
       "15                                              Phone             True  \n",
       "16                            Closed with explanation             True  \n",
       "17                                                Yes             True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intake columns: ['Date Received', 'Product Name', 'Sub Product', 'Issue', 'Sub Issue', 'Company', 'State Name', 'Zip Code', 'Tags', 'Submitted via']\n",
      "Workflow columns: ['Date Sent to Company', 'Company Response to Consumer', 'Company Public Response', 'Timely Response', 'Complaint ID']\n",
      "Intake-only scores: {'random_cv': 0.5900515995185385}\n",
      "Intake+workflow scores: {'random_cv': 0.6054917298073457}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>std</th>\n",
       "      <th>nunique</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company Response to Consumer</td>\n",
       "      <td>0.553540</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>4</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product Name</td>\n",
       "      <td>0.544824</td>\n",
       "      <td>0.009093</td>\n",
       "      <td>11</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sub Product</td>\n",
       "      <td>0.543912</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>45</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Submitted via</td>\n",
       "      <td>0.543063</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>6</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Complaint ID</td>\n",
       "      <td>0.505308</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>64391</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Company Public Response</td>\n",
       "      <td>0.501944</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>9</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tags</td>\n",
       "      <td>0.501036</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>3</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Timely Response</td>\n",
       "      <td>0.500367</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature   roc_auc       std  nunique   dtype\n",
       "0  Company Response to Consumer  0.553540  0.003773        4  object\n",
       "1                  Product Name  0.544824  0.009093       11  object\n",
       "2                   Sub Product  0.543912  0.006271       45  object\n",
       "3                 Submitted via  0.543063  0.001527        6  object\n",
       "4                  Complaint ID  0.505308  0.004983    64391   int64\n",
       "5       Company Public Response  0.501944  0.000621        9  object\n",
       "6                          Tags  0.501036  0.001619        3  object\n",
       "7               Timely Response  0.500367  0.001001        2  object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Case study D: ConsumerComplaints.csv ---\n",
    "complaints_path = \"../../../Datasets/Clustering/ConsumerComplaints.csv\"\n",
    "df_cc = load_csv(complaints_path)\n",
    "\n",
    "display(df_cc.head())\n",
    "display(summarize(df_cc))\n",
    "\n",
    "# Clean up target: Consumer Disputed (Yes/No)\n",
    "dfc = df_cc.copy()\n",
    "if \"Consumer Disputed\" not in dfc.columns:\n",
    "    raise ValueError(\"Expected column 'Consumer Disputed' not found in ConsumerComplaints.csv\")\n",
    "\n",
    "# Drop rows where target is missing\n",
    "dfc = dfc.dropna(subset=[\"Consumer Disputed\"]).reset_index(drop=True)\n",
    "\n",
    "dfc[\"y_disputed\"] = (dfc[\"Consumer Disputed\"].astype(str).str.strip().str.lower() == \"yes\").astype(int)\n",
    "\n",
    "# Define intake-time columns (best-effort, based on typical intake fields)\n",
    "intake_cols = []\n",
    "for c in [\"Date Received\", \"Product Name\", \"Sub Product\", \"Issue\", \"Sub Issue\", \"Company\", \"State Name\", \"Zip Code\", \"Tags\", \"Submitted via\"]:\n",
    "    if c in dfc.columns:\n",
    "        intake_cols.append(c)\n",
    "\n",
    "# Define workflow/post-outcome-ish columns (likely not known at intake time)\n",
    "workflow_cols = []\n",
    "for c in [\"Date Sent to Company\", \"Company Response to Consumer\", \"Company Public Response\", \"Timely Response\", \"Complaint ID\"]:\n",
    "    if c in dfc.columns:\n",
    "        workflow_cols.append(c)\n",
    "\n",
    "print(\"Intake columns:\", intake_cols)\n",
    "print(\"Workflow columns:\", workflow_cols)\n",
    "\n",
    "# Build two datasets:\n",
    "# 1) intake-only\n",
    "df_intake = dfc[intake_cols + [\"y_disputed\"]].copy()\n",
    "\n",
    "# 2) intake + workflow\n",
    "df_full = dfc[intake_cols + workflow_cols + [\"y_disputed\"]].copy()\n",
    "\n",
    "# Evaluate split sensitivity (random CV) as a quick proxy\n",
    "scores_intake = split_sensitivity_test(df_intake, target_col=\"y_disputed\", task=\"classification\", cv_splits=5)\n",
    "scores_full = split_sensitivity_test(df_full, target_col=\"y_disputed\", task=\"classification\", cv_splits=5)\n",
    "\n",
    "print(\"Intake-only scores:\", scores_intake)\n",
    "print(\"Intake+workflow scores:\", scores_full)\n",
    "\n",
    "# Single-feature screen on the full set to see which columns are suspiciously predictive\n",
    "screen_cc = single_feature_screen(df_full, target_col=\"y_disputed\", task=\"classification\", max_cat_unique=50, cv_splits=5)\n",
    "display(screen_cc.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153c7e95",
   "metadata": {},
   "source": [
    "### 7.1 “As-of time” thinking: the discipline that prevents leakage\n",
    "\n",
    "Leakage prevention becomes tractable when you explicitly document an **as-of time contract**:\n",
    "\n",
    "- What is $t_0$ for this prediction?\n",
    "- Which source systems are allowed?\n",
    "- Which events must have occurred before a feature can exist?\n",
    "- Which joins/aggregations are permitted?\n",
    "\n",
    "In a real feature store, this is enforced with event-time joins and point-in-time correctness.\n",
    "In notebooks, you enforce it by:\n",
    "- writing down the availability assumption,\n",
    "- restricting the feature set to columns that satisfy it,\n",
    "- and validating via time/group splits.\n",
    "\n",
    "A useful heuristic:\n",
    "\n",
    "- If a feature is generated by a downstream process that is triggered by the target (or by actions taken after observing the target), it is likely post-outcome and invalid at $t_0$.\n",
    "\n",
    "This is why columns like “resolution,” “closed,” “timely response,” and “final status” are frequent leakage culprits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f07dd",
   "metadata": {},
   "source": [
    "## 8) Beyond the basics: stronger leakage forensics patterns\n",
    "\n",
    "The quick screens above are intentionally lightweight. In higher-stakes work, you should add deeper checks.\n",
    "\n",
    "### 8.1 Conditional performance inflation test\n",
    "\n",
    "The defining symptom of leakage is that the model performs well because it can “peek” at restricted information.\n",
    "A practical test is:\n",
    "\n",
    "1. Train a baseline on the “safe” feature set.\n",
    "2. Add one suspected column.\n",
    "3. Re-train under the same evaluation protocol.\n",
    "4. If performance jumps sharply and the column is not available at $t_0$, treat it as leakage.\n",
    "\n",
    "### 8.2 Robustness to split strategy\n",
    "\n",
    "Compare:\n",
    "- random K-fold,\n",
    "- group K-fold (entity-aware),\n",
    "- time-aware splits (when applicable).\n",
    "\n",
    "If a feature is truly generalizable, performance should not collapse catastrophically under a more realistic split.\n",
    "A collapse does not automatically mean leakage (distribution shift can do this), but it is a strong investigation signal.\n",
    "\n",
    "### 8.3 Duplicate / near-duplicate detection\n",
    "\n",
    "In EDA, check for:\n",
    "- exact duplicate rows,\n",
    "- duplicates on key identifiers,\n",
    "- near-duplicates (high similarity across many fields).\n",
    "\n",
    "Leakage via duplicates is common in scraped or merged datasets.\n",
    "\n",
    "### 8.4 Preprocessing leakage audit\n",
    "\n",
    "If you compute any statistic using the full dataset (mean, variance, PCA, target encoding, feature selection), you risk leakage.\n",
    "The safe pattern is always:\n",
    "\n",
    "- split first,\n",
    "- fit preprocessing on train only,\n",
    "- apply to validation/test via `transform`.\n",
    "\n",
    "In scikit-learn, this is naturally enforced when you put preprocessing inside a `Pipeline` and cross-validate the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e3420a",
   "metadata": {},
   "source": [
    "## 8.5 Target encoding and aggregation leakage (a common EDA trap)\n",
    "\n",
    "Some of the most subtle leakage bugs are introduced *while doing EDA*—especially when you build “helpful summaries” of the target.\n",
    "\n",
    "### Target encoding: why it leaks so easily\n",
    "\n",
    "Target encoding replaces a category with a statistic computed from the target, commonly:\n",
    "\n",
    "$$\\mathrm{TE}(c) = \\mathbb{E}[y \\mid x=c].$$\n",
    "\n",
    "If you compute $\\mathrm{TE}(c)$ using the full dataset and then cross-validate, every fold’s validation rows have influenced the encoding. This is leakage through the preprocessing step.\n",
    "\n",
    "The correct approach is **cross-fitting**:\n",
    "- for each fold, compute encodings using only that fold’s training portion,\n",
    "- apply them to that fold’s validation portion.\n",
    "\n",
    "Below, we will demonstrate the performance inflation from naïve target encoding versus cross-fitted target encoding on the diabetes dataset.\n",
    "\n",
    "Even if you never plan to deploy target encoding, this example is valuable because it teaches a general lesson:\n",
    "\n",
    "- Any feature derived from the target must be computed in a way that respects the split boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f96c942",
   "metadata": {},
   "source": [
    "### 8.6 Point-in-time correctness for time-based aggregates\n",
    "\n",
    "Another frequent leakage pattern is building aggregates that unknowingly include future information. Consider a setting with events $(e_i, t_i)$:\n",
    "\n",
    "- You want to predict an outcome at $t_0$.\n",
    "- You compute an aggregate like “customer total spend” by summing transactions.\n",
    "- If the sum includes transactions with $t > t_0$, your feature violates the availability contract.\n",
    "\n",
    "In symbols, a safe aggregate is:\n",
    "$$\\mathrm{agg}(t_0) = \\sum_{i: t_i \\le t_0} v_i,$$\n",
    "not\n",
    "$$\\sum_{i} v_i.$$\n",
    "\n",
    "In tabular datasets without explicit event logs, this can still happen when:\n",
    "- you compute averages per group using the full dataset,\n",
    "- you compute “historical rates” using future rows,\n",
    "- you compute rolling statistics but do not respect chronological order.\n",
    "\n",
    "In the listings dataset, we will create a deliberately leaky group aggregate that uses the *label* to compute a host-level statistic, then show how to compute a safer variant using cross-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76150f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve TE mean AUC (leaky): 0.6847631027253668\n",
      "Cross-fitted TE mean AUC: 0.6815408805031445\n",
      "Leaky host-rate mean AUC: 0.9843660815848916\n",
      "Cross-fitted host-rate mean AUC: 0.7843591638684562\n"
     ]
    }
   ],
   "source": [
    "# --- Demonstration: naïve target encoding vs cross-fitted target encoding ---\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def naive_target_encode(series, y):\n",
    "    \"\"\"Compute target mean per category using the full dataset (THIS LEAKS under CV).\"\"\"\n",
    "    df_tmp = pd.DataFrame({\"x\": series.astype(str), \"y\": y})\n",
    "    means = df_tmp.groupby(\"x\")[\"y\"].mean()\n",
    "    return series.astype(str).map(means).astype(float)\n",
    "\n",
    "def cv_target_encode(series, y, cv):\n",
    "    \"\"\"Cross-fitted target encoding: encodings computed on train folds only.\"\"\"\n",
    "    series = series.astype(str)\n",
    "    y = np.asarray(y)\n",
    "    enc = np.zeros(len(series), dtype=float)\n",
    "\n",
    "    for tr_idx, va_idx in cv.split(series, y):\n",
    "        x_tr = series.iloc[tr_idx]\n",
    "        y_tr = y[tr_idx]\n",
    "        means = pd.DataFrame({\"x\": x_tr, \"y\": y_tr}).groupby(\"x\")[\"y\"].mean()\n",
    "        # For unseen categories in validation, use the global mean of the training fold\n",
    "        global_mean = float(np.mean(y_tr))\n",
    "        enc_va = series.iloc[va_idx].map(means).fillna(global_mean).astype(float)\n",
    "        enc[va_idx] = enc_va.values\n",
    "\n",
    "    return enc\n",
    "\n",
    "# Use diabetes dataset with a simple categorical binning of Age\n",
    "d = df_diabetes.copy()\n",
    "d[\"age_bin\"] = pd.cut(d[\"Age\"], bins=[0, 25, 35, 45, 55, 100], include_lowest=True).astype(str)\n",
    "\n",
    "y = d[\"y\"].values\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Naïve target encoding (leaky under CV)\n",
    "te_naive = naive_target_encode(d[\"age_bin\"], y)\n",
    "\n",
    "# Cross-fitted target encoding (respects CV boundary)\n",
    "te_cv = cv_target_encode(d[\"age_bin\"], y, cv)\n",
    "\n",
    "# Evaluate AUC using the encoded value as a score (no model needed)\n",
    "auc_naive = []\n",
    "auc_cv = []\n",
    "for tr_idx, va_idx in cv.split(d, y):\n",
    "    auc_naive.append(roc_auc_score(y[va_idx], te_naive.iloc[va_idx]))\n",
    "    auc_cv.append(roc_auc_score(y[va_idx], te_cv[va_idx]))\n",
    "\n",
    "print(\"Naïve TE mean AUC (leaky):\", float(np.mean(auc_naive)))\n",
    "print(\"Cross-fitted TE mean AUC:\", float(np.mean(auc_cv)))\n",
    "\n",
    "# --- Demonstration: leaky group aggregate on listings ---\n",
    "\n",
    "if \"host_id\" in dfl.columns:\n",
    "    temp = dfl.copy()\n",
    "\n",
    "    # Deliberately leaky: uses the label y_high_price to compute host-level rate using ALL rows\n",
    "    host_rate_leaky = temp.groupby(\"host_id\")[\"y_high_price\"].mean()\n",
    "    temp[\"host_highprice_rate_leaky\"] = temp[\"host_id\"].map(host_rate_leaky)\n",
    "\n",
    "    # Cross-fitted host rate: compute host rates on train fold only\n",
    "    def cv_group_rate(df, group_col, y_col, cv):\n",
    "        y = df[y_col].values\n",
    "        out = np.zeros(len(df), dtype=float)\n",
    "        for tr_idx, va_idx in cv.split(df, y):\n",
    "            tr = df.iloc[tr_idx]\n",
    "            va = df.iloc[va_idx]\n",
    "            rates = tr.groupby(group_col)[y_col].mean()\n",
    "            global_mean = float(tr[y_col].mean())\n",
    "            out[va_idx] = va[group_col].map(rates).fillna(global_mean).astype(float).values\n",
    "        return out\n",
    "\n",
    "    cv2 = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    temp[\"host_highprice_rate_cv\"] = cv_group_rate(temp, \"host_id\", \"y_high_price\", cv2)\n",
    "\n",
    "    # Evaluate how predictive these two versions are (AUC as a proxy)\n",
    "    auc_leaky = []\n",
    "    auc_safe = []\n",
    "    y2 = temp[\"y_high_price\"].values\n",
    "    for tr_idx, va_idx in cv2.split(temp, y2):\n",
    "        auc_leaky.append(roc_auc_score(y2[va_idx], temp.loc[va_idx, \"host_highprice_rate_leaky\"]))\n",
    "        auc_safe.append(roc_auc_score(y2[va_idx], temp.loc[va_idx, \"host_highprice_rate_cv\"]))\n",
    "\n",
    "    print(\"Leaky host-rate mean AUC:\", float(np.mean(auc_leaky)))\n",
    "    print(\"Cross-fitted host-rate mean AUC:\", float(np.mean(auc_safe)))\n",
    "else:\n",
    "    print(\"host_id column not found in listings sample; skipping host-rate demo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d92a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows (subset=None): 0\n",
      "Duplicate rows (subset=None): 0\n",
      "Duplicate rows (subset=['host_id']): 49863\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13913</td>\n",
       "      <td>Holiday London DB Room Let-on going</td>\n",
       "      <td>54730</td>\n",
       "      <td>Alina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Islington</td>\n",
       "      <td>51.56861</td>\n",
       "      <td>-0.112700</td>\n",
       "      <td>Private room</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2025-02-09</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3</td>\n",
       "      <td>344</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17402</td>\n",
       "      <td>Very Central Modern 3-Bed/2 Bath By Oxford St W1</td>\n",
       "      <td>67564</td>\n",
       "      <td>Liz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>51.52195</td>\n",
       "      <td>-0.140940</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>510.0</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>5</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31036</td>\n",
       "      <td>Bright  compact 1 Bedroom Apartment Brick Lane</td>\n",
       "      <td>133271</td>\n",
       "      <td>Hendryks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>51.52425</td>\n",
       "      <td>-0.069970</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33332</td>\n",
       "      <td>Beautiful Ensuite Richmond-upon-Thames borough</td>\n",
       "      <td>144444</td>\n",
       "      <td>Chi-Chi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Richmond upon Thames</td>\n",
       "      <td>51.46410</td>\n",
       "      <td>-0.324980</td>\n",
       "      <td>Private room</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36660</td>\n",
       "      <td>You are GUARANTEED to love this</td>\n",
       "      <td>157884</td>\n",
       "      <td>Agri &amp; Roger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haringey</td>\n",
       "      <td>51.58478</td>\n",
       "      <td>-0.160570</td>\n",
       "      <td>Private room</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2</td>\n",
       "      <td>711</td>\n",
       "      <td>2025-02-26</td>\n",
       "      <td>4.03</td>\n",
       "      <td>2</td>\n",
       "      <td>193</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38610</td>\n",
       "      <td>CHARMING FAMILY HOME</td>\n",
       "      <td>165579</td>\n",
       "      <td>Elisa &amp; Dom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hammersmith and Fulham</td>\n",
       "      <td>51.50701</td>\n",
       "      <td>-0.233620</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38950</td>\n",
       "      <td>Room 1 Large Double Bedroom - front ground floor</td>\n",
       "      <td>167107</td>\n",
       "      <td>Paul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haringey</td>\n",
       "      <td>51.58684</td>\n",
       "      <td>-0.086320</td>\n",
       "      <td>Private room</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>41712</td>\n",
       "      <td>Room with a view, shared flat,  central  Bankside</td>\n",
       "      <td>182322</td>\n",
       "      <td>Nina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwark</td>\n",
       "      <td>51.50191</td>\n",
       "      <td>-0.101998</td>\n",
       "      <td>Private room</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>2024-10-14</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>42010</td>\n",
       "      <td>You Will Save Money Here</td>\n",
       "      <td>157884</td>\n",
       "      <td>Agri &amp; Roger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barnet</td>\n",
       "      <td>51.58590</td>\n",
       "      <td>-0.164340</td>\n",
       "      <td>Private room</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2</td>\n",
       "      <td>613</td>\n",
       "      <td>2025-03-13</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43129</td>\n",
       "      <td>Quiet Comfortable Room in Fulham</td>\n",
       "      <td>188138</td>\n",
       "      <td>Sylvan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hammersmith and Fulham</td>\n",
       "      <td>51.48164</td>\n",
       "      <td>-0.210820</td>\n",
       "      <td>Private room</td>\n",
       "      <td>66.0</td>\n",
       "      <td>3</td>\n",
       "      <td>248</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3</td>\n",
       "      <td>242</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>44384</td>\n",
       "      <td>DOUBLE ROOM IN A PENTHOUSE APARTMEN</td>\n",
       "      <td>194769</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barnet</td>\n",
       "      <td>51.59790</td>\n",
       "      <td>-0.243270</td>\n",
       "      <td>Private room</td>\n",
       "      <td>37.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>46961</td>\n",
       "      <td>One Bedroom Apartment with 24h Security</td>\n",
       "      <td>194769</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kensington and Chelsea</td>\n",
       "      <td>51.48063</td>\n",
       "      <td>-0.181750</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>173.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>47687</td>\n",
       "      <td>Cosy Double studio in Zone 2 Hammersmith (6)</td>\n",
       "      <td>216660</td>\n",
       "      <td>Boris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hammersmith and Fulham</td>\n",
       "      <td>51.49340</td>\n",
       "      <td>-0.229290</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2</td>\n",
       "      <td>195</td>\n",
       "      <td>2025-02-19</td>\n",
       "      <td>1.11</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>49970</td>\n",
       "      <td>Beautiful Small Studio Hammersmith</td>\n",
       "      <td>216660</td>\n",
       "      <td>Boris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hammersmith and Fulham</td>\n",
       "      <td>51.49462</td>\n",
       "      <td>-0.229230</td>\n",
       "      <td>Hotel room</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>226</td>\n",
       "      <td>2025-02-10</td>\n",
       "      <td>1.31</td>\n",
       "      <td>11</td>\n",
       "      <td>113</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>52624</td>\n",
       "      <td>Close to Wimbledon All England Tennis -huge do...</td>\n",
       "      <td>243610</td>\n",
       "      <td>Beverley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Merton</td>\n",
       "      <td>51.41927</td>\n",
       "      <td>-0.212230</td>\n",
       "      <td>Private room</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>289</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>56229</td>\n",
       "      <td>Cosy Double studio in Zone 2 Hammersmith (1)</td>\n",
       "      <td>216660</td>\n",
       "      <td>Boris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hammersmith and Fulham</td>\n",
       "      <td>51.49547</td>\n",
       "      <td>-0.229420</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>2025-02-12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>63948</td>\n",
       "      <td>Cosy Double studio in Zone 2 Hammersmith (4)</td>\n",
       "      <td>216660</td>\n",
       "      <td>Boris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hammersmith and Fulham</td>\n",
       "      <td>51.49547</td>\n",
       "      <td>-0.228640</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3</td>\n",
       "      <td>191</td>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>1.17</td>\n",
       "      <td>11</td>\n",
       "      <td>79</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>66772</td>\n",
       "      <td>Cosy Double studio in Zone 2 Hammersmith (3)</td>\n",
       "      <td>216660</td>\n",
       "      <td>Boris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hammersmith and Fulham</td>\n",
       "      <td>51.49370</td>\n",
       "      <td>-0.229140</td>\n",
       "      <td>Private room</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>1.16</td>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>67934</td>\n",
       "      <td>NICE FAMILY HOME opposite NATURAL LANDSCAPED PARK</td>\n",
       "      <td>335716</td>\n",
       "      <td>Laura D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barnet</td>\n",
       "      <td>51.60268</td>\n",
       "      <td>-0.262680</td>\n",
       "      <td>Private room</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>81080</td>\n",
       "      <td>Luxury Self contained Studio Apt.</td>\n",
       "      <td>439154</td>\n",
       "      <td>Lucy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Richmond upon Thames</td>\n",
       "      <td>51.40644</td>\n",
       "      <td>-0.335630</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>168.0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5</td>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               name  host_id  \\\n",
       "0   13913                Holiday London DB Room Let-on going    54730   \n",
       "2   17402   Very Central Modern 3-Bed/2 Bath By Oxford St W1    67564   \n",
       "4   31036     Bright  compact 1 Bedroom Apartment Brick Lane   133271   \n",
       "5   33332     Beautiful Ensuite Richmond-upon-Thames borough   144444   \n",
       "7   36660                    You are GUARANTEED to love this   157884   \n",
       "8   38610                               CHARMING FAMILY HOME   165579   \n",
       "9   38950   Room 1 Large Double Bedroom - front ground floor   167107   \n",
       "14  41712  Room with a view, shared flat,  central  Bankside   182322   \n",
       "16  42010                           You Will Save Money Here   157884   \n",
       "18  43129                   Quiet Comfortable Room in Fulham   188138   \n",
       "20  44384                DOUBLE ROOM IN A PENTHOUSE APARTMEN   194769   \n",
       "23  46961            One Bedroom Apartment with 24h Security   194769   \n",
       "26  47687       Cosy Double studio in Zone 2 Hammersmith (6)   216660   \n",
       "27  49970                 Beautiful Small Studio Hammersmith   216660   \n",
       "28  52624  Close to Wimbledon All England Tennis -huge do...   243610   \n",
       "30  56229       Cosy Double studio in Zone 2 Hammersmith (1)   216660   \n",
       "33  63948       Cosy Double studio in Zone 2 Hammersmith (4)   216660   \n",
       "34  66772       Cosy Double studio in Zone 2 Hammersmith (3)   216660   \n",
       "36  67934  NICE FAMILY HOME opposite NATURAL LANDSCAPED PARK   335716   \n",
       "47  81080                  Luxury Self contained Studio Apt.   439154   \n",
       "\n",
       "       host_name  neighbourhood_group           neighbourhood  latitude  \\\n",
       "0          Alina                  NaN               Islington  51.56861   \n",
       "2            Liz                  NaN             Westminster  51.52195   \n",
       "4       Hendryks                  NaN           Tower Hamlets  51.52425   \n",
       "5        Chi-Chi                  NaN    Richmond upon Thames  51.46410   \n",
       "7   Agri & Roger                  NaN                Haringey  51.58478   \n",
       "8    Elisa & Dom                  NaN  Hammersmith and Fulham  51.50701   \n",
       "9           Paul                  NaN                Haringey  51.58684   \n",
       "14          Nina                  NaN               Southwark  51.50191   \n",
       "16  Agri & Roger                  NaN                  Barnet  51.58590   \n",
       "18        Sylvan                  NaN  Hammersmith and Fulham  51.48164   \n",
       "20             D                  NaN                  Barnet  51.59790   \n",
       "23             D                  NaN  Kensington and Chelsea  51.48063   \n",
       "26         Boris                  NaN  Hammersmith and Fulham  51.49340   \n",
       "27         Boris                  NaN  Hammersmith and Fulham  51.49462   \n",
       "28      Beverley                  NaN                  Merton  51.41927   \n",
       "30         Boris                  NaN  Hammersmith and Fulham  51.49547   \n",
       "33         Boris                  NaN  Hammersmith and Fulham  51.49547   \n",
       "34         Boris                  NaN  Hammersmith and Fulham  51.49370   \n",
       "36       Laura D                  NaN                  Barnet  51.60268   \n",
       "47          Lucy                  NaN    Richmond upon Thames  51.40644   \n",
       "\n",
       "    longitude        room_type  price  minimum_nights  number_of_reviews  \\\n",
       "0   -0.112700     Private room   57.0               1                 51   \n",
       "2   -0.140940  Entire home/apt  510.0               3                 56   \n",
       "4   -0.069970  Entire home/apt  100.0               2                126   \n",
       "5   -0.324980     Private room  133.0               2                 19   \n",
       "7   -0.160570     Private room   74.0               2                711   \n",
       "8   -0.233620  Entire home/apt    NaN              91                 42   \n",
       "9   -0.086320     Private room   52.0               1                  1   \n",
       "14  -0.101998     Private room    NaN               2                131   \n",
       "16  -0.164340     Private room   55.0               2                613   \n",
       "18  -0.210820     Private room   66.0               3                248   \n",
       "20  -0.243270     Private room   37.0              30                  0   \n",
       "23  -0.181750  Entire home/apt  173.0               7                  1   \n",
       "26  -0.229290  Entire home/apt   75.0               2                195   \n",
       "27  -0.229230       Hotel room   75.0               1                226   \n",
       "28  -0.212230     Private room    NaN               2                  7   \n",
       "30  -0.229420  Entire home/apt   71.0               5                156   \n",
       "33  -0.228640  Entire home/apt   63.0               3                191   \n",
       "34  -0.229140     Private room   75.0               3                200   \n",
       "36  -0.262680     Private room   40.0               5                 25   \n",
       "47  -0.335630  Entire home/apt  168.0               3                 16   \n",
       "\n",
       "   last_review  reviews_per_month  calculated_host_listings_count  \\\n",
       "0   2025-02-09               0.29                               3   \n",
       "2   2024-02-19               0.33                               5   \n",
       "4   2025-02-20               0.70                               8   \n",
       "5   2022-08-01               0.11                               2   \n",
       "7   2025-02-26               4.03                               2   \n",
       "8   2023-08-27               0.27                               2   \n",
       "9   2021-12-12               0.03                               2   \n",
       "14  2024-10-14               0.77                               2   \n",
       "16  2025-03-13               3.48                               2   \n",
       "18  2025-01-02               1.75                               3   \n",
       "20         NaN                NaN                               6   \n",
       "23  2023-11-16               0.06                               6   \n",
       "26  2025-02-19               1.11                              11   \n",
       "27  2025-02-10               1.31                              11   \n",
       "28  2024-12-15               0.98                               4   \n",
       "30  2025-02-12               0.89                              11   \n",
       "33  2025-02-18               1.17                              11   \n",
       "34  2025-02-14               1.16                              11   \n",
       "36  2020-01-03               0.15                               2   \n",
       "47  2022-10-30               0.18                               5   \n",
       "\n",
       "    availability_365  number_of_reviews_ltm  license  \n",
       "0                344                     10      NaN  \n",
       "2                293                      0      NaN  \n",
       "4                353                      3      NaN  \n",
       "5                365                      0      NaN  \n",
       "7                193                     51      NaN  \n",
       "8                 76                      0      NaN  \n",
       "9                 89                      0      NaN  \n",
       "14               179                      7      NaN  \n",
       "16               175                     50      NaN  \n",
       "18               242                      9      NaN  \n",
       "20               365                      0      NaN  \n",
       "23               364                      0      NaN  \n",
       "26                 8                     52      NaN  \n",
       "27               113                     44      NaN  \n",
       "28               289                      7      NaN  \n",
       "30                22                     45      NaN  \n",
       "33                79                     63      NaN  \n",
       "34               131                     46      NaN  \n",
       "36               285                      0      NaN  \n",
       "47               310                      0      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Duplicate and near-duplicate checks (generic utilities) ---\n",
    "\n",
    "def duplicate_report(df, subset=None):\n",
    "    if subset is None:\n",
    "        dup = df.duplicated(keep=False)\n",
    "    else:\n",
    "        dup = df.duplicated(subset=subset, keep=False)\n",
    "    n_dup = int(dup.sum())\n",
    "    print(f\"Duplicate rows (subset={subset}): {n_dup}\")\n",
    "    if n_dup > 0:\n",
    "        display(df.loc[dup].head(20))\n",
    "\n",
    "# Examples: run on each dataset\n",
    "duplicate_report(df_diabetes)\n",
    "duplicate_report(df_house)\n",
    "duplicate_report(df_listings, subset=[\"host_id\"] if \"host_id\" in df_listings.columns else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab1782",
   "metadata": {},
   "source": [
    "## 9) A practical leakage-forensics checklist (use this every time)\n",
    "\n",
    "Use this checklist during EDA, before you commit to modeling:\n",
    "\n",
    "**A. Define the prediction contract**\n",
    "- What exactly is $y$?\n",
    "- What is $t_0$ (prediction time)?\n",
    "- Which sources are available at $t_0$?\n",
    "\n",
    "**B. Column semantics**\n",
    "- Identify workflow/status fields, “final” outcomes, and post-hoc summaries.\n",
    "- Identify IDs and keys (high cardinality).\n",
    "- Identify timestamp fields and the events they represent.\n",
    "\n",
    "**C. Quick suspicion screens**\n",
    "- Name-pattern scan (`suspicious_name_scan`).\n",
    "- Single-feature performance screen (`single_feature_screen`).\n",
    "\n",
    "**D. Controlled experiments**\n",
    "- Remove suspected columns and confirm performance drops.\n",
    "- Compare random vs group vs time splits (`split_sensitivity_test`).\n",
    "\n",
    "**E. Preprocessing hygiene**\n",
    "- Ensure all transforms are inside a pipeline.\n",
    "- Never fit preprocessing on the full dataset before splitting.\n",
    "\n",
    "**F. Documentation**\n",
    "- Record which columns were excluded and why.\n",
    "- Record the as-of contract assumptions.\n",
    "\n",
    "If you make this a habit, leakage becomes something you catch early instead of a catastrophe you debug at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d54c4e",
   "metadata": {},
   "source": [
    "## 10) Exercises\n",
    "\n",
    "1. **Diabetes:** create a second leaky feature that mimics a “post-diagnosis indicator” (e.g., a binary flag derived from the target) and confirm it is detected.\n",
    "2. **House prices:** create a “leaky bucket” feature: `PriceBucket = round(Price / 10000)` and measure the performance inflation.\n",
    "3. **Listings:** rerun the split sensitivity test after removing `host_id` and any review-related columns. How much does group CV change?\n",
    "4. **Complaints:** redefine $t_0$ to be “after the complaint was sent to the company” and decide which workflow columns become valid. How do results change?\n",
    "\n",
    "When you can answer these questions, you have moved from “knowing leakage exists” to being able to *forensically prove it* and prevent it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c8618f",
   "metadata": {},
   "source": [
    "## 11) Summary\n",
    "\n",
    "- Leakage is a violation of an availability boundary: features (or preprocessing/evaluation) include restricted information.\n",
    "- EDA is the ideal phase to detect leakage because column meaning and data lineage issues surface here.\n",
    "- Combine semantic checks with quantitative screens:\n",
    "  - suspicious names,\n",
    "  - unusually high single-feature performance,\n",
    "  - split sensitivity (random vs group vs time),\n",
    "  - controlled “add/remove a column” experiments.\n",
    "- Make an as-of-time contract explicit. Post-outcome workflow columns are the most common leakage source in real data.\n",
    "- Enforce preprocessing hygiene with pipelines and train-only fitting.\n",
    "\n",
    "In the next lesson, you will learn how to package EDA insights into a report that is actionable for both technical and non-technical stakeholders."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
