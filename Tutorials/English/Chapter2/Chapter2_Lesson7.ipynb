{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b70332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&display=swap');\n",
       "\n",
       "\n",
       "/* Text areas (Classic Notebook + JupyterLab) */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "div.rendered_html, .output_subarea {\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "/* RTL for rendered markdown/html content */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "h1, h2, h3, h4, h5, h6, p, strong, label, ol, ul, li {\n",
       "  line-height: 1.9;\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "h1 { font-size: 2rem; color: #070F2B; font-weight: 900}\n",
       "h2 { font-size: 1.8rem; color: #070F2B; font-weight: 800}\n",
       "h3 { font-size: 1.6rem; color: #070F2B; font-weight: 700}\n",
       "h4 { font-size: 1.4rem; color: #1E3E62; font-weight: 600}\n",
       "h5 { font-size: 1.2rem; color: #1E3E62}\n",
       "h6 { font-size: 1rem; color: #1E3E62}\n",
       "p { font-size: 1.1rem; ; font-weight: 400}\n",
       "ol, ul, li, th, td  { font-size: 1rem; }\n",
       "\n",
       "/* Keep code + outputs LTR and monospace */\n",
       ".CodeMirror, .CodeMirror *,\n",
       "pre, code,\n",
       ".jp-CodeCell .jp-InputArea, .jp-CodeCell .jp-InputArea *,\n",
       ".jp-OutputArea, .jp-OutputArea * {\n",
       "  direction: ltr !important;\n",
       "  text-align: left !important;\n",
       "  font-size: 1rem !important;\n",
       "  font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "css = Path(\"../../../css/custom.css\").read_text(encoding=\"utf-8\")\n",
    "display(HTML(f\"<style>{css}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d6a9b6",
   "metadata": {},
   "source": [
    "# Chapter 2 — Basics of Data and Preprocessing\n",
    "## Lesson 7: Data Leakage and Prevention Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ab85e",
   "metadata": {},
   "source": [
    "\n",
    "### Why this lesson matters\n",
    "\n",
    "Data leakage is one of the fastest ways to make a machine learning project look successful in a notebook and fail in production. It happens when information that would **not be available at prediction time** (or information that “belongs to the test set”) is accidentally used during training. The result is **inflated validation/test scores**, misleading model selection, and brittle deployment.\n",
    "\n",
    "This lesson is practical and intentionally “hands-on”: you will build leaky pipelines on purpose, observe unrealistically high scores, then fix them using the correct split strategy and `sklearn` pipelines.\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "By the end of this lesson, you will be able to:\n",
    "\n",
    "1. Define leakage precisely and explain why it breaks generalization.\n",
    "2. Recognize the major leakage families:\n",
    "   - **Target leakage** (post‑outcome variables)\n",
    "   - **Train/test contamination** (duplicates, entity overlap, label reuse)\n",
    "   - **Preprocessing leakage** (scalers/encoders/feature selection fit on all data)\n",
    "   - **Temporal leakage** (future information in time series or events)\n",
    "   - **Group leakage** (same customer/host/device in both train and test)\n",
    "   - **Model selection leakage** (tuning on the test set)\n",
    "3. Implement leakage‑safe workflows using:\n",
    "   - `Pipeline`, `ColumnTransformer`\n",
    "   - `GroupKFold`, time‑based splits, and nested CV patterns\n",
    "4. Apply “leakage forensics”: sanity checks that detect leakage early.\n",
    "\n",
    "### Key idea in one sentence\n",
    "\n",
    "A model evaluation is valid only if the evaluation data is treated as **strictly unseen future information**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d454b78f",
   "metadata": {},
   "source": [
    "## 1) What is data leakage?\n",
    "\n",
    "Let a dataset consist of pairs $(x_i, y_i)$ where $x_i$ are features and $y_i$ is the target. We want an estimate of how a model $f_\\theta$ will perform on new data drawn from the same (or a close) distribution.\n",
    "\n",
    "A simplified view of training is:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = \\arg\\min_\\theta \\frac{1}{n}\\sum_{i=1}^n \\ell\\big(y_i, f_\\theta(x_i)\\big).\n",
    "$$\n",
    "\n",
    "A simplified view of evaluation is to estimate risk:\n",
    "\n",
    "$$\n",
    "\\hat{R} = \\frac{1}{m}\\sum_{j=1}^m \\ell\\big(y^{(test)}_j, f_{\\hat{\\theta}}(x^{(test)}_j)\\big).\n",
    "$$\n",
    "\n",
    "Leakage occurs when **information from the test set** (or information that depends on $y$ in a way that would not be available at prediction time) influences either:\n",
    "\n",
    "- the learned parameters $\\hat{\\theta}$ (training leakage), or\n",
    "- the selection of hyperparameters/model class (selection leakage), or\n",
    "- the construction of features (feature engineering leakage).\n",
    "\n",
    "### A practical definition\n",
    "\n",
    "Leakage is present if **the process that creates the training features uses information that should be unknown at training time**.\n",
    "\n",
    "Equivalently:\n",
    "\n",
    "- If a feature uses “future” fields (post‑outcome), it is target leakage.\n",
    "- If the same real‑world entity appears in both train and test, you may be measuring memorization rather than generalization.\n",
    "- If a transformation is fit on the full dataset (including test), you have allowed the test distribution to influence training.\n",
    "\n",
    "### Why leakage inflates metrics\n",
    "\n",
    "Leakage increases the mutual information between features and target in an unrealistic way. If a feature (directly or indirectly) encodes $y$, the model can “cheat”. The cheat disappears the moment you deploy the model, because that leaked feature is not available or not stable.\n",
    "\n",
    "### The two questions you must always ask\n",
    "\n",
    "1. **Would this feature exist at prediction time?** (operational availability)\n",
    "2. **Was this transformation fit using only training data?** (workflow hygiene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78daccaa",
   "metadata": {},
   "source": [
    "## 2) Leakage taxonomy and typical causes\n",
    "\n",
    "### 2.1 Target leakage (post-outcome features)\n",
    "\n",
    "Examples:\n",
    "- A medical dataset where “treatment plan” is recorded after diagnosis.\n",
    "- A loan dataset where “months delinquent” is computed after default.\n",
    "- A customer dataset where “churned_last_month” is used to predict churn.\n",
    "\n",
    "Symptom: near‑perfect metrics that feel “too good to be true”.\n",
    "\n",
    "### 2.2 Train/test contamination\n",
    "\n",
    "Examples:\n",
    "- Duplicate rows across splits.\n",
    "- Precomputed aggregates using the full dataset (e.g., mean target by category computed on all rows).\n",
    "- Data from the same individual in both train and test (entity leakage).\n",
    "\n",
    "Symptom: strong performance that collapses when evaluated on a truly external dataset.\n",
    "\n",
    "### 2.3 Preprocessing leakage\n",
    "\n",
    "Examples:\n",
    "- Standardizing features using mean/std of the full dataset before splitting.\n",
    "- One-hot encoding categories after seeing test categories (less severe, but still invalid).\n",
    "- Feature selection performed before cross‑validation.\n",
    "\n",
    "Symptom: evaluation scores improve “mysteriously” after heavy preprocessing.\n",
    "\n",
    "### 2.4 Temporal leakage\n",
    "\n",
    "Examples:\n",
    "- Random split on time‑ordered data (future points appear in training).\n",
    "- Features that include future information (e.g., “next week’s sales”).\n",
    "- Leakage through rolling windows that look ahead.\n",
    "\n",
    "Symptom: excellent backtest performance but poor forward performance.\n",
    "\n",
    "### 2.5 Group leakage (entity leakage)\n",
    "\n",
    "Examples:\n",
    "- Same `customer_id` in train and test.\n",
    "- Same `host_id` across Airbnb listings splits.\n",
    "- Same patient in train and test with multiple visits.\n",
    "\n",
    "Symptom: model appears strong but is actually memorizing id‑specific patterns.\n",
    "\n",
    "### 2.6 Model selection leakage\n",
    "\n",
    "Examples:\n",
    "- Repeatedly evaluating on the test set while tuning hyperparameters.\n",
    "- Comparing many models and choosing the best based on test.\n",
    "\n",
    "Symptom: the test set becomes a “validation set” and no longer measures generalization.\n",
    "\n",
    "In the code labs below, you will see each of these patterns and the fix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0117b",
   "metadata": {},
   "source": [
    "## 3) Setup\n",
    "\n",
    "We will use several datasets from the repository to demonstrate leakage in different forms:\n",
    "\n",
    "- **Classification**: `diabetes.csv` (binary target)\n",
    "- **Regression**: `house-prices.csv` (continuous target)\n",
    "- **Temporal + groups**: `listings.csv` (time column + `host_id`)\n",
    "- **Text + target leakage**: `ConsumerComplaints.csv`\n",
    "- **Feature selection leakage**: `Wine_Quality.csv`\n",
    "\n",
    "The key is that leakage is not dataset-specific: it is caused by *workflow mistakes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1d6c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold, cross_val_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "def show_df(name, df, n=5):\n",
    "    print(f\"{name}: shape={df.shape}\")\n",
    "    display(df.head(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede198e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes: shape=(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>Non-Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>Non-Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age classification  \n",
       "0                     0.627   50       Diabetic  \n",
       "1                     0.351   31   Non-Diabetic  \n",
       "2                     0.672   32       Diabetic  \n",
       "3                     0.167   21   Non-Diabetic  \n",
       "4                     2.288   33       Diabetic  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house-prices: shape=(128, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home</th>\n",
       "      <th>Price</th>\n",
       "      <th>SqFt</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Offers</th>\n",
       "      <th>Brick</th>\n",
       "      <th>Neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114300</td>\n",
       "      <td>1790</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>114200</td>\n",
       "      <td>2030</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>114800</td>\n",
       "      <td>1740</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>94700</td>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>119800</td>\n",
       "      <td>2130</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Home   Price  SqFt  Bedrooms  Bathrooms  Offers Brick Neighborhood\n",
       "0     1  114300  1790         2          2       2    No         East\n",
       "1     2  114200  2030         4          2       3    No         East\n",
       "2     3  114800  1740         3          2       1    No         East\n",
       "3     4   94700  1980         3          2       3    No         East\n",
       "4     5  119800  2130         3          3       3    No         East"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listings: shape=(94559, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13913</td>\n",
       "      <td>Holiday London DB Room Let-on going</td>\n",
       "      <td>54730</td>\n",
       "      <td>Alina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Islington</td>\n",
       "      <td>51.56861</td>\n",
       "      <td>-0.11270</td>\n",
       "      <td>Private room</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2025-02-09</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3</td>\n",
       "      <td>344</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15400</td>\n",
       "      <td>Bright Chelsea  Apartment. Chelsea!</td>\n",
       "      <td>60302</td>\n",
       "      <td>Philippa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kensington and Chelsea</td>\n",
       "      <td>51.48780</td>\n",
       "      <td>-0.16813</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>2024-04-28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17402</td>\n",
       "      <td>Very Central Modern 3-Bed/2 Bath By Oxford St W1</td>\n",
       "      <td>67564</td>\n",
       "      <td>Liz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>51.52195</td>\n",
       "      <td>-0.14094</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>510.0</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>5</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24328</td>\n",
       "      <td>Battersea live/work artist house</td>\n",
       "      <td>41759</td>\n",
       "      <td>Joe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>51.47072</td>\n",
       "      <td>-0.16266</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>213.0</td>\n",
       "      <td>90</td>\n",
       "      <td>94</td>\n",
       "      <td>2022-07-19</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31036</td>\n",
       "      <td>Bright  compact 1 Bedroom Apartment Brick Lane</td>\n",
       "      <td>133271</td>\n",
       "      <td>Hendryks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>51.52425</td>\n",
       "      <td>-0.06997</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              name  host_id host_name  \\\n",
       "0  13913               Holiday London DB Room Let-on going    54730     Alina   \n",
       "1  15400               Bright Chelsea  Apartment. Chelsea!    60302  Philippa   \n",
       "2  17402  Very Central Modern 3-Bed/2 Bath By Oxford St W1    67564       Liz   \n",
       "3  24328                  Battersea live/work artist house    41759       Joe   \n",
       "4  31036    Bright  compact 1 Bedroom Apartment Brick Lane   133271  Hendryks   \n",
       "\n",
       "   neighbourhood_group           neighbourhood  latitude  longitude  \\\n",
       "0                  NaN               Islington  51.56861   -0.11270   \n",
       "1                  NaN  Kensington and Chelsea  51.48780   -0.16813   \n",
       "2                  NaN             Westminster  51.52195   -0.14094   \n",
       "3                  NaN              Wandsworth  51.47072   -0.16266   \n",
       "4                  NaN           Tower Hamlets  51.52425   -0.06997   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room   57.0               1                 51  2025-02-09   \n",
       "1  Entire home/apt    NaN               4                 96  2024-04-28   \n",
       "2  Entire home/apt  510.0               3                 56  2024-02-19   \n",
       "3  Entire home/apt  213.0              90                 94  2022-07-19   \n",
       "4  Entire home/apt  100.0               2                126  2025-02-20   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \\\n",
       "0               0.29                               3               344   \n",
       "1               0.52                               1                11   \n",
       "2               0.33                               5               293   \n",
       "3               0.54                               1               194   \n",
       "4               0.70                               8               353   \n",
       "\n",
       "   number_of_reviews_ltm  license  \n",
       "0                     10      NaN  \n",
       "1                      2      NaN  \n",
       "2                      0      NaN  \n",
       "3                      0      NaN  \n",
       "4                      3      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConsumerComplaints: shape=(65499, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Received</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sub Product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub Issue</th>\n",
       "      <th>Consumer Complaint Narrative</th>\n",
       "      <th>Company Public Response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State Name</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer Consent Provided</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date Sent to Company</th>\n",
       "      <th>Company Response to Consumer</th>\n",
       "      <th>Timely Response</th>\n",
       "      <th>Consumer Disputed</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Vehicle loan</td>\n",
       "      <td>Managing the loan or lease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>VA</td>\n",
       "      <td>24540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Phone</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>468882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>Checking account</td>\n",
       "      <td>Using a debit or ATM card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>CA</td>\n",
       "      <td>95992</td>\n",
       "      <td>Older American</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Web</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>468889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>Checking account</td>\n",
       "      <td>Account opening, closing, or management</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Santander Bank US</td>\n",
       "      <td>NY</td>\n",
       "      <td>10065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Fax</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>468879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>Checking account</td>\n",
       "      <td>Deposits and withdrawals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>GA</td>\n",
       "      <td>30084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Web</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>468949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Conventional fixed mortgage</td>\n",
       "      <td>Loan servicing, payments, escrow account</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Franklin Credit Management</td>\n",
       "      <td>CT</td>\n",
       "      <td>6106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Web</td>\n",
       "      <td>2013-07-30</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>475823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date Received             Product Name                  Sub Product  \\\n",
       "0    2013-07-29            Consumer Loan                 Vehicle loan   \n",
       "1    2013-07-29  Bank account or service             Checking account   \n",
       "2    2013-07-29  Bank account or service             Checking account   \n",
       "3    2013-07-29  Bank account or service             Checking account   \n",
       "4    2013-07-29                 Mortgage  Conventional fixed mortgage   \n",
       "\n",
       "                                      Issue Sub Issue  \\\n",
       "0                Managing the loan or lease       NaN   \n",
       "1                 Using a debit or ATM card       NaN   \n",
       "2   Account opening, closing, or management       NaN   \n",
       "3                  Deposits and withdrawals       NaN   \n",
       "4  Loan servicing, payments, escrow account       NaN   \n",
       "\n",
       "  Consumer Complaint Narrative Company Public Response  \\\n",
       "0                         <NA>                     NaN   \n",
       "1                         <NA>                     NaN   \n",
       "2                         <NA>                     NaN   \n",
       "3                         <NA>                     NaN   \n",
       "4                         <NA>                     NaN   \n",
       "\n",
       "                      Company State Name Zip Code            Tags  \\\n",
       "0       Wells Fargo & Company         VA    24540             NaN   \n",
       "1       Wells Fargo & Company         CA    95992  Older American   \n",
       "2           Santander Bank US         NY    10065             NaN   \n",
       "3       Wells Fargo & Company         GA    30084             NaN   \n",
       "4  Franklin Credit Management         CT     6106             NaN   \n",
       "\n",
       "  Consumer Consent Provided Submitted via Date Sent to Company  \\\n",
       "0                      <NA>         Phone           2013-07-30   \n",
       "1                      <NA>           Web           2013-07-31   \n",
       "2                      <NA>           Fax           2013-07-31   \n",
       "3                      <NA>           Web           2013-07-30   \n",
       "4                      <NA>           Web           2013-07-30   \n",
       "\n",
       "  Company Response to Consumer Timely Response Consumer Disputed  Complaint ID  \n",
       "0      Closed with explanation             Yes                No        468882  \n",
       "1      Closed with explanation             Yes                No        468889  \n",
       "2                       Closed             Yes                No        468879  \n",
       "3      Closed with explanation             Yes                No        468949  \n",
       "4      Closed with explanation             Yes                No        475823  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine_Quality: shape=(4898, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load datasets using repository-relative paths from this notebook location:\n",
    "# Tutorials/English/Chapter2/Chapter2_Lesson7.ipynb  -> ../../../Datasets/...\n",
    "\n",
    "base = Path(\"../../../\")\n",
    "\n",
    "paths = {\n",
    "    \"diabetes\": base / \"Datasets/Classification/diabetes.csv\",\n",
    "    \"house\": base / \"Datasets/Regression/house-prices.csv\",\n",
    "    \"listings\": base / \"Datasets/Regression/listings.csv\",\n",
    "    \"complaints\": base / \"Datasets/Clustering/ConsumerComplaints.csv\",\n",
    "    \"wine\": base / \"Datasets/Classification/Wine_Quality.csv\",\n",
    "}\n",
    "\n",
    "diabetes = pd.read_csv(paths[\"diabetes\"])\n",
    "house = pd.read_csv(paths[\"house\"])\n",
    "listings = pd.read_csv(paths[\"listings\"])\n",
    "complaints = pd.read_csv(\n",
    "    paths[\"complaints\"],\n",
    "    low_memory=False,\n",
    "    dtype={\n",
    "        \"Consumer Complaint Narrative\": \"string\",\n",
    "        \"Consumer Consent Provided\": \"string\",\n",
    "    }\n",
    ")\n",
    "wine = pd.read_csv(paths[\"wine\"])\n",
    "\n",
    "show_df(\"diabetes\", diabetes)\n",
    "show_df(\"house-prices\", house)\n",
    "show_df(\"listings\", listings)\n",
    "show_df(\"ConsumerComplaints\", complaints)\n",
    "show_df(\"Wine_Quality\", wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb77249",
   "metadata": {},
   "source": [
    "## 4) Lab A — Target leakage (post-outcome features)\n",
    "\n",
    "We will simulate a classic mistake: adding a feature that is computed using the true label (even indirectly).\n",
    "\n",
    "Suppose we are predicting diabetes status. A leaky feature might be something like:\n",
    "\n",
    "- “diagnosis_code” generated **after** diagnosis\n",
    "- “treatment_plan_intensity”\n",
    "- “follow_up_frequency”\n",
    "\n",
    "These are strongly correlated with the target because they are consequences of the target.\n",
    "\n",
    "### What you should observe\n",
    "\n",
    "- With the leaky feature, accuracy can become unrealistically high.\n",
    "- After removing leakage, performance drops to a more believable value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72fc6b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated accuracy with target leakage:\n",
      "[1. 1. 1. 1. 1.]\n",
      "Mean accuracy: 1.0\n",
      "\n",
      "Hold-out accuracy (leaky): 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       125\n",
      "           1      1.000     1.000     1.000        67\n",
      "\n",
      "    accuracy                          1.000       192\n",
      "   macro avg      1.000     1.000     1.000       192\n",
      "weighted avg      1.000     1.000     1.000       192\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = diabetes.copy()\n",
    "\n",
    "# Binary target\n",
    "y = (df[\"classification\"] == \"Diabetic\").astype(int)\n",
    "\n",
    "X = df.drop(columns=[\"classification\"])\n",
    "\n",
    "# Create an intentionally leaky feature: a noisy copy of the target\n",
    "rng = np.random.default_rng(7)\n",
    "X_leaky = X.copy()\n",
    "X_leaky[\"post_diagnosis_flag\"] = y + rng.normal(0, 0.05, size=len(y))  # almost directly encodes y\n",
    "\n",
    "numeric_features = X.columns.tolist() + [\"post_diagnosis_flag\"]\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "scores_leaky = cross_val_score(pipe, X_leaky[numeric_features], y, cv=5, scoring=\"accuracy\")\n",
    "print(\"Cross-validated accuracy with target leakage:\")\n",
    "print(scores_leaky)\n",
    "print(\"Mean accuracy:\", scores_leaky.mean().round(4))\n",
    "\n",
    "# Evaluate on a held-out split to show the same effect\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_leaky[numeric_features], y, test_size=0.25, random_state=7, stratify=y)\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"\\nHold-out accuracy (leaky):\", round(accuracy_score(y_test, pred), 4))\n",
    "print(classification_report(y_test, pred, digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d8899",
   "metadata": {},
   "source": [
    "### Fix: remove post-outcome variables\n",
    "\n",
    "The fix is conceptually simple: remove any feature that would not be available *before* the event you are predicting. In practice, you also need to enforce this with governance:\n",
    "\n",
    "- Document feature definitions with timestamps (“available as-of”).\n",
    "- Implement feature generation that respects cutoff time.\n",
    "- Use data lineage checks (e.g., prevent joins to tables that are only populated after the outcome).\n",
    "\n",
    "Now we drop the leaky column and re-evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f886b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated accuracy without the leaky feature:\n",
      "[0.77272727 0.74675325 0.75324675 0.81699346 0.76470588]\n",
      "Mean accuracy: 0.7709\n",
      "\n",
      "Hold-out accuracy (clean): 0.7812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.799     0.888     0.841       125\n",
      "           1      0.736     0.582     0.650        67\n",
      "\n",
      "    accuracy                          0.781       192\n",
      "   macro avg      0.767     0.735     0.745       192\n",
      "weighted avg      0.777     0.781     0.774       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_clean = X.copy()\n",
    "numeric_features_clean = X_clean.columns.tolist()\n",
    "\n",
    "scores_clean = cross_val_score(pipe, X_clean[numeric_features_clean], y, cv=5, scoring=\"accuracy\")\n",
    "print(\"Cross-validated accuracy without the leaky feature:\")\n",
    "print(scores_clean)\n",
    "print(\"Mean accuracy:\", scores_clean.mean().round(4))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean[numeric_features_clean], y, test_size=0.25, random_state=7, stratify=y)\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"\\nHold-out accuracy (clean):\", round(accuracy_score(y_test, pred), 4))\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f13a664",
   "metadata": {},
   "source": [
    "## 5) Lab B — Preprocessing leakage (fit on full data vs fit on training data)\n",
    "\n",
    "A frequent leak is fitting preprocessing steps on the full dataset before splitting:\n",
    "\n",
    "- `StandardScaler().fit(X)` on all rows\n",
    "- `OneHotEncoder().fit(X)` on all rows\n",
    "- `SimpleImputer().fit(X)` on all rows\n",
    "\n",
    "This makes the evaluation optimistic because test statistics influence the transformation.\n",
    "\n",
    "The correct pattern is to place preprocessing in a `Pipeline` and fit it only on training folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4f883ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaky preprocessing (fit on full data) => R2: 0.8703  MAE: 6856.1\n",
      "Pipeline (fit on train only)          => R2: 0.8696  MAE: 6868.2\n"
     ]
    }
   ],
   "source": [
    "df = house.copy()\n",
    "\n",
    "y = df[\"Price\"].astype(float)\n",
    "X = df.drop(columns=[\"Price\"])\n",
    "\n",
    "num_cols = [\"SqFt\", \"Bedrooms\", \"Bathrooms\", \"Offers\"]\n",
    "cat_cols = [\"Brick\", \"Neighborhood\"]\n",
    "\n",
    "# -------------------------\n",
    "# BAD: Fit preprocessing on the full dataset (leaky)\n",
    "# -------------------------\n",
    "X_full = X.copy()\n",
    "\n",
    "imp_num = SimpleImputer(strategy=\"median\").fit(X_full[num_cols])\n",
    "imp_cat = SimpleImputer(strategy=\"most_frequent\").fit(X_full[cat_cols])\n",
    "\n",
    "X_num_imp = pd.DataFrame(imp_num.transform(X_full[num_cols]), columns=num_cols)\n",
    "X_cat_imp = pd.DataFrame(imp_cat.transform(X_full[cat_cols]), columns=cat_cols)\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False).fit(X_cat_imp)\n",
    "X_cat_ohe = pd.DataFrame(ohe.transform(X_cat_imp), columns=ohe.get_feature_names_out(cat_cols))\n",
    "\n",
    "scaler = StandardScaler().fit(X_num_imp)\n",
    "X_num_scaled = pd.DataFrame(scaler.transform(X_num_imp), columns=num_cols)\n",
    "\n",
    "X_leaky = pd.concat([X_num_scaled, X_cat_ohe], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_leaky, y, test_size=0.25, random_state=7)\n",
    "\n",
    "model = Ridge(alpha=10.0)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(\"Leaky preprocessing (fit on full data) => R2:\", round(r2_score(y_test, pred), 4), \" MAE:\", round(mean_absolute_error(y_test, pred), 1))\n",
    "\n",
    "# -------------------------\n",
    "# GOOD: Pipeline (no leakage)\n",
    "# -------------------------\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                      (\"scaler\", StandardScaler())]), num_cols),\n",
    "    (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                      (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
    "])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", Ridge(alpha=10.0))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=7)\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"Pipeline (fit on train only)          => R2:\", round(r2_score(y_test, pred), 4), \" MAE:\", round(mean_absolute_error(y_test, pred), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398a06f",
   "metadata": {},
   "source": [
    "## 6) Lab C — Feature selection leakage (selection before CV)\n",
    "\n",
    "Feature selection can leak information when it is performed using the full dataset (or using the test fold) before cross‑validation.\n",
    "\n",
    "The leaky pattern:\n",
    "\n",
    "1. Compute feature scores using all rows (including future test folds)\n",
    "2. Keep top-$k$ features\n",
    "3. Cross-validate a model using only those features\n",
    "\n",
    "This is invalid because step (1) peeks at the test folds.\n",
    "\n",
    "### Correct pattern\n",
    "\n",
    "Put the feature selector inside a `Pipeline`, so it is fit separately within each training fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0118c5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaky feature selection => CV accuracy: 0.7893\n",
      "Selected features: ['residual sugar', 'chlorides', 'total sulfur dioxide', 'density', 'alcohol']\n",
      "Pipeline feature selection => CV accuracy: 0.7934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline feature selection => CV accuracy: 0.7825\n"
     ]
    }
   ],
   "source": [
    "df = wine.copy()\n",
    "\n",
    "# Define a binary target: \"high quality\" wines\n",
    "y = (df[\"quality\"] >= 7).astype(int)\n",
    "X = df.drop(columns=[\"quality\"])\n",
    "\n",
    "# BAD: select on full dataset\n",
    "selector = SelectKBest(score_func=f_classif, k=5).fit(X, y)\n",
    "X_selected_leaky = selector.transform(X)\n",
    "\n",
    "clf = LogisticRegression(max_iter=2000)\n",
    "scores_leaky = cross_val_score(clf, X_selected_leaky, y, cv=5, scoring=\"accuracy\")\n",
    "print(\"Leaky feature selection => CV accuracy:\", scores_leaky.mean().round(4))\n",
    "print(\"Selected features:\", X.columns[selector.get_support()].tolist())\n",
    "\n",
    "# GOOD: selection inside pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"selector\", SelectKBest(score_func=f_classif, k=5)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "scores_clean = cross_val_score(pipe, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(\"Pipeline feature selection => CV accuracy:\", scores_clean.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc5a1a",
   "metadata": {},
   "source": [
    "## 7) Lab D — Temporal leakage (random split vs forward split)\n",
    "\n",
    "When data has a time axis, a random split allows training to see the “future”. If there is trend, seasonality, or concept drift, this produces overly optimistic results.\n",
    "\n",
    "We will predict listing price using features available at the time of listing, and compare:\n",
    "\n",
    "- **Random split** (leaky for time problems)\n",
    "- **Forward split**: train on earlier dates, test on later dates (closer to deployment reality)\n",
    "\n",
    "A valid evaluation for time data often resembles: “train on past, predict future.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f457f519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random split MAE: 88.25\n",
      "Forward split MAE: 75.74\n",
      "\n",
      "Interpretation: if MAE is much smaller in random split than forward split,\n",
      "the random split is mixing future conditions into training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward split MAE: 34.35\n",
      "\n",
      "Interpretation: if MAE is much smaller in random split than forward split,\n",
      "the random split is mixing future conditions into training.\n"
     ]
    }
   ],
   "source": [
    "df = listings.copy()\n",
    "\n",
    "# Basic cleaning: remove missing target\n",
    "df = df.dropna(subset=[\"price\"]).copy()\n",
    "\n",
    "# Parse time\n",
    "df[\"last_review\"] = pd.to_datetime(df[\"last_review\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"last_review\"]).copy()\n",
    "\n",
    "y = df[\"price\"].astype(float)\n",
    "X = df.drop(columns=[\"price\"])\n",
    "\n",
    "# Engineer time features (available at prediction time)\n",
    "X = X.copy()\n",
    "X[\"review_year\"] = X[\"last_review\"].dt.year\n",
    "X[\"review_month\"] = X[\"last_review\"].dt.month\n",
    "X[\"review_dayofweek\"] = X[\"last_review\"].dt.dayofweek\n",
    "X = X.drop(columns=[\"last_review\"])\n",
    "\n",
    "num_cols = [\"latitude\",\"longitude\",\"minimum_nights\",\"number_of_reviews\",\"reviews_per_month\",\n",
    "            \"calculated_host_listings_count\",\"availability_365\",\"number_of_reviews_ltm\",\n",
    "            \"review_year\",\"review_month\",\"review_dayofweek\"]\n",
    "cat_cols = [\"neighbourhood\",\"room_type\",\"host_name\"]\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                      (\"scaler\", StandardScaler())]), num_cols),\n",
    "    (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                      (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "pipe = Pipeline([(\"prep\", preprocess), (\"model\", Ridge(alpha=15.0))])\n",
    "\n",
    "# ---- Random split (leaky for time) ----\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "mae_random = mean_absolute_error(y_test, pred)\n",
    "\n",
    "print(\"Random split MAE:\", round(mae_random, 2))\n",
    "\n",
    "# ---- Forward split (time-respecting) ----\n",
    "df_sorted = df.sort_values(\"last_review\").drop(columns=[\"price\"]).copy()\n",
    "y_sorted = df.sort_values(\"last_review\")[\"price\"].astype(float).to_numpy()\n",
    "\n",
    "# Recompute engineered features on the sorted frame\n",
    "X_sorted = df.sort_values(\"last_review\").drop(columns=[\"price\"]).copy()\n",
    "X_sorted[\"review_year\"] = X_sorted[\"last_review\"].dt.year\n",
    "X_sorted[\"review_month\"] = X_sorted[\"last_review\"].dt.month\n",
    "X_sorted[\"review_dayofweek\"] = X_sorted[\"last_review\"].dt.dayofweek\n",
    "X_sorted = X_sorted.drop(columns=[\"last_review\"])\n",
    "\n",
    "cut = int(len(X_sorted) * 0.8)\n",
    "X_train, X_test = X_sorted.iloc[:cut], X_sorted.iloc[cut:]\n",
    "y_train, y_test = y_sorted[:cut], y_sorted[cut:]\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "mae_forward = mean_absolute_error(y_test, pred)\n",
    "\n",
    "print(\"Forward split MAE:\", round(mae_forward, 2))\n",
    "\n",
    "print(\"\\nInterpretation: if MAE is much smaller in random split than forward split,\")\n",
    "print(\"the random split is mixing future conditions into training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c9c930",
   "metadata": {},
   "source": [
    "## 8) Lab E — Group leakage (entity appears in both train and test)\n",
    "\n",
    "Many real datasets contain multiple rows per entity:\n",
    "\n",
    "- multiple purchases per customer\n",
    "- multiple sessions per user\n",
    "- multiple medical visits per patient\n",
    "- multiple listings per host\n",
    "\n",
    "If the same entity appears in both train and test, the model can exploit entity-specific signals (including IDs, stable behavioral patterns, or even subtle artifacts). This produces optimistic evaluation and poor generalization to new entities.\n",
    "\n",
    "We will demonstrate this using `host_id` as the grouping variable.\n",
    "\n",
    "### Correct tool: `GroupKFold`\n",
    "\n",
    "`GroupKFold` ensures that all rows from a given group appear in a single fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c14682bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold MAE (hosts mixed): 85.82\n",
      "GroupKFold MAE (hosts separated): 94.56\n"
     ]
    }
   ],
   "source": [
    "df = listings.dropna(subset=[\"price\"]).copy()\n",
    "df[\"last_review\"] = pd.to_datetime(df[\"last_review\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"last_review\"]).copy()\n",
    "\n",
    "y = df[\"price\"].astype(float)\n",
    "X = df.drop(columns=[\"price\"]).copy()\n",
    "\n",
    "# Minimal time features\n",
    "X[\"review_year\"] = X[\"last_review\"].dt.year\n",
    "X[\"review_month\"] = X[\"last_review\"].dt.month\n",
    "X = X.drop(columns=[\"last_review\"])\n",
    "\n",
    "# Include host_id as a categorical feature (common in practice; also a leakage risk if split is wrong)\n",
    "cat_cols = [\"neighbourhood\",\"room_type\",\"host_name\",\"host_id\"]\n",
    "num_cols = [\"latitude\",\"longitude\",\"minimum_nights\",\"number_of_reviews\",\"reviews_per_month\",\n",
    "            \"calculated_host_listings_count\",\"availability_365\",\"number_of_reviews_ltm\",\n",
    "            \"review_year\",\"review_month\"]\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                      (\"scaler\", StandardScaler())]), num_cols),\n",
    "    (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                      (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
    "])\n",
    "\n",
    "pipe = Pipeline([(\"prep\", preprocess), (\"model\", Ridge(alpha=15.0))])\n",
    "\n",
    "# Leaky CV: regular KFold mixes hosts across folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "scores_kf = -cross_val_score(pipe, X, y, cv=kf, scoring=\"neg_mean_absolute_error\")\n",
    "print(\"KFold MAE (hosts mixed):\", round(scores_kf.mean(), 2))\n",
    "\n",
    "# Correct CV: GroupKFold keeps each host in one fold\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "groups = X[\"host_id\"]\n",
    "scores_gkf = -cross_val_score(pipe, X, y, cv=gkf, groups=groups, scoring=\"neg_mean_absolute_error\")\n",
    "print(\"GroupKFold MAE (hosts separated):\", round(scores_gkf.mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb7c03",
   "metadata": {},
   "source": [
    "## 9) Lab F — Train/test contamination via duplicates\n",
    "\n",
    "Duplicates (exact or near-exact) can easily occur due to:\n",
    "\n",
    "- repeated exports\n",
    "- joins that accidentally multiply rows\n",
    "- data ingestion retries\n",
    "- copies of the same record under different IDs\n",
    "\n",
    "If duplicates cross the train/test boundary, the evaluation partially measures “did we see this record already?”.\n",
    "\n",
    "We will:\n",
    "1. Inject duplicates into a dataset.\n",
    "2. Measure the overlap across splits.\n",
    "3. Observe the effect on metrics.\n",
    "4. Fix it by deduplicating or enforcing group-aware splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daa85d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random split accuracy: 0.8047\n",
      "Exact duplicate rows crossing split: 32\n",
      "\n",
      "After deduplication accuracy: 0.7812\n",
      "Group-aware split accuracy: 0.743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After deduplication accuracy: 1.0\n",
      "Group-aware split accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "df = diabetes.copy()\n",
    "\n",
    "# Create duplicates: copy 12% of rows and append\n",
    "dup_frac = 0.12\n",
    "dup = df.sample(frac=dup_frac, random_state=7)\n",
    "df_dup = pd.concat([df, dup], ignore_index=True)\n",
    "\n",
    "# Prepare features/target\n",
    "y = (df_dup[\"classification\"] == \"Diabetic\").astype(int)\n",
    "X = df_dup.drop(columns=[\"classification\"])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "# Random split (duplicates can cross the boundary)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=7, stratify=y)\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "acc_random = accuracy_score(y_test, pred)\n",
    "\n",
    "# Detect exact duplicates across the split by hashing feature rows\n",
    "train_hash = pd.util.hash_pandas_object(X_train, index=False)\n",
    "test_hash = pd.util.hash_pandas_object(X_test, index=False)\n",
    "overlap = np.intersect1d(train_hash.to_numpy(), test_hash.to_numpy()).size\n",
    "\n",
    "print(\"Random split accuracy:\", round(acc_random, 4))\n",
    "print(\"Exact duplicate rows crossing split:\", int(overlap))\n",
    "\n",
    "# Fix A: deduplicate before splitting\n",
    "df_dedup = df_dup.drop_duplicates()\n",
    "y2 = (df_dedup[\"classification\"] == \"Diabetic\").astype(int)\n",
    "X2 = df_dedup.drop(columns=[\"classification\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.25, random_state=7, stratify=y2)\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "print(\"\\nAfter deduplication accuracy:\", round(accuracy_score(y_test, pred), 4))\n",
    "\n",
    "# Fix B: group-aware split using the row-hash as group id (keeps duplicates together)\n",
    "groups = pd.util.hash_pandas_object(X, index=False).to_numpy()\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=7)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "print(\"Group-aware split accuracy:\", round(accuracy_score(y_test, pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe05eba",
   "metadata": {},
   "source": [
    "## 10) Lab G — Leakage in text/tabular joins (post-outcome fields in the table)\n",
    "\n",
    "Text datasets often come from multiple tables (events, responses, dispositions). A common error is joining post‑outcome fields into the training table.\n",
    "\n",
    "In the complaints dataset, imagine predicting `Timely Response` at the moment a complaint is received. Fields such as “Company Public Response” or “Company Response to Consumer” may be recorded later, and may directly reveal the target.\n",
    "\n",
    "We will compare:\n",
    "\n",
    "- A reasonable model using complaint narrative + metadata\n",
    "- A leaky model that includes a post-outcome column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2db70819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text+meta (clean) accuracy: 0.9781\n",
      "Text+meta + post-outcome column (leaky) accuracy: 0.9781\n"
     ]
    }
   ],
   "source": [
    "df = complaints.copy()\n",
    "\n",
    "# Target\n",
    "y = (df[\"Timely Response\"] == \"Yes\").astype(int)\n",
    "\n",
    "# Feature subsets\n",
    "text_col = \"Consumer Complaint Narrative\"\n",
    "meta_cols = [\"Product Name\", \"Issue\", \"Company\", \"State Name\", \"Submitted via\"]\n",
    "\n",
    "# Ensure text/categorical columns are strings (avoid NaN in vectorizer/encoder)\n",
    "df[text_col] = df[text_col].fillna(\"\")\n",
    "for c in meta_cols + [\"Company Public Response\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].fillna(\"Unknown\")\n",
    "\n",
    "# Clean set (no obvious post-outcome fields)\n",
    "X_clean = df[[text_col] + meta_cols].copy()\n",
    "\n",
    "# Leaky set (adds a post-outcome column)\n",
    "X_leaky = df[[text_col] + meta_cols + [\"Company Public Response\"]].copy()\n",
    "\n",
    "# Pipeline for text + categorical features\n",
    "def build_pipe(include_leaky=False):\n",
    "    cols = [text_col] + meta_cols + ([\"Company Public Response\"] if include_leaky else [])\n",
    "    X = df[cols].copy()\n",
    "\n",
    "    preprocess = ColumnTransformer([\n",
    "        (\"text\", TfidfVectorizer(min_df=2, ngram_range=(1, 2)), text_col),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "         meta_cols + ([\"Company Public Response\"] if include_leaky else [])),\n",
    "    ])\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"clf\", LogisticRegression(max_iter=2000))\n",
    "    ])\n",
    "    return X, pipe\n",
    "\n",
    "# Evaluate with a simple train/test split\n",
    "Xc, pipe_clean = build_pipe(include_leaky=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xc, y, test_size=0.25, random_state=7, stratify=y)\n",
    "pipe_clean.fit(X_train, y_train)\n",
    "pred = pipe_clean.predict(X_test)\n",
    "print(\"Text+meta (clean) accuracy:\", round(accuracy_score(y_test, pred), 4))\n",
    "\n",
    "Xl, pipe_leaky = build_pipe(include_leaky=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xl, y, test_size=0.25, random_state=7, stratify=y)\n",
    "pipe_leaky.fit(X_train, y_train)\n",
    "pred = pipe_leaky.predict(X_test)\n",
    "print(\"Text+meta + post-outcome column (leaky) accuracy:\", round(accuracy_score(y_test, pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bf083b",
   "metadata": {},
   "source": [
    "## 11) Prevention playbook (what to do in real projects)\n",
    "\n",
    "### 11.1 Split first, then fit\n",
    "\n",
    "A high-integrity workflow is:\n",
    "\n",
    "1. Choose the correct split strategy:\n",
    "   - i.i.d. data: stratified random split\n",
    "   - time data: forward split or rolling windows\n",
    "   - grouped data: group-aware split\n",
    "2. Freeze the test set.\n",
    "3. Do **all** preprocessing inside pipelines.\n",
    "4. Tune hyperparameters using only training data (often with nested CV).\n",
    "5. Report a final score once on the frozen test set.\n",
    "\n",
    "### 11.2 Always use `Pipeline` / `ColumnTransformer`\n",
    "\n",
    "Common leak sources that pipelines fix automatically:\n",
    "\n",
    "- scalers (`StandardScaler`, `MinMaxScaler`)\n",
    "- imputers (`SimpleImputer`)\n",
    "- encoders (`OneHotEncoder`, target encoding alternatives)\n",
    "- feature selection (`SelectKBest`, PCA)\n",
    "- resampling (should be applied inside CV folds)\n",
    "\n",
    "### 11.3 Time-aware and group-aware validation\n",
    "\n",
    "If you have `timestamp` or an entity key:\n",
    "\n",
    "- Prefer `TimeSeriesSplit` for backtesting-like evaluation.\n",
    "- Prefer `GroupKFold` / `GroupShuffleSplit` when multiple rows per entity exist.\n",
    "\n",
    "### 11.4 Leakage forensics checklist\n",
    "\n",
    "If you suspect leakage, check:\n",
    "\n",
    "- Are there columns generated *after* the target event?\n",
    "- Are there duplicates or near-duplicates across splits?\n",
    "- Do any features have suspiciously high correlation with the target?\n",
    "- Did you compute any aggregates using the full dataset (including test)?\n",
    "- Did you perform feature selection before CV?\n",
    "- Did you tune hyperparameters on the test set?\n",
    "\n",
    "### 11.5 A minimal “safe template”\n",
    "\n",
    "Below is a compact template that you can adapt. It is not a complete MLOps system, but it enforces the most important invariants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beaec71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example usage: choose a split mode and keep all preprocessing inside a Pipeline.\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class SplitConfig:\n",
    "    mode: str  # \"iid\", \"time\", \"group\"\n",
    "    test_size: float = 0.2\n",
    "    time_col: str | None = None\n",
    "    group_col: str | None = None\n",
    "    random_state: int = 7\n",
    "\n",
    "def make_splits(df, y, cfg: SplitConfig):\n",
    "    if cfg.mode == \"iid\":\n",
    "        return train_test_split(df, y, test_size=cfg.test_size, random_state=cfg.random_state, stratify=y)\n",
    "    if cfg.mode == \"time\":\n",
    "        if cfg.time_col is None:\n",
    "            raise ValueError(\"time_col is required for time split\")\n",
    "        d = df.copy()\n",
    "        d[cfg.time_col] = pd.to_datetime(d[cfg.time_col], errors=\"coerce\")\n",
    "        d = d.dropna(subset=[cfg.time_col]).sort_values(cfg.time_col)\n",
    "        cut = int(len(d) * (1 - cfg.test_size))\n",
    "        X_train, X_test = d.iloc[:cut].drop(columns=[cfg.time_col]), d.iloc[cut:].drop(columns=[cfg.time_col])\n",
    "        y_train, y_test = y.loc[d.index[:cut]], y.loc[d.index[cut:]]\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    if cfg.mode == \"group\":\n",
    "        if cfg.group_col is None:\n",
    "            raise ValueError(\"group_col is required for group split\")\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=cfg.test_size, random_state=cfg.random_state)\n",
    "        groups = df[cfg.group_col]\n",
    "        train_idx, test_idx = next(gss.split(df, y, groups=groups))\n",
    "        return df.iloc[train_idx], df.iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
    "    raise ValueError(\"Unknown mode\")\n",
    "\n",
    "print(\"Example usage: choose a split mode and keep all preprocessing inside a Pipeline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a8fa36",
   "metadata": {},
   "source": [
    "## 12) Exercises (recommended)\n",
    "\n",
    "1. In the diabetes example, invent two additional “post-outcome” columns that would realistically appear in healthcare data. Confirm the metric inflation, then remove them.\n",
    "2. In the listings example, create a “rolling average price by neighbourhood” feature. Implement it **correctly** so that each row uses only past data.\n",
    "3. In the complaints example, add `Company Response to Consumer` and quantify the leakage. Then build a model that only uses fields available at complaint time.\n",
    "4. For any dataset you work with, write down an explicit “as-of” time for each feature. Treat that as a contract.\n",
    "\n",
    "If you can reliably prevent leakage, you will usually improve real-world model reliability more than by switching to a more complex algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dda1d7",
   "metadata": {},
   "source": [
    "## 13) Advanced leakage patterns (you will see these in real pipelines)\n",
    "\n",
    "### 13.1 Target encoding leakage\n",
    "\n",
    "Target encoding replaces a categorical value $c$ with a statistic of the target, for example:\n",
    "\n",
    "$$\n",
    "\\mathrm{TE}(c) = \\mathbb{E}[y \\mid x_{cat} = c].\n",
    "$$\n",
    "\n",
    "If you compute $\\mathrm{TE}(c)$ using the **full dataset**, then the encoding of categories in the test set has already “seen” $y$ from the test set. This can create dramatic metric inflation.\n",
    "\n",
    "The safe variants are:\n",
    "\n",
    "- Compute encodings using **training data only**, then apply to test.\n",
    "- For cross-validation, compute encodings per fold (out-of-fold encoding).\n",
    "- Apply smoothing/shrinkage to reduce overfitting on rare categories.\n",
    "\n",
    "### 13.2 Resampling leakage (imbalanced data)\n",
    "\n",
    "If you oversample/SMOTE before splitting, you can create near-duplicates that appear in both train and test. That turns evaluation into a memorization test.\n",
    "\n",
    "Safe pattern:\n",
    "- split first\n",
    "- resample only the training partition (and, ideally, only within CV folds)\n",
    "\n",
    "### 13.3 Hyperparameter selection leakage\n",
    "\n",
    "The test set must not guide model selection. If you compare many models on the test set and pick the best, you are implicitly fitting to test noise.\n",
    "\n",
    "Safe pattern:\n",
    "- use an inner CV for tuning\n",
    "- use an outer CV or a single frozen test set for reporting\n",
    "\n",
    "A common nested CV view is:\n",
    "\n",
    "$$\n",
    "\\text{Generalization estimate} \\approx \\frac{1}{K}\\sum_{k=1}^K \\mathrm{score}\\big(f_{\\hat{\\theta}_k}, D^{(test)}_k\\big),\n",
    "$$\n",
    "\n",
    "where each $\\hat{\\theta}_k$ is chosen using only the corresponding training fold (often with its own inner CV).\n",
    "\n",
    "We now implement two additional labs: target encoding leakage and resampling leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21dbb10",
   "metadata": {},
   "source": [
    "## 14) Lab H — Target encoding leakage (mean encoding)\n",
    "\n",
    "We will build a feature `neighborhood_mean_price` computed from the target. If we compute it on the full dataset, the test rows leak their target values into the encoding.\n",
    "\n",
    "Then we will fix it by computing the encoding on training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ef6619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaky target encoding => R2: 0.4927\n",
      "Train-only target encoding => R2: 0.4901\n"
     ]
    }
   ],
   "source": [
    "df = house.copy()\n",
    "\n",
    "y = df[\"Price\"].astype(float)\n",
    "X = df.drop(columns=[\"Price\"]).copy()\n",
    "\n",
    "# BAD: mean encoding computed on the full dataset (leak)\n",
    "full_means = df.groupby(\"Neighborhood\")[\"Price\"].mean()\n",
    "X_leaky = X.copy()\n",
    "X_leaky[\"neighborhood_mean_price\"] = X_leaky[\"Neighborhood\"].map(full_means)\n",
    "\n",
    "# Use a simple model that can exploit the leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_leaky[[\"neighborhood_mean_price\"]], y, test_size=0.25, random_state=7)\n",
    "m = Ridge(alpha=1.0).fit(X_train, y_train)\n",
    "pred = m.predict(X_test)\n",
    "print(\"Leaky target encoding => R2:\", round(r2_score(y_test, pred), 4))\n",
    "\n",
    "# GOOD: split first, then compute means on training only\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "train_means = pd.concat([X_train_raw, y_train], axis=1).groupby(\"Neighborhood\")[\"Price\"].mean()\n",
    "global_mean = y_train.mean()\n",
    "\n",
    "X_train_enc = pd.DataFrame({\n",
    "    \"neighborhood_mean_price\": X_train_raw[\"Neighborhood\"].map(train_means).fillna(global_mean)\n",
    "})\n",
    "X_test_enc = pd.DataFrame({\n",
    "    \"neighborhood_mean_price\": X_test_raw[\"Neighborhood\"].map(train_means).fillna(global_mean)\n",
    "})\n",
    "\n",
    "m = Ridge(alpha=1.0).fit(X_train_enc, y_train)\n",
    "pred = m.predict(X_test_enc)\n",
    "print(\"Train-only target encoding => R2:\", round(r2_score(y_test, pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a47e1c0",
   "metadata": {},
   "source": [
    "## 15) Lab I — Resampling leakage with imbalanced classes\n",
    "\n",
    "We will treat “high quality wine” as the positive class. This is intentionally imbalanced.\n",
    "\n",
    "We will compare:\n",
    "\n",
    "- Oversampling before splitting (leaky)\n",
    "- Splitting first, then oversampling train only (clean)\n",
    "\n",
    "To keep the example transparent, we implement oversampling by duplicating minority samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e8b6a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance (original):\n",
      "quality\n",
      "0    0.784\n",
      "1    0.216\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Oversample-before-split accuracy: 0.7223\n",
      "Exact duplicate rows crossing split: 775\n",
      "\n",
      "Split-then-oversample accuracy: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split-then-oversample accuracy: 0.745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df = wine.copy()\n",
    "y = (df[\"quality\"] >= 7).astype(int)\n",
    "X = df.drop(columns=[\"quality\"]).copy()\n",
    "\n",
    "print(\"Class balance (original):\")\n",
    "print(y.value_counts(normalize=True).round(3))\n",
    "\n",
    "def oversample_train(X_train, y_train, random_state=7):\n",
    "    Xy = pd.concat([X_train, y_train.rename(\"y\")], axis=1)\n",
    "    maj = Xy[Xy[\"y\"] == 0]\n",
    "    mino = Xy[Xy[\"y\"] == 1]\n",
    "    mino_up = resample(mino, replace=True, n_samples=len(maj), random_state=random_state)\n",
    "    up = pd.concat([maj, mino_up]).sample(frac=1, random_state=random_state)\n",
    "    return up.drop(columns=[\"y\"]), up[\"y\"]\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "# BAD: oversample first, then split (creates duplicates across split)\n",
    "Xy = pd.concat([X, y.rename(\"y\")], axis=1)\n",
    "maj = Xy[Xy[\"y\"] == 0]\n",
    "mino = Xy[Xy[\"y\"] == 1]\n",
    "mino_up = resample(mino, replace=True, n_samples=len(maj), random_state=7)\n",
    "Xy_up = pd.concat([maj, mino_up]).sample(frac=1, random_state=7)\n",
    "X_up = Xy_up.drop(columns=[\"y\"])\n",
    "y_up = Xy_up[\"y\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_up, y_up, test_size=0.25, random_state=7, stratify=y_up)\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "acc_leaky = accuracy_score(y_test, pred)\n",
    "\n",
    "# Duplicate overlap check (hash-based)\n",
    "train_hash = pd.util.hash_pandas_object(X_train, index=False)\n",
    "test_hash = pd.util.hash_pandas_object(X_test, index=False)\n",
    "overlap = np.intersect1d(train_hash.to_numpy(), test_hash.to_numpy()).size\n",
    "\n",
    "print(\"\\nOversample-before-split accuracy:\", round(acc_leaky, 4))\n",
    "print(\"Exact duplicate rows crossing split:\", int(overlap))\n",
    "\n",
    "# GOOD: split first, oversample train only\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=7, stratify=y)\n",
    "X_train_up, y_train_up = oversample_train(X_train, y_train)\n",
    "\n",
    "pipe.fit(X_train_up, y_train_up)\n",
    "pred = pipe.predict(X_test)\n",
    "acc_clean = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"\\nSplit-then-oversample accuracy:\", round(acc_clean, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8312be",
   "metadata": {},
   "source": [
    "## 16) Lab J — Model selection leakage (tuning on the test set)\n",
    "\n",
    "A subtle but common leakage pattern:\n",
    "\n",
    "1. Split data into train and test.\n",
    "2. Try many model variants/hyperparameters.\n",
    "3. Pick the best based on test performance.\n",
    "4. Report that same test performance as “final”.\n",
    "\n",
    "This is invalid because the test set has become part of the training process (through selection).\n",
    "\n",
    "### Demonstration strategy\n",
    "\n",
    "We will run a small Monte Carlo simulation:\n",
    "\n",
    "- Each repetition creates a new random split into train/validation/test.\n",
    "- We try a grid of $C$ values for logistic regression.\n",
    "- We compare two selection strategies:\n",
    "  - **Correct**: select hyperparameters on validation, then report test score once.\n",
    "  - **Leaky**: select hyperparameters directly on test, then report that same test score.\n",
    "\n",
    "Across repetitions, the leaky strategy will look better on average, even though it does not truly generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25f17787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test accuracy (correct selection): 0.7578\n",
      "Average test accuracy (leaky selection)  : 0.7662\n",
      "Typical gap (leaky - correct): 0.0084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = diabetes.copy()\n",
    "y = (df[\"classification\"] == \"Diabetic\").astype(int)\n",
    "X = df.drop(columns=[\"classification\"])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "C_grid = [0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "\n",
    "def fit_with_C(C):\n",
    "    p = Pipeline(pipe.steps[:-1] + [(\"clf\", LogisticRegression(max_iter=2000, C=C))])\n",
    "    return p\n",
    "\n",
    "def one_run(seed):\n",
    "    # train/val/test split: 60/20/20\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=seed, stratify=y_temp)\n",
    "\n",
    "    # Correct selection on validation\n",
    "    best_C_val = None\n",
    "    best_val = -1\n",
    "    for C in C_grid:\n",
    "        m = fit_with_C(C)\n",
    "        m.fit(X_train, y_train)\n",
    "        val_acc = accuracy_score(y_val, m.predict(X_val))\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_C_val = C\n",
    "    m_val = fit_with_C(best_C_val)\n",
    "    m_val.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\n",
    "    test_acc_correct = accuracy_score(y_test, m_val.predict(X_test))\n",
    "\n",
    "    # Leaky selection on test\n",
    "    best_C_test = None\n",
    "    best_test = -1\n",
    "    for C in C_grid:\n",
    "        m = fit_with_C(C)\n",
    "        m.fit(X_train, y_train)\n",
    "        test_acc = accuracy_score(y_test, m.predict(X_test))\n",
    "        if test_acc > best_test:\n",
    "            best_test = test_acc\n",
    "            best_C_test = C\n",
    "    # report the same test used for selection\n",
    "    test_acc_leaky = best_test\n",
    "\n",
    "    return test_acc_correct, test_acc_leaky, best_C_val, best_C_test\n",
    "\n",
    "runs = 40\n",
    "correct_scores = []\n",
    "leaky_scores = []\n",
    "for s in range(100, 100 + runs):\n",
    "    a, b, _, _ = one_run(s)\n",
    "    correct_scores.append(a)\n",
    "    leaky_scores.append(b)\n",
    "\n",
    "print(\"Average test accuracy (correct selection):\", round(float(np.mean(correct_scores)), 4))\n",
    "print(\"Average test accuracy (leaky selection)  :\", round(float(np.mean(leaky_scores)), 4))\n",
    "print(\"Typical gap (leaky - correct):\", round(float(np.mean(np.array(leaky_scores) - np.array(correct_scores))), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189600e",
   "metadata": {},
   "source": [
    "## 17) Leakage audit and governance (practitioner-grade)\n",
    "\n",
    "In mature ML systems, leakage prevention is not just a modeling trick; it is a **data governance and process discipline**. The highest-impact controls are often upstream of the model.\n",
    "\n",
    "### 17.1 Feature availability contracts (“as-of” timestamps)\n",
    "\n",
    "For every feature, record:\n",
    "\n",
    "- **Source table / system**\n",
    "- **Definition**\n",
    "- **Refresh cadence**\n",
    "- **Availability time** relative to the prediction moment (the “as-of” moment)\n",
    "- **Backfill behavior** (does the table get updated retroactively?)\n",
    "\n",
    "A simple rule is:\n",
    "\n",
    "> A feature is eligible only if it can be computed using information available at or before the prediction timestamp.\n",
    "\n",
    "This prevents subtle leaks, including those caused by ETL backfills.\n",
    "\n",
    "### 17.2 Joins are the #1 leakage gateway\n",
    "\n",
    "Many leaks are created when multiple tables are joined without careful attention to time:\n",
    "\n",
    "- Joining a complaint record with a later “resolution” record.\n",
    "- Joining a user record with a later “churn flag”.\n",
    "- Joining an order with its “refund outcome”.\n",
    "\n",
    "When joining, treat time as a first-class key. Typical patterns:\n",
    "\n",
    "- Use **as-of joins** (join the latest record *before* the prediction time).\n",
    "- Enforce `join_timestamp <= prediction_timestamp`.\n",
    "\n",
    "### 17.3 Label leakage and label delay\n",
    "\n",
    "Labels are often created after the fact:\n",
    "\n",
    "- fraud labels appear after investigation\n",
    "- churn labels appear after a window of inactivity\n",
    "- default labels appear after missed payments\n",
    "\n",
    "If you train on data that includes features computed after the label window closes, you can leak. A robust approach is to build training examples with a clear timeline:\n",
    "\n",
    "- observation window: $[t_0, t_{obs}]$\n",
    "- prediction time: $t_{pred}$\n",
    "- label window: $(t_{pred}, t_{label}]$\n",
    "\n",
    "A safe dataset respects $t_{obs} \\le t_{pred} < t_{label}$ and prevents any feature from depending on data after $t_{pred}$.\n",
    "\n",
    "### 17.4 “Too good to be true” diagnostics\n",
    "\n",
    "High accuracy is not always leakage, but it should trigger a review if:\n",
    "\n",
    "- The improvement is sudden after feature additions or a join.\n",
    "- A single feature dominates importance (e.g., permutation importance is extreme).\n",
    "- The model achieves near-perfect score in a domain that is known to be noisy.\n",
    "- Cross-validation scores vary wildly depending on the split strategy.\n",
    "\n",
    "### 17.5 Practical audit steps you can automate\n",
    "\n",
    "1. **Duplicate & near-duplicate detection**\n",
    "   - Hash rows, check overlaps across splits.\n",
    "   - For near-duplicates, use similarity on key fields (e.g., text fingerprints).\n",
    "2. **Entity overlap report**\n",
    "   - Count unique entities in train, test, and intersection.\n",
    "3. **Time leakage report**\n",
    "   - Ensure all training timestamps are earlier than test timestamps in forward evaluations.\n",
    "4. **Suspicious feature scan**\n",
    "   - High mutual information / correlation with the target.\n",
    "   - Feature names containing target-related tokens (domain-specific).\n",
    "5. **Pipeline enforcement**\n",
    "   - Fail builds if `.fit()` is called on preprocessing objects outside a pipeline.\n",
    "\n",
    "These controls turn leakage prevention into a repeatable engineering practice rather than a one-off notebook correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6994283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features by mutual information (higher can be a leakage red flag):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "post_diagnosis_flag         0.647451\n",
       "Glucose                     0.124771\n",
       "BMI                         0.080343\n",
       "Age                         0.055995\n",
       "Insulin                     0.034215\n",
       "Pregnancies                 0.024920\n",
       "DiabetesPedigreeFunction    0.007056\n",
       "SkinThickness               0.002824\n",
       "BloodPressure               0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "df = diabetes.copy()\n",
    "y = (df[\"classification\"] == \"Diabetic\").astype(int)\n",
    "X = df.drop(columns=[\"classification\"]).copy()\n",
    "\n",
    "# Create one leaky feature again to see how forensics picks it up\n",
    "X[\"post_diagnosis_flag\"] = y + np.random.default_rng(7).normal(0, 0.05, size=len(y))\n",
    "\n",
    "X_imp = SimpleImputer(strategy=\"median\").fit_transform(X)\n",
    "\n",
    "mi = mutual_info_classif(X_imp, y, random_state=7)\n",
    "mi_series = pd.Series(mi, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "print(\"Top features by mutual information (higher can be a leakage red flag):\")\n",
    "display(mi_series.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c2a39",
   "metadata": {},
   "source": [
    "## 18) Case study: how leakage sneaks in during feature engineering\n",
    "\n",
    "Consider a simplified “will a customer default in the next 90 days?” problem. Teams often build features from multiple sources:\n",
    "\n",
    "- transactions table (daily)\n",
    "- account status table (updates when status changes)\n",
    "- collections table (updates when a case is opened)\n",
    "- payments table (timestamps for successful and failed payments)\n",
    "\n",
    "### The intended timeline\n",
    "\n",
    "- Prediction time: $t_{pred}$ (today)\n",
    "- Label: default in $(t_{pred}, t_{pred}+90\\text{ days}]$\n",
    "\n",
    "The model should only use information available up to $t_{pred}$.\n",
    "\n",
    "### A realistic leakage incident\n",
    "\n",
    "A feature engineer adds: “number of collections interactions” and “collection case opened flag”. Those fields are populated *after* the bank starts collections, which happens when the customer is already in trouble. In the training dataset, these features become extremely predictive. Cross-validation score spikes. The model is celebrated.\n",
    "\n",
    "In production, however, these features are unavailable at $t_{pred}$ for most customers. The model is now deprived of its strongest signals and fails.\n",
    "\n",
    "### Lessons\n",
    "\n",
    "1. Leakage is often created by good intentions:\n",
    "   - “Let’s add operational data, it must help.”\n",
    "2. Time is the most important join key:\n",
    "   - “As-of” correctness beats “more data”.\n",
    "3. Auditing matters:\n",
    "   - A sudden metric jump after adding new tables should trigger a formal review.\n",
    "\n",
    "### A concrete checklist for feature additions\n",
    "\n",
    "Whenever you add a new feature (especially from a new data source), answer:\n",
    "\n",
    "- What is the exact timestamp when this value becomes known?\n",
    "- Can it be computed at inference time for every record?\n",
    "- Does the table get backfilled or updated retroactively?\n",
    "- Does the feature encode an operational decision that is downstream of the target?\n",
    "- If this feature is missing in production for many users, what happens?\n",
    "\n",
    "This kind of process discipline is what separates robust ML systems from “demo-grade” notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
