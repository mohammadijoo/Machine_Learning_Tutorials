{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01fc3d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&display=swap');\n",
       "\n",
       "\n",
       "/* Text areas (Classic Notebook + JupyterLab) */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "div.rendered_html, .output_subarea {\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "/* RTL for rendered markdown/html content */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "h1, h2, h3, h4, h5, h6, p, strong, label, ol, ul, li {\n",
       "  line-height: 1.9;\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "h1 { font-size: 2rem; color: #070F2B; font-weight: 900}\n",
       "h2 { font-size: 1.8rem; color: #070F2B; font-weight: 800}\n",
       "h3 { font-size: 1.6rem; color: #070F2B; font-weight: 700}\n",
       "h4 { font-size: 1.4rem; color: #1E3E62; font-weight: 600}\n",
       "h5 { font-size: 1.2rem; color: #1E3E62}\n",
       "h6 { font-size: 1rem; color: #1E3E62}\n",
       "p { font-size: 1.1rem; ; font-weight: 400}\n",
       "ol, ul, li, th, td  { font-size: 1rem; }\n",
       "\n",
       "/* Keep code + outputs LTR and monospace */\n",
       ".CodeMirror, .CodeMirror *,\n",
       "pre, code,\n",
       ".jp-CodeCell .jp-InputArea, .jp-CodeCell .jp-InputArea *,\n",
       ".jp-OutputArea, .jp-OutputArea * {\n",
       "  direction: ltr !important;\n",
       "  text-align: left !important;\n",
       "  font-size: 1rem !important;\n",
       "  font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "css = Path(\"../../../css/custom.css\").read_text(encoding=\"utf-8\")\n",
    "display(HTML(f\"<style>{css}</style>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d926b9e",
   "metadata": {},
   "source": [
    "# Chapter 2 — Data Transformation and Encoding\n",
    "## Lesson 13: Building Preprocessing Pipelines (Fit/Transform Discipline, Column-Wise Pipelines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea98db4",
   "metadata": {},
   "source": [
    "\n",
    "### What you will learn\n",
    "\n",
    "By the end of this lesson, you should be able to:\n",
    "\n",
    "- Explain *why* preprocessing must be learned only from training data and then reused unchanged on validation/test data.\n",
    "- Use `Pipeline` to chain multiple preprocessing steps with an estimator in a single, safe object.\n",
    "- Use `ColumnTransformer` to apply different preprocessing to numeric, categorical, and text columns.\n",
    "- Diagnose common pipeline failures: shape mismatches, sparse/dense issues, missing-value handling, and feature-name tracking.\n",
    "- Set up cross-validation and hyperparameter tuning *without* data leakage.\n",
    "\n",
    "---\n",
    "\n",
    "### Why pipelines exist (the problem they solve)\n",
    "\n",
    "In classical machine learning on tabular data, the model rarely consumes the raw table directly. Instead, we apply a sequence of transformations:\n",
    "\n",
    "- cleaning (missing values, type fixes),\n",
    "- encoding (categorical to numeric),\n",
    "- scaling (standardization/normalization),\n",
    "- feature generation (interaction terms, log transforms, date parts),\n",
    "- dimensionality reduction (optional).\n",
    "\n",
    "A dangerous temptation is to do these transformations “once” on the entire dataset and then split into train/test. That breaks the most important rule:\n",
    "\n",
    "> **Any transformation with learned parameters must be fitted only on training data.**\n",
    "\n",
    "Examples of learned parameters:\n",
    "\n",
    "- mean and standard deviation for standardization,\n",
    "- category-to-index mapping for one-hot encoding,\n",
    "- vocabulary and IDF weights for TF–IDF,\n",
    "- imputation statistics (median, most-frequent),\n",
    "- PCA components.\n",
    "\n",
    "If those parameters “see” the test set, the transformation becomes a covert channel that leaks information from test to train.\n",
    "\n",
    "---\n",
    "\n",
    "### Fit/Transform discipline as a mathematical statement\n",
    "\n",
    "Let $D = \\{(x_i, y_i)\\}_{i=1}^n$ be a dataset, split into training and test sets:\n",
    "\n",
    "$$D_{\\text{train}} \\cup D_{\\text{test}} = D, \\quad D_{\\text{train}} \\cap D_{\\text{test}} = \\emptyset.$$\n",
    "\n",
    "A preprocessing step is typically a pair of operations:\n",
    "\n",
    "- **fit**: estimate parameters $\\theta$ from data\n",
    "- **transform**: apply those parameters to inputs\n",
    "\n",
    "Formally, a transformer $T$ induces:\n",
    "\n",
    "$$\\theta = \\mathrm{fit}(T, X_{\\text{train}}), \\qquad Z = \\mathrm{transform}(T, X; \\theta).$$\n",
    "\n",
    "The rule is:\n",
    "\n",
    "$$Z_{\\text{train}} = \\mathrm{transform}(T, X_{\\text{train}}; \\theta), \\quad\n",
    "Z_{\\text{test}} = \\mathrm{transform}(T, X_{\\text{test}}; \\theta)$$\n",
    "\n",
    "with the *same* $\\theta$ learned only from $X_{\\text{train}}$.\n",
    "\n",
    "A **pipeline** packages this discipline so it is hard to violate accidentally.\n",
    "\n",
    "---\n",
    "\n",
    "### High-level mental model\n",
    "\n",
    "A pipeline is a function composition:\n",
    "\n",
    "$$f(x) = (M \\circ T_k \\circ \\cdots \\circ T_2 \\circ T_1)(x)$$\n",
    "\n",
    "where $T_j$ are preprocessing transformations and $M$ is the final estimator.\n",
    "\n",
    "During training, each $T_j$ is fitted on the output of previous steps **using only training folds** inside cross-validation. This is exactly why pipelines are essential for reliable evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068171ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101ee456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def read_csv(path, **kwargs):\n",
    "    return pd.read_csv(path, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d344143e",
   "metadata": {},
   "source": [
    "\n",
    "### A quick leakage demonstration (standardization done wrong)\n",
    "\n",
    "Standardization is:\n",
    "\n",
    "$$x' = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "If you estimate $\\mu$ and $\\sigma$ using *all* data (train + test), you are using test distribution information during training.\n",
    "\n",
    "In the code below we compare two workflows:\n",
    "\n",
    "1. **Wrong**: fit the scaler before splitting.\n",
    "2. **Correct**: put scaler inside a pipeline.\n",
    "\n",
    "You should expect the “wrong” workflow to be *optimistically biased*—sometimes by a lot, sometimes only slightly, but always in the wrong direction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c53b486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Workflow</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wrong (leakage)</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Correct (pipeline)</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Workflow  Accuracy  ROC-AUC\n",
       "0     Wrong (leakage)  0.734375    0.832\n",
       "1  Correct (pipeline)  0.734375    0.832"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset: diabetes (binary classification)\n",
    "path_diabetes = \"../../../Datasets/Classification/diabetes.csv\"\n",
    "df = read_csv(path_diabetes)\n",
    "\n",
    "X = df.drop(columns=[\"classification\"])\n",
    "y = df[\"classification\"]\n",
    "\n",
    "# Encode target as 0/1 for metrics\n",
    "y01 = (y == \"Diabetic\").astype(int)\n",
    "\n",
    "# Wrong workflow: scale before splitting (leaks test distribution into scaler)\n",
    "scaler_wrong = StandardScaler()\n",
    "X_wrong = scaler_wrong.fit_transform(X)\n",
    "\n",
    "Xw_train, Xw_test, yw_train, yw_test = train_test_split(\n",
    "    X_wrong, y01, test_size=0.25, random_state=42, stratify=y01\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(max_iter=2000)\n",
    "clf.fit(Xw_train, yw_train)\n",
    "pred_proba_wrong = clf.predict_proba(Xw_test)[:, 1]\n",
    "pred_wrong = (pred_proba_wrong >= 0.5).astype(int)\n",
    "\n",
    "acc_wrong = accuracy_score(yw_test, pred_wrong)\n",
    "auc_wrong = roc_auc_score(yw_test, pred_proba_wrong)\n",
    "\n",
    "# Correct workflow: scaler inside a Pipeline\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y01, test_size=0.25, random_state=42, stratify=y01\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pred_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "pred = (pred_proba >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "auc = roc_auc_score(y_test, pred_proba)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Workflow\": [\"Wrong (leakage)\", \"Correct (pipeline)\"],\n",
    "    \"Accuracy\": [acc_wrong, acc],\n",
    "    \"ROC-AUC\": [auc_wrong, auc],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89679a1",
   "metadata": {},
   "source": [
    "\n",
    "### Pipeline internals: parameter routing and “double underscores”\n",
    "\n",
    "Each pipeline step has a **name**. Hyperparameters are addressed using:\n",
    "\n",
    "`<step_name>__<parameter_name>`\n",
    "\n",
    "Example:\n",
    "\n",
    "- `model__C` adjusts the regularization strength of a logistic regression model,\n",
    "- `preprocess__cat__onehot__min_frequency` adjusts the categorical encoder behavior (if supported in your version).\n",
    "\n",
    "This is not syntactic sugar; it is what makes nested tuning feasible.\n",
    "\n",
    "---\n",
    "\n",
    "### Why leakage breaks evaluation (a compact argument)\n",
    "\n",
    "Suppose you evaluate a model on $D_{\\text{test}}$ after transforming inputs with parameters $\\theta$ estimated from *all* $X$ (including $X_{\\text{test}}$). Then your evaluation is not measuring:\n",
    "\n",
    "$$\\mathbb{E}_{(X,Y) \\sim \\mathcal{P}}[L(Y, f(X))]$$\n",
    "\n",
    "for a pipeline trained on *independent* training data. Instead, it measures performance **conditional on the specific test set** because $\\theta$ is a function of $X_{\\text{test}}$:\n",
    "\n",
    "$$\\theta = g(X_{\\text{train}}, X_{\\text{test}}).$$\n",
    "\n",
    "Therefore, the predictor you evaluate is:\n",
    "\n",
    "$$f_{\\theta}(\\cdot) = M(T(\\cdot; \\theta))$$\n",
    "\n",
    "and $f_{\\theta}$ depends on the test set you are evaluating on. This violates the independence that makes holdout error or cross-validation a valid proxy for generalization.\n",
    "\n",
    "Pipelines restore the intended structure: each fold is transformed by parameters learned from that fold’s training split only.\n",
    "\n",
    "---\n",
    "\n",
    "### Common preprocessing steps that *must* live inside the pipeline\n",
    "\n",
    "1. **Imputation** (missing-value statistics are learned)\n",
    "2. **Scaling** (mean/variance are learned)\n",
    "3. **Encoding** (category mappings are learned)\n",
    "4. **Text vectorization** (vocabulary and IDF are learned)\n",
    "5. **Dimensionality reduction** (projection matrix is learned)\n",
    "6. **Target-based encoders** (explicitly learned from $y$, requiring extra care)\n",
    "\n",
    "Stateless transforms (e.g., `np.log1p`, clipping, unit conversions) can be applied either inside or outside; but it is usually cleaner to keep everything inside one pipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a04224",
   "metadata": {},
   "source": [
    "\n",
    "### Cross-validation with pipelines: what is being estimated?\n",
    "\n",
    "In $K$-fold cross-validation, you repeatedly train on $K-1$ folds and validate on the held-out fold. If $L$ is a loss function, the cross-validation estimate is:\n",
    "\n",
    "$$\\hat R_{\\text{CV}} = \\frac{1}{K} \\sum_{k=1}^K \\frac{1}{|\\mathcal{I}_k|} \\sum_{i \\in \\mathcal{I}_k} L\\big(y_i, \\hat y_i^{(-k)}\\big)$$\n",
    "\n",
    "where $\\hat y_i^{(-k)}$ is the prediction for sample $i$ produced by a model trained without fold $k$.\n",
    "\n",
    "If you preprocess outside the pipeline, the transformation has already “seen” all folds, so $\\hat y_i^{(-k)}$ is no longer produced by a model trained without that fold. Pipelines ensure that for each fold:\n",
    "\n",
    "- the transformer parameters are estimated on the training portion of that fold,\n",
    "- the validation fold is transformed using those parameters only.\n",
    "\n",
    "This is one of the highest-leverage habits you can build in applied ML.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6721f685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_roc_auc</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816852</td>\n",
       "      <td>0.830388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.869259</td>\n",
       "      <td>0.830388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.841111</td>\n",
       "      <td>0.830388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.808868</td>\n",
       "      <td>0.830388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.815849</td>\n",
       "      <td>0.830388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold_roc_auc      mean\n",
       "0      0.816852  0.830388\n",
       "1      0.869259  0.830388\n",
       "2      0.841111  0.830388\n",
       "3      0.808868  0.830388\n",
       "4      0.815849  0.830388"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validation with a pipeline: preprocessing is refit inside each fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipe, X, y01, cv=cv, scoring=\"roc_auc\")\n",
    "pd.DataFrame({\"fold_roc_auc\": scores, \"mean\": [scores.mean()]*len(scores)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f21138",
   "metadata": {},
   "source": [
    "\n",
    "### Ordering of preprocessing steps (it is not arbitrary)\n",
    "\n",
    "Many transformations are not commutative. A safe default ordering for numeric data is:\n",
    "\n",
    "1. **Type coercion / parsing** (strings to numbers/dates)\n",
    "2. **Imputation** (replace missing values)\n",
    "3. **Outlier handling** (optional, often with robust scalers)\n",
    "4. **Scaling** (standardization/normalization)\n",
    "5. **Feature generation** (polynomials/interactions, log transforms)\n",
    "6. **Model**\n",
    "\n",
    "Why impute before scaling? Because the scaler needs numeric values everywhere.\n",
    "\n",
    "A median imputer estimates:\n",
    "\n",
    "$$\\tilde x_j = \\mathrm{median}(\\{x_{ij}: i \\in D_{\\text{train}}\\})$$\n",
    "\n",
    "and replaces missing $x_{ij}$ with $\\tilde x_j$ for each feature $j$.\n",
    "\n",
    "If you scale first, missing values propagate and many estimators will fail.\n",
    "\n",
    "---\n",
    "\n",
    "### Schema drift: why column selection must be explicit\n",
    "\n",
    "In notebooks it is common to select columns by dtype:\n",
    "\n",
    "- numeric: `dtype_include=np.number`\n",
    "- categorical: “everything else”\n",
    "\n",
    "That is convenient, but in production you may see schema drift:\n",
    "\n",
    "- a column that should be numeric arrives as strings due to parsing issues,\n",
    "- categories appear that were unseen during training,\n",
    "- a column is renamed or removed.\n",
    "\n",
    "Engineering practices to reduce surprises:\n",
    "\n",
    "- keep explicit column lists for each block,\n",
    "- validate expected columns and dtypes at runtime,\n",
    "- set `handle_unknown=\"ignore\"` for one-hot encoding (already done above),\n",
    "- consider `remainder=\"drop\"` or `remainder=\"passthrough\"` deliberately in `ColumnTransformer`.\n",
    "\n",
    "A pipeline is a good place to centralize these checks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b72b99a",
   "metadata": {},
   "source": [
    "\n",
    "### ColumnTransformer: turning a heterogeneous table into a numeric matrix\n",
    "\n",
    "Categorical one-hot encoding maps a category $c$ into a basis vector $e_j$:\n",
    "\n",
    "$$\\text{onehot}(c) = e_{\\pi(c)}, \\quad e_j \\in \\{0,1\\}^m$$\n",
    "\n",
    "where $\\pi$ is the category-to-index mapping learned during `fit`.\n",
    "\n",
    "For a table with numeric block $X_n \\in \\mathbb{R}^{n \\times p}$ and categorical block $X_c$ with total expanded dimension $q$, the transformed design matrix is:\n",
    "\n",
    "$$Z = [\\, Z_n \\; \\; Z_c \\,] \\in \\mathbb{R}^{n \\times (p+q)}.$$\n",
    "\n",
    "A `ColumnTransformer` builds $Z$ by applying each block pipeline in parallel and concatenating the results.\n",
    "\n",
    "---\n",
    "\n",
    "### Dense vs sparse outputs (practical consequences)\n",
    "\n",
    "One-hot encoding often yields a sparse matrix, because most category indicators are zero. Many estimators in scikit-learn accept sparse matrices natively (linear models, linear SVMs, SGD), while some require dense arrays.\n",
    "\n",
    "Two common patterns:\n",
    "\n",
    "- Keep everything sparse and use models that support sparse input.\n",
    "- Convert to dense only if the resulting matrix is not huge (risk of memory blow-up).\n",
    "\n",
    "For scaling sparse matrices, you cannot subtract the mean (it would densify). That is why you may see:\n",
    "\n",
    "- `StandardScaler(with_mean=False)` for sparse blocks.\n",
    "\n",
    "In our mixed-type regression example, the numeric block is dense and the categorical block is sparse; `ColumnTransformer` handles the concatenation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d4a31",
   "metadata": {},
   "source": [
    "### Mixed-type regression example (numeric + categorical)\n",
    "\n",
    "We now build a column-wise preprocessing pipeline and a regression model on the house-prices dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b57b35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_RMSE</th>\n",
       "      <th>mean_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10647.431875</td>\n",
       "      <td>9984.70284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9271.887576</td>\n",
       "      <td>9984.70284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12038.205273</td>\n",
       "      <td>9984.70284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8299.623666</td>\n",
       "      <td>9984.70284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9666.365810</td>\n",
       "      <td>9984.70284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fold_RMSE   mean_RMSE\n",
       "0  10647.431875  9984.70284\n",
       "1   9271.887576  9984.70284\n",
       "2  12038.205273  9984.70284\n",
       "3   8299.623666  9984.70284\n",
       "4   9666.365810  9984.70284"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset: house prices (regression with mixed types)\n",
    "path_house = \"../../../Datasets/Regression/house-prices.csv\"\n",
    "house = read_csv(path_house)\n",
    "\n",
    "Xh = house.drop(columns=[\"Price\"])\n",
    "yh = house[\"Price\"].astype(float)\n",
    "\n",
    "num_sel = make_column_selector(dtype_include=np.number)\n",
    "cat_sel = make_column_selector(dtype_exclude=np.number)\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, num_sel),\n",
    "    (\"cat\", categorical_pipeline, cat_sel)\n",
    "])\n",
    "\n",
    "reg = Ridge(alpha=1.0, random_state=42)\n",
    "\n",
    "reg_pipe = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", reg)\n",
    "])\n",
    "\n",
    "cv_reg = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmse_scores = -cross_val_score(reg_pipe, Xh, yh, cv=cv_reg, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "pd.DataFrame({\"fold_RMSE\": rmse_scores, \"mean_RMSE\": [rmse_scores.mean()]*len(rmse_scores)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf2f0d",
   "metadata": {},
   "source": [
    "\n",
    "### Tracking feature names after one-hot encoding\n",
    "\n",
    "When you one-hot encode categorical variables, the number of columns increases and the mapping from transformed columns back to original semantics can be lost.\n",
    "\n",
    "For interpretability and debugging, scikit-learn provides `get_feature_names_out`. In a `ColumnTransformer` you can access the fitted encoder and recover expanded names.\n",
    "\n",
    "This is especially important when:\n",
    "\n",
    "- you want to inspect linear model coefficients,\n",
    "- you want to compute permutation importance,\n",
    "- you need audit-friendly explanations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "932a97cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  Home\n",
       "1                  SqFt\n",
       "2              Bedrooms\n",
       "3             Bathrooms\n",
       "4                Offers\n",
       "5              Brick_No\n",
       "6             Brick_Yes\n",
       "7     Neighborhood_East\n",
       "8    Neighborhood_North\n",
       "9     Neighborhood_West\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect feature names after ColumnTransformer (useful for debugging and interpretability)\n",
    "reg_pipe.fit(Xh, yh)\n",
    "pre = reg_pipe.named_steps[\"preprocess\"]\n",
    "\n",
    "num_features = list(pre.transformers_[0][2])\n",
    "cat_features = list(pre.transformers_[1][2])\n",
    "\n",
    "ohe = pre.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "cat_ohe_names = list(ohe.get_feature_names_out(cat_features))\n",
    "\n",
    "all_feature_names = list(num_features) + cat_ohe_names\n",
    "pd.Series(all_feature_names).head(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a2dbe0",
   "metadata": {},
   "source": [
    "\n",
    "### Hyperparameter tuning over pipelines\n",
    "\n",
    "A frequent mistake is to tune a model on preprocessed features that were produced by a transformer fitted on all data. `GridSearchCV` (or `RandomizedSearchCV`) avoids this when the transformer is inside the pipeline.\n",
    "\n",
    "Conceptually, the search loop repeats:\n",
    "\n",
    "1. choose hyperparameters,\n",
    "2. run cross-validation,\n",
    "3. in each fold: fit preprocessing on fold-train, transform fold-train and fold-val, fit model, score on fold-val.\n",
    "\n",
    "This gives a much more realistic estimate than “preprocess once, then search”.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b9ce17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_alpha</th>\n",
       "      <th>best_cv_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>9972.637062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_alpha  best_cv_RMSE\n",
       "0         0.1   9972.637062"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tuning without leakage: GridSearchCV wraps the pipeline\n",
    "param_grid = {\n",
    "    \"model__alpha\": [0.1, 1.0, 10.0, 100.0],\n",
    "    \"preprocess__num__scaler__with_mean\": [True],  # numeric block is dense, OK\n",
    "}\n",
    "\n",
    "search = GridSearchCV(\n",
    "    reg_pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv_reg,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(Xh, yh)\n",
    "pd.DataFrame({\n",
    "    \"best_alpha\": [search.best_params_[\"model__alpha\"]],\n",
    "    \"best_cv_RMSE\": [-search.best_score_],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bed756",
   "metadata": {},
   "source": [
    "\n",
    "### Categorical-heavy tables: encoding and model choice\n",
    "\n",
    "Some datasets are mostly categorical. In such cases:\n",
    "\n",
    "- one-hot encoding is the default baseline,\n",
    "- rare categories can create very wide sparse matrices,\n",
    "- linear models often work surprisingly well on sparse one-hot features.\n",
    "\n",
    "Key engineering knobs:\n",
    "\n",
    "- `handle_unknown=\"ignore\"` to avoid runtime failure on unseen categories,\n",
    "- imputation of missing categories (most frequent or a constant token),\n",
    "- regularization strength in the downstream linear model.\n",
    "\n",
    "We demonstrate this with the `drug200.csv` dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b141c9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_accuracy</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold_accuracy   mean\n",
       "0          0.975  0.955\n",
       "1          1.000  0.955\n",
       "2          0.950  0.955\n",
       "3          0.950  0.955\n",
       "4          0.900  0.955"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset: drug200 (categorical-heavy classification)\n",
    "path_drug = \"../../../Datasets/Classification/drug200.csv\"\n",
    "drug = read_csv(path_drug)\n",
    "\n",
    "Xd = drug.drop(columns=[\"Drug\"])\n",
    "yd = drug[\"Drug\"]\n",
    "\n",
    "num_cols = Xd.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in Xd.columns if c not in num_cols]\n",
    "\n",
    "pre_d = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                      (\"scaler\", StandardScaler())]), num_cols),\n",
    "    (\"cat\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                      (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
    "])\n",
    "\n",
    "clf_pipe = Pipeline([\n",
    "    (\"preprocess\", pre_d),\n",
    "    (\"model\", LogisticRegression(max_iter=5000))\n",
    "])\n",
    "\n",
    "cv_d = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc_scores = cross_val_score(clf_pipe, Xd, yd, cv=cv_d, scoring=\"accuracy\")\n",
    "pd.DataFrame({\"fold_accuracy\": acc_scores, \"mean\": [acc_scores.mean()]*len(acc_scores)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5e770",
   "metadata": {},
   "source": [
    "\n",
    "### Text preprocessing inside a column-wise pipeline (TF–IDF)\n",
    "\n",
    "TF–IDF converts raw text into numeric features. For a term $t$ in document $d$:\n",
    "\n",
    "- term frequency: $\\mathrm{tf}(t,d)$\n",
    "- document frequency: $\\mathrm{df}(t)$ (how many documents contain $t$)\n",
    "\n",
    "A common form is:\n",
    "\n",
    "$$\\mathrm{idf}(t) = \\log\\left(\\frac{N+1}{\\mathrm{df}(t)+1}\\right) + 1$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\mathrm{tfidf}(t,d) = \\mathrm{tf}(t,d) \\cdot \\mathrm{idf}(t).$$\n",
    "\n",
    "Both the vocabulary and the IDF statistics are learned during `fit`, so TF–IDF must be inside the pipeline to avoid leakage.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpreting the complaints example\n",
    "\n",
    "We build a single pipeline that:\n",
    "\n",
    "- imputes missing narratives as empty strings,\n",
    "- vectorizes narratives with TF–IDF (1-grams and 2-grams),\n",
    "- one-hot encodes structured categorical columns,\n",
    "- fits a classifier.\n",
    "\n",
    "This is a standard production pattern: a unified object that can be `fit`, `predict`, validated, and serialized.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df65c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_roc_auc</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.586768</td>\n",
       "      <td>0.58082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585495</td>\n",
       "      <td>0.58082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.589274</td>\n",
       "      <td>0.58082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.578170</td>\n",
       "      <td>0.58082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.564396</td>\n",
       "      <td>0.58082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold_roc_auc     mean\n",
       "0      0.586768  0.58082\n",
       "1      0.585495  0.58082\n",
       "2      0.589274  0.58082\n",
       "3      0.578170  0.58082\n",
       "4      0.564396  0.58082"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset: Consumer complaints (text + structured columns)\n",
    "path_complaints = \"../../../Datasets/Clustering/ConsumerComplaints.csv\"\n",
    "\n",
    "usecols = [\n",
    "    \"Product Name\",\n",
    "    \"Issue\",\n",
    "    \"Company\",\n",
    "    \"State Name\",\n",
    "    \"Consumer Complaint Narrative\",\n",
    "    \"Company Response to Consumer\",\n",
    "    \"Timely Response\",\n",
    "    \"Consumer Disputed\",\n",
    "]\n",
    "\n",
    "complaints = read_csv(path_complaints, usecols=usecols, nrows=8000, low_memory=False)\n",
    "\n",
    "# Define a binary target: whether consumer disputed the outcome\n",
    "complaints = complaints.dropna(subset=[\"Consumer Disputed\"])\n",
    "ytext = (complaints[\"Consumer Disputed\"].astype(str).str.strip().str.lower() == \"yes\").astype(int)\n",
    "\n",
    "Xtext = complaints.drop(columns=[\"Consumer Disputed\"])\n",
    "\n",
    "text_cols = [\"Product Name\", \"Issue\", \"Consumer Complaint Narrative\"]\n",
    "cat_cols = [c for c in Xtext.columns if c not in text_cols]\n",
    "def join_text_columns(X):\n",
    "    \"\"\"\n",
    "    Join multiple text-like columns into a single 1D array of documents.\n",
    "    ColumnTransformer provides 2D arrays/dataframes; vectorizers expect 1D strings.\n",
    "    \"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        df = X\n",
    "    else:\n",
    "        df = pd.DataFrame(np.asarray(X))\n",
    "    return df.fillna(\"\").astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "text_pipeline = Pipeline([\n",
    "    (\"join\", FunctionTransformer(join_text_columns, validate=False)),\n",
    "    (\"tfidf\", TfidfVectorizer(min_df=1, ngram_range=(1, 2)))\n",
    "])\n",
    "\n",
    "pre_text = ColumnTransformer([\n",
    "    (\"text\", text_pipeline, text_cols),\n",
    "    (\"cat\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]), cat_cols)\n",
    "])\n",
    "\n",
    "text_clf = LogisticRegression(max_iter=5000)\n",
    "\n",
    "pipe_text = Pipeline([\n",
    "    (\"preprocess\", pre_text),\n",
    "    (\"model\", text_clf)\n",
    "])\n",
    "\n",
    "cv_text = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "auc_scores = cross_val_score(pipe_text, Xtext, ytext, cv=cv_text, scoring=\"roc_auc\")\n",
    "pd.DataFrame({\"fold_roc_auc\": auc_scores, \"mean\": [auc_scores.mean()]*len(auc_scores)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7892b2",
   "metadata": {},
   "source": [
    "\n",
    "### Custom transformers (when built-ins are not enough)\n",
    "\n",
    "Many preprocessing needs are domain-specific:\n",
    "\n",
    "- parsing timestamps and extracting seasonal patterns,\n",
    "- converting units,\n",
    "- building ratios and interactions,\n",
    "- enforcing monotonic transformations.\n",
    "\n",
    "If you implement a transformer with `fit` and `transform`, it becomes pipeline-compatible.\n",
    "\n",
    "In the earthquake example we:\n",
    "\n",
    "1. Parse `date` + `time` into a timestamp.\n",
    "2. Extract calendar parts.\n",
    "3. Add cyclic encoding for hour-of-day:\n",
    "\n",
    "$$\\mathrm{hour\\_sin} = \\sin\\left(\\frac{2\\pi h}{24}\\right), \\quad\n",
    "\\mathrm{hour\\_cos} = \\cos\\left(\\frac{2\\pi h}{24}\\right).$$\n",
    "\n",
    "Cyclic encoding avoids the discontinuity between 23:00 and 00:00.\n",
    "\n",
    "---\n",
    "\n",
    "### FunctionTransformer for stateless transforms\n",
    "\n",
    "If you want a quick transform without creating a class, use `FunctionTransformer`. For example, a log transform:\n",
    "\n",
    "$$x' = \\log(1+x)$$\n",
    "\n",
    "can be represented as `FunctionTransformer(np.log1p)`.\n",
    "\n",
    "In practice, prefer explicit named steps: readability and debuggability are part of engineering quality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d7a58f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_RMSE</th>\n",
       "      <th>mean_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.741367</td>\n",
       "      <td>0.741874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.745375</td>\n",
       "      <td>0.741874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741413</td>\n",
       "      <td>0.741874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.740502</td>\n",
       "      <td>0.741874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.740714</td>\n",
       "      <td>0.741874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold_RMSE  mean_RMSE\n",
       "0   0.741367   0.741874\n",
       "1   0.745375   0.741874\n",
       "2   0.741413   0.741874\n",
       "3   0.740502   0.741874\n",
       "4   0.740714   0.741874"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom transformer example: extracting cyclic time features from earthquake date/time\n",
    "path_quake = \"../../../Datasets/Regression/earthquake.csv\"\n",
    "quake = read_csv(path_quake)\n",
    "\n",
    "# Predict magnitude from location + depth + time features\n",
    "yq = quake[\"magnitude\"].astype(float)\n",
    "Xq = quake.drop(columns=[\"magnitude\"])\n",
    "\n",
    "class DateTimeFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, date_col=\"date\", time_col=\"time\"):\n",
    "        self.date_col = date_col\n",
    "        self.time_col = time_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        dt = pd.to_datetime(X[self.date_col].astype(str) + \" \" + X[self.time_col].astype(str), errors=\"coerce\")\n",
    "\n",
    "        # Basic components\n",
    "        X[\"year\"] = dt.dt.year.fillna(0).astype(int)\n",
    "        X[\"month\"] = dt.dt.month.fillna(0).astype(int)\n",
    "        X[\"day\"] = dt.dt.day.fillna(0).astype(int)\n",
    "        X[\"hour\"] = dt.dt.hour.fillna(0).astype(int)\n",
    "\n",
    "        # Cyclic encoding for hour-of-day\n",
    "        h = X[\"hour\"].astype(float)\n",
    "        X[\"hour_sin\"] = np.sin(2 * np.pi * h / 24.0)\n",
    "        X[\"hour_cos\"] = np.cos(2 * np.pi * h / 24.0)\n",
    "\n",
    "        return X.drop(columns=[self.date_col, self.time_col])\n",
    "\n",
    "pre_q = Pipeline([\n",
    "    (\"dt\", DateTimeFeatures(date_col=\"date\", time_col=\"time\")),\n",
    "    (\"ct\", ColumnTransformer([\n",
    "        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                          (\"scaler\", StandardScaler())]),\n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ]))\n",
    "])\n",
    "\n",
    "reg_q = Ridge(alpha=1.0, random_state=42)\n",
    "\n",
    "pipe_q = Pipeline([\n",
    "    (\"preprocess\", pre_q),\n",
    "    (\"model\", reg_q)\n",
    "])\n",
    "\n",
    "cv_q = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmse_q = -cross_val_score(pipe_q, Xq, yq, cv=cv_q, scoring=\"neg_root_mean_squared_error\")\n",
    "pd.DataFrame({\"fold_RMSE\": rmse_q, \"mean_RMSE\": [rmse_q.mean()]*len(rmse_q)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e6b77b",
   "metadata": {},
   "source": [
    "\n",
    "### Debugging and validation checklist\n",
    "\n",
    "When pipelines misbehave, the failure mode is often predictable. A disciplined checklist saves time:\n",
    "\n",
    "**1) Verify schema early**\n",
    "- Are column names as expected?\n",
    "- Are numeric columns truly numeric (`dtype`)?\n",
    "- Are missing values represented consistently?\n",
    "\n",
    "**2) Validate the preprocessing output**\n",
    "- Check `transform` shapes: number of rows must match.\n",
    "- Confirm whether the result is sparse or dense.\n",
    "- Spot-check transformed values for a few rows.\n",
    "\n",
    "**3) Watch for implicit leakage**\n",
    "- Any `fit` called on all data before splitting?\n",
    "- Any target-dependent encoding without careful cross-fitting?\n",
    "- Any feature using post-outcome timestamps?\n",
    "\n",
    "**4) Confirm evaluation protocol**\n",
    "- Use pipelines inside `cross_val_score` / `GridSearchCV`.\n",
    "- Use stratification for classification when appropriate.\n",
    "- Fix randomness (`random_state`) for reproducibility.\n",
    "\n",
    "**5) Interpretability hygiene**\n",
    "- Track feature names (`get_feature_names_out`) when one-hot encoding.\n",
    "- Keep an explicit list of input columns per block to avoid silent drift.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "037dc03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0          consumer\n",
       " 1              loan\n",
       " 2          managing\n",
       " 3               the\n",
       " 4                or\n",
       " 5             lease\n",
       " 6     consumer loan\n",
       " 7     loan managing\n",
       " 8      managing the\n",
       " 9          the loan\n",
       " 10          loan or\n",
       " 11         or lease\n",
       " 12             bank\n",
       " 13          account\n",
       " 14          service\n",
       " 15            using\n",
       " 16            debit\n",
       " 17              atm\n",
       " 18             card\n",
       " 19     bank account\n",
       " 20       account or\n",
       " 21       or service\n",
       " 22    service using\n",
       " 23      using debit\n",
       " 24         debit or\n",
       " Name: sample_terms, dtype: object,\n",
       " 419)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debugging tools: check intermediate outputs\n",
    "pipe_text.fit(Xtext, ytext)\n",
    "\n",
    "tfidf = pipe_text.named_steps[\"preprocess\"].named_transformers_[\"text\"].named_steps[\"tfidf\"]\n",
    "vocab_size = len(tfidf.vocabulary_)\n",
    "\n",
    "pd.Series(list(tfidf.vocabulary_.keys())[:25], name=\"sample_terms\"), vocab_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f291eb8a",
   "metadata": {},
   "source": [
    "\n",
    "### Visual intuition: what scaling does to a feature\n",
    "\n",
    "Scaling is not only about “making numbers smaller.” It changes the geometry seen by many models.\n",
    "\n",
    "For example, in logistic regression, the optimization problem often uses an $\\ell_2$ penalty:\n",
    "\n",
    "$$\\min_w \\; \\sum_{i=1}^n \\log\\big(1+\\exp(-y_i w^\\top x_i)\\big) + \\lambda \\|w\\|_2^2.$$\n",
    "\n",
    "If one feature has a much larger scale, it can dominate the gradient and distort regularization unless scaling is applied.\n",
    "\n",
    "The histogram below contrasts a raw feature distribution vs the standardized version.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a508c800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing a single transformation: standardization effect on one feature\n",
    "feature = \"Glucose\"\n",
    "x_raw = df[feature].astype(float).to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_scaled = sc.fit_transform(x_raw.reshape(-1, 1)).ravel()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(x_raw, bins=30)\n",
    "plt.title(\"Raw feature distribution: Glucose\")\n",
    "plt.xlabel(\"Glucose\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(x_scaled, bins=30)\n",
    "plt.title(\"Standardized feature distribution: Glucose\")\n",
    "plt.xlabel(\"Standardized Glucose\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9fb269",
   "metadata": {},
   "source": [
    "\n",
    "### Saving fitted pipelines (one artifact for preprocessing + model)\n",
    "\n",
    "When you call `joblib.dump` on a fitted pipeline, you capture:\n",
    "\n",
    "- fitted preprocessing parameters,\n",
    "- fitted model parameters,\n",
    "- and the exact wiring between them.\n",
    "\n",
    "This is the simplest route to consistent inference later.\n",
    "\n",
    "In a GitHub tutorial repository, it is usually better to **show** serialization as a technique, but avoid committing large binary artifacts to the repository unless you have a clear MLOps plan (e.g., Git LFS, model registry).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aee47d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chapter2_Lesson13_diabetes_pipeline.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialization: save a fully-fitted pipeline (preprocessing + model)\n",
    "import joblib\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "joblib.dump(pipe, \"Chapter2_Lesson13_diabetes_pipeline.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeeb26b",
   "metadata": {},
   "source": [
    "\n",
    "### Training/serving consistency (why a single serialized pipeline matters)\n",
    "\n",
    "A frequent failure mode in real systems is *training-serving skew*:\n",
    "\n",
    "- Training code applies preprocessing version A.\n",
    "- Serving code applies preprocessing version B (or forgets a step).\n",
    "- Model performance in production collapses.\n",
    "\n",
    "If you serialize a single object that includes both preprocessing and model, then:\n",
    "\n",
    "- training and inference use the same transformations,\n",
    "- versioning is simpler (one artifact),\n",
    "- audits become easier (“what exactly produced this prediction?”).\n",
    "\n",
    "This is one reason why even in purely academic work, you should treat pipelines as first-class artifacts.\n",
    "\n",
    "---\n",
    "\n",
    "### Caching expensive transforms (optional)\n",
    "\n",
    "Some transforms are expensive (text vectorization, large one-hot expansions). `Pipeline` supports caching via `memory=...` (joblib). For long experiments, caching can reduce runtime significantly. Use it only when inputs are stable and you understand the trade-offs.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "- Put all learned preprocessing steps inside a pipeline.\n",
    "- Use `ColumnTransformer` for mixed-type tables.\n",
    "- Validate with cross-validation on the pipeline object.\n",
    "- Tune hyperparameters with `GridSearchCV` around the pipeline.\n",
    "- Serialize the fitted pipeline for reproducible inference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce5155",
   "metadata": {},
   "source": [
    "\n",
    "### Exercises (recommended)\n",
    "\n",
    "1. **Leakage stress test (diabetes)**\n",
    "   - Add an imputer step and intentionally fit it outside the pipeline.\n",
    "   - Measure how cross-validation ROC–AUC changes.\n",
    "   - Explain why the difference occurs.\n",
    "\n",
    "2. **Robust mixed-type regression (house prices)**\n",
    "   - Replace `Ridge` with a tree-based regressor (e.g., `RandomForestRegressor`).\n",
    "   - Observe which preprocessing steps become less critical and why.\n",
    "   - Compare RMSE and training time.\n",
    "\n",
    "3. **High-cardinality categorical features**\n",
    "   - In a dataset with many categories, compare:\n",
    "     - one-hot encoding,\n",
    "     - hashing (via `FeatureHasher` or similar),\n",
    "     - grouping rare categories (if supported).\n",
    "   - Evaluate performance and memory footprint.\n",
    "\n",
    "4. **Pipeline portability**\n",
    "   - Fit a pipeline, serialize it with `joblib`, reload it, and run `predict` on a held-out sample.\n",
    "   - Verify that reloaded predictions match exactly.\n",
    "\n",
    "5. **Create your own transformer**\n",
    "   - Implement a transformer that adds:\n",
    "     - a ratio feature (e.g., $\\frac{\\text{Insulin}}{\\text{Glucose}+\\epsilon}$),\n",
    "     - and a clipped version of BMI.\n",
    "   - Insert it into a pipeline and validate with cross-validation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
