{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f31a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap');\n",
       "@import url('https://cdnjs.cloudflare.com/ajax/libs/shabnam-font/5.0.1/font-face.css');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Amiri:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Mirza:wght@400;700&display=swap');\n",
       "\n",
       "\n",
       "\n",
       "/* Text areas (Classic Notebook + JupyterLab) */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "div.rendered_html, .output_subarea {\n",
       "  font-family: \"Vazirmatn\", \"Shabnam\", \"Mirza\", \"Amiri\", Tahoma, \"Segoe UI\", sans-serif !important;\n",
       "}\n",
       "\n",
       "/* RTL for rendered markdown/html content */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "h1, h2, h3, h4, h5, h6, p, strong, label, ol, ul, li {\n",
       "  direction: rtl !important;\n",
       "  text-align: right !important;\n",
       "  line-height: 1.9;\n",
       "  font-family: \"Vazirmatn\", \"Shabnam\", \"Mirza\", \"Amiri\", Tahoma, \"Segoe UI\", sans-serif !important;\n",
       "}\n",
       "\n",
       "h1 { font-size: 2rem; color: #070F2B; font-weight: 900}\n",
       "h2 { font-size: 1.8rem; color: #070F2B; font-weight: 800}\n",
       "h3 { font-size: 1.6rem; color: #070F2B; font-weight: 700}\n",
       "h4 { font-size: 1.4rem; color: #1E3E62; font-weight: 600}\n",
       "h5 { font-size: 1.2rem; color: #1E3E62}\n",
       "h6 { font-size: 1rem; color: #1E3E62}\n",
       "p { font-size: 1.1rem; ; font-weight: 400}\n",
       "ol, ul, li, th, td  { font-size: 1rem; }\n",
       "\n",
       "/* Keep code + outputs LTR and monospace */\n",
       ".CodeMirror, .CodeMirror *,\n",
       "pre, code,\n",
       ".jp-CodeCell .jp-InputArea, .jp-CodeCell .jp-InputArea *,\n",
       ".jp-OutputArea, .jp-OutputArea * {\n",
       "  direction: ltr !important;\n",
       "  text-align: left !important;\n",
       "  font-size: 1rem !important;\n",
       "  font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "css = Path(\"../../../css/rtl.css\").read_text(encoding=\"utf-8\")\n",
    "display(HTML(f\"<style>{css}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcfb0e7",
   "metadata": {},
   "source": [
    "# فصل ۱ — مقدمه‌ای بر یادگیری ماشین\n",
    "# درس ۱۰: پارادایم‌های یادگیری و طبقه‌بندی وظایف (رگرسیون، دسته‌بندی، رتبه‌بندی، پیش‌بینی)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3493618b",
   "metadata": {},
   "source": [
    "# فصل ۱ — مقدمه‌ای بر یادگیری ماشین\n",
    "درس ۱۰: پارادایم‌های یادگیری و طبقه‌بندی وظایف (رگرسیون، دسته‌بندی، رتبه‌بندی، پیش‌بینی)\n",
    "\n",
    "\n",
    "این نوت‌بوک بخشی از یک دوره‌ی دوزبانه و مبتنی بر ژوپیتر است.\n",
    "\n",
    "### چرا این درس مهم است؟\n",
    "\n",
    "در عمل، خیلی‌ها از الگوریتم شروع می‌کنند («XGBoost خوب است یا نه؟») قبل از اینکه **نوع وظیفه** مشخص شود.\n",
    "این ترتیب معمولاً غلط است. تعریف درست وظیفه تعیین می‌کند:\n",
    "\n",
    "- هدف ($y$) چیست،\n",
    "- چه فرض‌هایی درباره‌ی تولید داده منطقی است (IID یا وابسته به زمان)،\n",
    "- چه معیارهایی گزارش می‌شود،\n",
    "- و چه پروتکل اعتبارسنجی معتبر است.\n",
    "\n",
    "### دامنه‌ی درس\n",
    "\n",
    "روی خانواده‌های بسیار رایج در یادگیری ماشین کلاسیک تمرکز داریم:\n",
    "\n",
    "1. رگرسیون\n",
    "2. دسته‌بندی (دودویی و چندکلاسه)\n",
    "3. رتبه‌بندی / یادگیری برای رتبه‌بندی\n",
    "4. پیش‌بینی (یادگیری نظارت‌شده با وابستگی زمانی)\n",
    "\n",
    "همچنین ارتباط آن‌ها را با پارادایم‌های یادگیری (نظارت‌شده/بدون‌نظارت/نیمه‌نظارت/تقویتی) بیان می‌کنیم،\n",
    "اما بخش عملی عمدتاً نظارت‌شده است.\n",
    "\n",
    "---\n",
    "\n",
    "## اهداف یادگیری\n",
    "\n",
    "در پایان درس باید بتوانید:\n",
    "\n",
    "1. یک سؤال کاربردی را به نوع وظیفه (رگرسیون/دسته‌بندی/رتبه‌بندی/پیش‌بینی) نگاشت کنید.\n",
    "2. برای هر وظیفه، **زیان‌ها** و **معیارهای** مناسب را انتخاب کنید.\n",
    "3. تفاوت ارزیابی IID با ارزیابی سری‌زمانی را تشخیص دهید.\n",
    "4. baseline حداقلی و صحیح در scikit-learn بسازید و نتایج را تفسیر کنید.\n",
    "5. خطاهای رایج (عدم تطابق معیار، leakage، split نامعتبر) را توضیح دهید.\n",
    "\n",
    "---\n",
    "\n",
    "## مدل ذهنی: «وظیفه = نوع هدف + پروتکل ارزیابی + هزینه‌ی تصمیم»\n",
    "\n",
    "یک تعریف کاربردی از وظیفه:\n",
    "\n",
    "$$\n",
    "\\text{Task} = \\big(\\text{target type}, \\; \\text{valid evaluation}, \\; \\text{decision cost}\\big)\n",
    "$$\n",
    "\n",
    "اگر فقط نوع هدف را مشخص کنید و ارزیابی را نادیده بگیرید، احتمالاً مدلی می‌سازید که در تولید شکست می‌خورد.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79a27e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Versions:\n",
      "  pandas: 2.2.3\n",
      "  numpy: 2.1.2\n",
      "  sklearn: 1.5.2\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, f1_score, classification_report,\n",
    "    confusion_matrix, roc_auc_score\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def read_csv_or_sample(path, sample_csv_text, **kwargs):\n",
    "    \"\"\"Read a CSV from repo path; fall back to embedded sample rows if missing.\"\"\"\n",
    "    p = Path(path)\n",
    "    if p.exists():\n",
    "        return pd.read_csv(p, **kwargs)\n",
    "    return pd.read_csv(io.StringIO(sample_csv_text), **kwargs)\n",
    "\n",
    "def synthesize_from_sample(df, n=500, noise=0.05, seed=42):\n",
    "    \"\"\"Bootstrap + jitter to make a larger dataset for demonstrative modeling.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df_big = df.sample(n=n, replace=True, random_state=seed).reset_index(drop=True)\n",
    "    for col in df_big.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df_big[col]):\n",
    "            std = df_big[col].std(ddof=0)\n",
    "            if np.isfinite(std) and std > 0:\n",
    "                df_big[col] = df_big[col] + rng.normal(0, noise*std, size=len(df_big))\n",
    "    return df_big\n",
    "\n",
    "def synthesize_earthquake_timeseries(df_small, days=220, avg_events_per_day=4, seed=19):\n",
    "    \"\"\"Create a multi-day series when only sample rows are available.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df_small = df_small.copy()\n",
    "    df_small[\"timestamp\"] = pd.to_datetime(df_small[\"date\"].astype(str) + \" \" + df_small[\"time\"].astype(str), errors=\"coerce\")\n",
    "    df_small = df_small.dropna(subset=[\"timestamp\"])\n",
    "\n",
    "    start = df_small[\"timestamp\"].min().normalize()\n",
    "    rows = []\n",
    "    for d in range(days):\n",
    "        day = start + pd.Timedelta(days=d)\n",
    "        m = rng.poisson(avg_events_per_day) + 1\n",
    "        sample = df_small.sample(n=m, replace=True, random_state=int(seed + d)).reset_index(drop=True)\n",
    "        secs = rng.integers(0, 24*3600, size=m)\n",
    "        sample[\"timestamp\"] = day + pd.to_timedelta(secs, unit=\"s\")\n",
    "\n",
    "        for col in [\"latitude\", \"longitude\", \"depth\", \"magnitude\"]:\n",
    "            if col in sample.columns:\n",
    "                sample[col] = pd.to_numeric(sample[col], errors=\"coerce\")\n",
    "                std = np.nanstd(sample[col])\n",
    "                if np.isfinite(std) and std > 0:\n",
    "                    sample[col] = sample[col] + rng.normal(0, 0.10*std, size=m)\n",
    "\n",
    "        rows.append(sample)\n",
    "\n",
    "    out = pd.concat(rows, ignore_index=True)\n",
    "    out[\"date\"] = out[\"timestamp\"].dt.date.astype(str)\n",
    "    out[\"time\"] = out[\"timestamp\"].dt.time.astype(str)\n",
    "    return out.drop(columns=[\"timestamp\"])\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Compute RMSE without using deprecated sklearn squared=... parameter.\"\"\"\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "print(\"Setup complete. Versions:\")\n",
    "import sklearn\n",
    "print(\"  pandas:\", pd.__version__)\n",
    "print(\"  numpy:\", np.__version__)\n",
    "print(\"  sklearn:\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e338cccc",
   "metadata": {},
   "source": [
    "## ۱. پارادایم‌های یادگیری: نظارت از کجا می‌آید؟\n",
    "\n",
    "**پارادایم یادگیری** مشخص می‌کند مدل چگونه اطلاعات لازم برای تعریف «رفتار خوب» را به‌دست می‌آورد.\n",
    "\n",
    "### ۱.۱ یادگیری نظارت‌شده\n",
    "\n",
    "جفت‌های برچسب‌دار $(x_i, y_i)$ را مشاهده می‌کنید و نگاشت $f: x \\mapsto y$ را می‌آموزید.\n",
    "\n",
    "هدف رایج:\n",
    "\n",
    "$$\n",
    "\\hat{f} = \\arg\\min_{f \\in \\mathcal{F}} \\; \\frac{1}{n} \\sum_{i=1}^n \\ell\\big(y_i, f(x_i)\\big) + \\lambda \\Omega(f)\n",
    "$$\n",
    "\n",
    "- $\\ell$ تابع زیان است (چقدر پیش‌بینی اشتباه است)\n",
    "- $\\Omega$ منظم‌ساز است (کنترل ظرفیت)\n",
    "- $\\lambda$ شدت منظم‌سازی را تنظیم می‌کند\n",
    "\n",
    "### ۱.۲ یادگیری بدون‌نظارت\n",
    "\n",
    "بدون هدف صریح، فقط $x_i$ را می‌بینید و ساختار را یاد می‌گیرید: خوشه‌ها، چگالی‌ها، embeddingها.\n",
    "در عمل برای نمایش‌سازی، سگمنتیشن و تشخیص ناهنجاری بسیار استفاده می‌شود.\n",
    "\n",
    "### ۱.۳ نیمه‌نظارت‌شده و نظارت ضعیف\n",
    "\n",
    "یک مجموعه‌ی کوچک برچسب‌دار و یک مجموعه‌ی بزرگ بدون برچسب دارید.\n",
    "ممکن است از pseudo-label و ساختار گراف برای انتشار برچسب استفاده کنید.\n",
    "در «نظارت ضعیف»، برچسب‌های نویزی از قوانین اکتشافی ساخته می‌شود.\n",
    "\n",
    "### ۱.۴ یادگیری تقویتی (RL) و باندیت‌ها\n",
    "\n",
    "با محیط تعامل می‌کنید، عمل انتخاب می‌کنید و پاداش می‌گیرید.\n",
    "تمرکز این درس نیست، اما برخی مسائل رتبه‌بندی/پیشنهاددهی را می‌توان به شکل contextual bandit دید.\n",
    "\n",
    "---\n",
    "\n",
    "## ۲. طبقه‌بندی وظایف: نوع هدف و پروتکل ارزیابی\n",
    "\n",
    "یک طبقه‌بندی فشرده برای وظایف رایج نظارت‌شده:\n",
    "\n",
    "| نوع وظیفه | هدف $y$ | خروجی پیش‌بینی | معیار رایج |\n",
    "|---|---|---|---|\n",
    "| رگرسیون | $\\mathbb{R}$ | مقدار | MAE، RMSE، $R^2$ |\n",
    "| دسته‌بندی دودویی | $\\{0,1\\}$ | برچسب/احتمال | F1، ROC AUC، PR AUC |\n",
    "| دسته‌بندی چندکلاسه | $\\{1,\\dots,K\\}$ | احتمال کلاس‌ها | accuracy، macro-F1 |\n",
    "| رتبه‌بندی | ارتباط/ترجیح زوجی | ترتیب | NDCG@k، MAP، Recall@k |\n",
    "| پیش‌بینی | $y_{t+h}$ | مقدار آینده | MAE/RMSE بر اساس افق |\n",
    "\n",
    "نکته: **پیش‌بینی** معمولاً نظارت‌شده است اما **IID نیست**.\n",
    "پس معنای split آموزش/آزمون متفاوت می‌شود.\n",
    "\n",
    "---\n",
    "\n",
    "## ۲.۱ هزینه، آستانه و قانون تصمیم\n",
    "\n",
    "حتی برای یک نوع وظیفه‌ی ثابت، هزینه‌ها می‌توانند قانون تصمیم را تغییر دهند.\n",
    "\n",
    "برای دسته‌بندی دودویی:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\mathbf{1}\\big[\\; P(y=1\\mid x) \\ge \\tau \\;\\big]\n",
    "$$\n",
    "\n",
    "آستانه‌ی $\\tau$ باید بر اساس هزینه‌ی خطای نوع اول/دوم تعیین شود، نه صرفاً $0.5$.\n",
    "\n",
    "برای رتبه‌بندی، معمولاً ابتدای لیست مهم است چون ظرفیت محدود دارید:\n",
    "\n",
    "- فقط به ۱٪ بالای leadها ایمیل می‌زنید\n",
    "- فقط ۱۰ محصول اول را نمایش می‌دهید\n",
    "- فقط ۵۰ تراکنش اول را بررسی می‌کنید\n",
    "\n",
    "پس ارزیابی باید با معیارهای top-$k$ انجام شود.\n",
    "\n",
    "---\n",
    "\n",
    "## ۲.۲ چک‌لیست کوچک برای فرموله‌کردن وظیفه\n",
    "\n",
    "قبل از آموزش هر چیزی، این‌ها را بنویسید:\n",
    "\n",
    "1. هدف $y$ چیست (با واحد/تعریف دقیق)؟\n",
    "2. بعد از پیش‌بینی چه اقدام/تصمیمی انجام می‌شود؟\n",
    "3. هزینه‌ی خطاها چیست؟\n",
    "4. قانون split داده باید چه باشد تا شبیه تولید شود؟\n",
    "\n",
    "حالا این ایده‌ها را با مثال‌های کدنویسی ملموس می‌کنیم.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebba741",
   "metadata": {},
   "source": [
    "## ۳. فرموله‌کردن کوچک: رگرسیون در برابر دسته‌بندی و رتبه‌بندی\n",
    "\n",
    "این مثال کوچک یک ویژگی $x$ و یک خروجی پیوسته را در نظر می‌گیرد.\n",
    "\n",
    "- در **رگرسیون**، $y$ را مستقیم پیش‌بینی می‌کنید.\n",
    "- در **دسته‌بندی**، پیش‌بینی می‌کنید آیا $y$ از یک آستانه بیشتر است یا نه.\n",
    "- در **رتبه‌بندی**، از امتیاز پیش‌بینی برای مرتب‌سازی نمونه‌ها بر اساس ریسک استفاده می‌کنید.\n",
    "\n",
    "با اینکه داده‌ی خام یکسان است، پارامترها و ارزیابی متفاوت خواهد بود.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db490d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y_cont</th>\n",
       "      <th>y_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125730</td>\n",
       "      <td>-0.911055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.132105</td>\n",
       "      <td>-0.373606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.640423</td>\n",
       "      <td>0.657890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104900</td>\n",
       "      <td>-0.156333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.535669</td>\n",
       "      <td>-1.343468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.361595</td>\n",
       "      <td>0.565040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.304000</td>\n",
       "      <td>2.813815</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.947081</td>\n",
       "      <td>2.415419</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.703735</td>\n",
       "      <td>-1.471738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.265421</td>\n",
       "      <td>-1.847611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.623274</td>\n",
       "      <td>-1.579146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.041326</td>\n",
       "      <td>0.258407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x    y_cont  y_bin\n",
       "0   0.125730 -0.911055      0\n",
       "1  -0.132105 -0.373606      0\n",
       "2   0.640423  0.657890      1\n",
       "3   0.104900 -0.156333      1\n",
       "4  -0.535669 -1.343468      0\n",
       "5   0.361595  0.565040      1\n",
       "6   1.304000  2.813815      1\n",
       "7   0.947081  2.415419      1\n",
       "8  -0.703735 -1.471738      0\n",
       "9  -1.265421 -1.847611      0\n",
       "10 -0.623274 -1.579146      0\n",
       "11  0.041326  0.258407      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression coefficients: 1.9512520123535053 intercept: -0.12409791654978095\n",
      "Classification coefficient: 1.4488474737404589 intercept: -0.027935787302401996\n",
      "\n",
      "First 5 predictions:\n",
      "  x= 0.126  y_cont=-0.911  y_hat_reg= 0.121  p(y=1)= 0.538\n",
      "  x=-0.132  y_cont=-0.374  y_hat_reg=-0.382  p(y=1)= 0.445\n",
      "  x= 0.640  y_cont= 0.658  y_hat_reg= 1.126  p(y=1)= 0.711\n",
      "  x= 0.105  y_cont=-0.156  y_hat_reg= 0.081  p(y=1)= 0.531\n",
      "  x=-0.536  y_cont=-1.343  y_hat_reg=-1.169  p(y=1)= 0.309\n"
     ]
    }
   ],
   "source": [
    "# A tiny illustration: the same data can be framed as regression or classification.\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "n = 12\n",
    "x = rng.normal(size=n)\n",
    "y_cont = 2*x + rng.normal(scale=0.5, size=n)          # continuous target\n",
    "y_bin = (y_cont > np.median(y_cont)).astype(int)      # binarized target\n",
    "\n",
    "toy = pd.DataFrame({\"x\": x, \"y_cont\": y_cont, \"y_bin\": y_bin})\n",
    "display(toy)\n",
    "\n",
    "# Regression framing\n",
    "reg = LinearRegression().fit(toy[[\"x\"]], toy[\"y_cont\"])\n",
    "y_hat_reg = reg.predict(toy[[\"x\"]])\n",
    "\n",
    "# Classification framing\n",
    "clf = LogisticRegression().fit(toy[[\"x\"]], toy[\"y_bin\"])\n",
    "p_hat = clf.predict_proba(toy[[\"x\"]])[:, 1]\n",
    "\n",
    "print(\"Regression coefficients:\", reg.coef_[0], \"intercept:\", reg.intercept_)\n",
    "print(\"Classification coefficient:\", clf.coef_[0,0], \"intercept:\", clf.intercept_[0])\n",
    "print(\"\\nFirst 5 predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"  x={x[i]: .3f}  y_cont={y_cont[i]: .3f}  y_hat_reg={y_hat_reg[i]: .3f}  p(y=1)={p_hat[i]: .3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8604c6b4",
   "metadata": {},
   "source": [
    "## ۴. مثال رگرسیون: پیش‌بینی قیمت خانه\n",
    "\n",
    "### ۴.۱ صورت مسئله\n",
    "\n",
    "با داشتن ویژگی‌های یک خانه، قیمت فروش را پیش‌بینی کنید:\n",
    "\n",
    "- ورودی‌ها $x$: متراژ، تعداد اتاق‌ها، محله و ...\n",
    "- هدف $y$: قیمت (واحد پول)\n",
    "\n",
    "این یک وظیفه‌ی رگرسیون است چون $y \\in \\mathbb{R}$.\n",
    "\n",
    "### ۴.۲ رویکرد baseline\n",
    "\n",
    "می‌سازیم:\n",
    "\n",
    "1. پایپ‌لاین پیش‌پردازش:\n",
    "   - عددی: جایگذاری میانه + استانداردسازی\n",
    "   - دسته‌ای: جایگذاری پرتکرار + one-hot encoding\n",
    "2. مدل رگرسیون خطی\n",
    "\n",
    "### ۴.۳ معیارها\n",
    "\n",
    "MAE، RMSE و $R^2$ را گزارش می‌کنیم:\n",
    "\n",
    "- MAE در واحد هدف قابل تفسیر است.\n",
    "- RMSE خطاهای بزرگ را بیشتر جریمه می‌کند.\n",
    "- $R^2$ برای «واریانس توضیح‌داده‌شده» مفید است اما بین دیتاست‌ها قابل مقایسه‌ی مستقیم نیست.\n",
    "\n",
    "baseline را پیاده‌سازی می‌کنیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd18c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw rows (head):\n",
      " Home  Price  SqFt  Bedrooms  Bathrooms  Offers Brick Neighborhood\n",
      "    1 114300  1790         2          2       2    No         East\n",
      "    2 114200  2030         4          2       3    No         East\n",
      "    3 114800  1740         3          2       1    No         East\n",
      "    4  94700  1980         3          2       3    No         East\n",
      "    5 119800  2130         3          3       3    No         East\n",
      "MAE:  7,283.09\n",
      "RMSE: 9,529.77\n",
      "R^2:  0.889\n"
     ]
    }
   ],
   "source": [
    "# Regression dataset: house-prices\n",
    "HOUSE_PATH = \"../../../Datasets/Regression/house-prices.csv\"\n",
    "sample_house = \"Home,Price,SqFt,Bedrooms,Bathrooms,Offers,Brick,Neighborhood\\n1,114300,1790,2,2,2,No,East\\n2,114200,2030,4,2,3,No,East\\n3,114800,1740,3,2,1,No,East\\n4,94700,1980,3,2,3,No,East\\n5,119800,2130,3,3,3,No,East\\n\"\n",
    "\n",
    "house_df = read_csv_or_sample(HOUSE_PATH, sample_house)\n",
    "print(\"Raw rows (head):\")\n",
    "print(house_df.head().to_string(index=False))\n",
    "\n",
    "df = synthesize_from_sample(house_df, n=500, noise=0.08, seed=13)\n",
    "\n",
    "y = df[\"Price\"].astype(float)\n",
    "X = df.drop(columns=[\"Price\"]).copy()\n",
    "\n",
    "num_cols = [\"SqFt\", \"Bedrooms\", \"Bathrooms\", \"Offers\"]\n",
    "cat_cols = [\"Brick\", \"Neighborhood\"]\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                      (\"sc\", StandardScaler())]), num_cols),\n",
    "    (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                      (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
    "])\n",
    "\n",
    "model = Pipeline([(\"pre\", pre), (\"linreg\", LinearRegression())])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "rmse_val = rmse(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "\n",
    "print(f\"MAE:  {mae:,.2f}\")\n",
    "print(f\"RMSE: {rmse_val:,.2f}\")\n",
    "print(f\"R^2:  {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06996a0d",
   "metadata": {},
   "source": [
    "## ۵. مثال دسته‌بندی دودویی: پیش‌بینی دیابت\n",
    "\n",
    "### ۵.۱ صورت مسئله\n",
    "\n",
    "با داشتن اندازه‌گیری‌های بیمار، پیش‌بینی کنید بیمار دیابتی است یا نه.\n",
    "\n",
    "- ورودی‌ها $x$: گلوکز، BMI، سن و ...\n",
    "- هدف $y \\in \\{0,1\\}$: دیابتی / غیردیابتی\n",
    "\n",
    "### ۵.۲ اهمیت پیش‌بینی احتمالی\n",
    "\n",
    "بسیاری از تصمیم‌های پایین‌دستی به «ریسک» نیاز دارند نه فقط برچسب قطعی.\n",
    "رگرسیون لجستیک احتمال $P(y=1\\mid x)$ را برآورد می‌کند.\n",
    "\n",
    "### ۵.۳ معیارها\n",
    "\n",
    "محاسبه می‌کنیم:\n",
    "\n",
    "- Accuracy\n",
    "- F1\n",
    "- ROC AUC\n",
    "- ماتریس درهم‌ریختگی (Confusion Matrix)\n",
    "\n",
    "در داده‌های نامتوازن، accuracy به‌تنهایی گمراه‌کننده است؛ F1 و AUC سیگنال بیشتری می‌دهند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "266bd19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw rows (head):\n",
      " Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age classification\n",
      "           6      148             72             35        0 33.6                     0.627   50       Diabetic\n",
      "           1       85             66             29        0 26.6                     0.351   31   Non-Diabetic\n",
      "           8      183             64              0        0 23.3                     0.672   32       Diabetic\n",
      "           1       89             66             23       94 28.1                     0.167   21   Non-Diabetic\n",
      "           0      137             40             35      168 43.1                     2.288   33       Diabetic\n",
      "Accuracy: 0.793\n",
      "F1:       0.667\n",
      "ROC AUC:  0.828\n",
      "Confusion matrix [[TN, FP], [FN, TP]]:\n",
      "[[88  8]\n",
      " [23 31]]\n"
     ]
    }
   ],
   "source": [
    "# Classification dataset: diabetes\n",
    "DIAB_PATH = \"../../../Datasets/Classification/diabetes.csv\"\n",
    "sample_diabetes = \"Pregnancies,Glucose,BloodPressure,SkinThickness,Insulin,BMI,DiabetesPedigreeFunction,Age,classification\\n6,148,72,35,0,33.6,0.627,50,Diabetic\\n1,85,66,29,0,26.6,0.351,31,Non-Diabetic\\n8,183,64,0,0,23.3,0.672,32,Diabetic\\n1,89,66,23,94,28.1,0.167,21,Non-Diabetic\\n0,137,40,35,168,43.1,2.288,33,Diabetic\\n\"\n",
    "\n",
    "diab_df = read_csv_or_sample(DIAB_PATH, sample_diabetes)\n",
    "print(\"Raw rows (head):\")\n",
    "print(diab_df.head().to_string(index=False))\n",
    "\n",
    "df = synthesize_from_sample(diab_df, n=600, noise=0.10, seed=7)\n",
    "\n",
    "y = (df[\"classification\"].astype(str) == \"Diabetic\").astype(int)\n",
    "X = df.drop(columns=[\"classification\"])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"sc\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=1000, random_state=0)),\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, stratify=y)\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "proba = pipe.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "auc = roc_auc_score(y_test, proba)\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"F1:       {f1:.3f}\")\n",
    "print(f\"ROC AUC:  {auc:.3f}\")\n",
    "print(\"Confusion matrix [[TN, FP], [FN, TP]]:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0fa854",
   "metadata": {},
   "source": [
    "## ۶. دسته‌بندی چندکلاسه: Iris\n",
    "\n",
    "در دسته‌بندی چندکلاسه، بین $K>2$ کلاس پیش‌بینی می‌کنید.\n",
    "حتی اگر accuracy بالا باشد، بهتر است عملکرد هر کلاس را در گزارش دسته‌بندی بررسی کنید.\n",
    "\n",
    "از دیتاست iris برای نمایش استفاده می‌کنیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f04e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw rows (head):\n",
      " sepal_length  sepal_width  petal_length  petal_width classification\n",
      "          5.4          3.7           1.5          0.2    Iris-setosa\n",
      "          4.8          3.4           1.6          0.2    Iris-setosa\n",
      "          4.8          3.0           1.4          0.1    Iris-setosa\n",
      "          4.3          3.0           1.1          0.1    Iris-setosa\n",
      "          5.8          4.0           1.2          0.2    Iris-setosa\n",
      "Accuracy (multi-class): 0.948\n",
      "\n",
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        42\n",
      "Iris-versicolor       0.97      0.86      0.92        44\n",
      " Iris-virginica       0.89      0.98      0.93        49\n",
      "\n",
      "       accuracy                           0.95       135\n",
      "      macro avg       0.95      0.95      0.95       135\n",
      "   weighted avg       0.95      0.95      0.95       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multi-class dataset: iris\n",
    "IRIS_PATH = \"../../../Datasets/Classification/iris.csv\"\n",
    "sample_iris = \"sepal_length,sepal_width,petal_length,petal_width,classification\\n5.1,3.5,1.4,0.2,Iris-setosa\\n4.9,3.0,1.4,0.2,Iris-setosa\\n5.0,3.6,1.4,0.2,Iris-setosa\\n7.0,3.2,4.7,1.4,Iris-versicolor\\n6.4,3.2,4.5,1.5,Iris-versicolor\\n6.9,3.1,4.9,1.5,Iris-versicolor\\n6.3,3.3,6.0,2.5,Iris-virginica\\n5.8,2.7,5.1,1.9,Iris-virginica\\n7.1,3.0,5.9,2.1,Iris-virginica\\n\"\n",
    "\n",
    "iris_df = read_csv_or_sample(IRIS_PATH, sample_iris)\n",
    "print(\"Raw rows (head):\")\n",
    "print(iris_df.head().to_string(index=False))\n",
    "\n",
    "df = synthesize_from_sample(iris_df, n=450, noise=0.08, seed=11)\n",
    "\n",
    "y = df[\"classification\"].astype(str)\n",
    "X = df.drop(columns=[\"classification\"])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"sc\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=1000, random_state=0)),\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0, stratify=y)\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f\"Accuracy (multi-class): {acc:.3f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8b329",
   "metadata": {},
   "source": [
    "## ۷. baseline رتبه‌بندی / یادگیری برای رتبه‌بندی\n",
    "\n",
    "### ۷.۱ چه چیزی رتبه‌بندی را متفاوت می‌کند؟\n",
    "\n",
    "در دسته‌بندی، هر نمونه مستقل است و یک برچسب دارد.\n",
    "\n",
    "در رتبه‌بندی، معمولاً یک «پرسش/کانتکست» (کاربر، سشن، جستجو) و مجموعه‌ای از آیتم‌های کاندید دارید.\n",
    "باید آیتم‌ها را طوری مرتب کنید که سودمندی در ابتدای لیست بیشینه شود.\n",
    "\n",
    "### ۷.۲ pointwise در برابر pairwise و listwise\n",
    "\n",
    "- **Pointwise:** برای هر آیتم یک امتیاز ارتباط پیش‌بینی کن و سپس sort کن\n",
    "- **Pairwise:** ترجیح زوجی یاد بگیر (A باید بالاتر از B باشد)\n",
    "- **Listwise:** یک هدف سطح-لیست را مستقیم بهینه کن\n",
    "\n",
    "ما یک baseline pointwise پیاده‌سازی می‌کنیم چون ساده است و به‌عنوان قدم اول رایج است.\n",
    "\n",
    "### ۷.۳ ارزیابی با NDCG\n",
    "\n",
    "NDCG به ابتدای لیست وزن بیشتری می‌دهد:\n",
    "\n",
    "$$\n",
    "\\mathrm{DCG}@k = \\sum_{i=1}^{k} \\frac{2^{rel_i}-1}{\\log_2(i+1)}, \\quad\n",
    "\\mathrm{NDCG}@k = \\frac{\\mathrm{DCG}@k}{\\mathrm{IDCG}@k}\n",
    "$$\n",
    "\n",
    "یک برچسب ارتباط مصنوعی از ویژگی‌ها می‌سازیم و NDCG@10 و NDCG@50 را محاسبه می‌کنیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d898c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw rows (head):\n",
      "   id                                             name  host_id host_name  neighbourhood_group          neighbourhood  latitude  longitude       room_type  price  minimum_nights  number_of_reviews last_review  reviews_per_month  calculated_host_listings_count  availability_365  number_of_reviews_ltm  license\n",
      "13913              Holiday London DB Room Let-on going    54730     Alina                  NaN              Islington  51.56861   -0.11270    Private room   57.0               1                 51  2025-02-09               0.29                               3               344                     10      NaN\n",
      "15400              Bright Chelsea  Apartment. Chelsea!    60302  Philippa                  NaN Kensington and Chelsea  51.48780   -0.16813 Entire home/apt    NaN               4                 96  2024-04-28               0.52                               1                11                      2      NaN\n",
      "17402 Very Central Modern 3-Bed/2 Bath By Oxford St W1    67564       Liz                  NaN            Westminster  51.52195   -0.14094 Entire home/apt  510.0               3                 56  2024-02-19               0.33                               5               293                      0      NaN\n",
      "24328                 Battersea live/work artist house    41759       Joe                  NaN             Wandsworth  51.47072   -0.16266 Entire home/apt  213.0              90                 94  2022-07-19               0.54                               1               194                      0      NaN\n",
      "31036   Bright  compact 1 Bedroom Apartment Brick Lane   133271  Hendryks                  NaN          Tower Hamlets  51.52425   -0.06997 Entire home/apt  100.0               2                126  2025-02-20               0.70                               8               353                      3      NaN\n",
      "NDCG@10: 1.0\n",
      "NDCG@50: 1.0\n",
      "\n",
      "Top-10 ranked items (sample):\n",
      "                                              name neighbourhood       room_type      price  number_of_reviews  availability_365  relevance\n",
      "                    Contemporary 1 bed in Peckham.     Southwark Entire home/apt  88.176443          24.736264        211.228017          3\n",
      "              Cozy large double bedroom in Clapham       Lambeth    Private room  49.250978         154.549350        148.867355          3\n",
      " Charming designer 1 bed on Charlie Chaplin Street       Lambeth Entire home/apt  87.440453          59.878215        171.795480          3\n",
      "                        Modern Studio in Fitzrovia        Camden Entire home/apt  98.876716          36.658148        129.114251          3\n",
      "                                   Women only room Tower Hamlets    Private room  62.625605          22.942540        254.631726          3\n",
      "Modern New 1 Bedroom Flat Oval/Kennington Flat No2       Lambeth Entire home/apt 107.623338         114.725058        160.265335          3\n",
      "           Charming double studio with kitchenette         Brent Entire home/apt  98.039241          24.212722        371.669066          3\n",
      "     Double bedroom in central London flat, Zone 2     Southwark    Private room  75.518620          23.645129        156.163889          3\n",
      "  Large bedroom with garden 20 minutes to Victoria       Lambeth    Private room  39.003440          31.967961        242.990954          3\n",
      " Beautifully Decorated, Spacious 2 Bed in Brixton!       Lambeth Entire home/apt  93.331393         117.557026        105.565523          3\n"
     ]
    }
   ],
   "source": [
    "# Ranking dataset: listings (Airbnb-style)\n",
    "LIST_PATH = \"../../../Datasets/Regression/listings.csv\"\n",
    "sample_listings = \"id,name,host_id,host_name,neighbourhood_group,neighbourhood,latitude,longitude,room_type,price,minimum_nights,number_of_reviews,last_review,reviews_per_month,calculated_host_listings_count,availability_365,number_of_reviews_ltm,license\\n13913,Holiday London DB Room Let-on going,54730,Alina,,Islington,51.56861,-0.1127,Private room,57,1,51,2025-02-09,0.29,3,344,10,\\n15400,Bright Chelsea  Apartment. Chelsea!,60302,Philippa,,Kensington and Chelsea,51.4878,-0.16813,Entire home/apt,180,4,96,2024-04-28,0.52,1,11,2,\\n17402,Very Central Modern 3-Bed/2 Bath By Oxford St W1,67564,Liz,,Westminster,51.52195,-0.14094,Entire home/apt,510,3,56,2024-02-19,0.33,5,293,0,\\n24328,Battersea live/work artist house,41759,Joe,,Wandsworth,51.47072,-0.16266,Entire home/apt,213,90,94,2022-07-19,0.54,1,194,0,\\n31036,Bright  compact 1 Bedroom Apartment Brick Lane,133271,Hendryks,,Tower Hamlets,51.52425,-0.06997,Entire home/apt,100,2,126,2025-02-20,0.70,8,353,3,\\n\"\n",
    "\n",
    "list_df = read_csv_or_sample(LIST_PATH, sample_listings)\n",
    "print(\"Raw rows (head):\")\n",
    "print(list_df.head().to_string(index=False))\n",
    "\n",
    "df = synthesize_from_sample(list_df, n=800, noise=0.06, seed=17)\n",
    "\n",
    "# Convert and clip numeric columns to keep them in reasonable ranges (prevents invalid log1p)\n",
    "num_cols_all = [\"price\", \"minimum_nights\", \"number_of_reviews\", \"reviews_per_month\",\n",
    "                \"calculated_host_listings_count\", \"availability_365\"]\n",
    "for c in num_cols_all:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df[\"price\"] = df[\"price\"].fillna(df[\"price\"].median()).clip(lower=0)\n",
    "df[\"reviews_per_month\"] = df[\"reviews_per_month\"].fillna(0.0).clip(lower=0)\n",
    "df[\"number_of_reviews\"] = df[\"number_of_reviews\"].fillna(0.0).clip(lower=0)\n",
    "df[\"availability_365\"] = df[\"availability_365\"].fillna(df[\"availability_365\"].median()).clip(lower=0)\n",
    "df[\"minimum_nights\"] = df[\"minimum_nights\"].fillna(df[\"minimum_nights\"].median()).clip(lower=1)\n",
    "df[\"calculated_host_listings_count\"] = df[\"calculated_host_listings_count\"].fillna(1.0).clip(lower=1)\n",
    "\n",
    "df[\"room_type\"] = df[\"room_type\"].astype(str)\n",
    "df[\"neighbourhood\"] = df[\"neighbourhood\"].astype(str)\n",
    "\n",
    "# Synthetic relevance label (for demonstration only)\n",
    "score = (0.6*np.log1p(df[\"number_of_reviews\"]) + 0.3*np.log1p(df[\"availability_365\"]) - 0.002*df[\"price\"])\n",
    "qs = score.quantile([0.25, 0.5, 0.75]).values\n",
    "df[\"relevance\"] = np.digitize(score, qs).astype(int)\n",
    "\n",
    "def ndcg_at_k(y_true, y_score, k=10):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_score = np.asarray(y_score)\n",
    "    order = np.argsort(y_score)[::-1][:k]\n",
    "    gains = (2**y_true[order] - 1)\n",
    "    discounts = 1.0 / np.log2(np.arange(2, len(order)+2))\n",
    "    dcg = np.sum(gains * discounts)\n",
    "\n",
    "    ideal_order = np.argsort(y_true)[::-1][:k]\n",
    "    ideal_gains = (2**y_true[ideal_order] - 1)\n",
    "    idcg = np.sum(ideal_gains * discounts)\n",
    "    return float(dcg / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "y = df[\"relevance\"].astype(int)\n",
    "X = df[[\n",
    "    \"price\", \"minimum_nights\", \"number_of_reviews\", \"reviews_per_month\",\n",
    "    \"calculated_host_listings_count\", \"availability_365\",\n",
    "    \"room_type\", \"neighbourhood\"\n",
    "]].copy()\n",
    "\n",
    "num_cols = [\"price\", \"minimum_nights\", \"number_of_reviews\", \"reviews_per_month\",\n",
    "            \"calculated_host_listings_count\", \"availability_365\"]\n",
    "cat_cols = [\"room_type\", \"neighbourhood\"]\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                      (\"sc\", StandardScaler())]), num_cols),\n",
    "    (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                      (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols)\n",
    "])\n",
    "\n",
    "ranker = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"rf\", RandomForestRegressor(n_estimators=200, random_state=0, n_jobs=-1, min_samples_leaf=3))\n",
    "])\n",
    "\n",
    "# Hold out entire neighbourhoods (group-aware evaluation)\n",
    "unique_neigh = df[\"neighbourhood\"].unique()\n",
    "rng = np.random.default_rng(0)\n",
    "test_neigh = set(rng.choice(unique_neigh, size=max(1, len(unique_neigh)//4), replace=False))\n",
    "test_mask = df[\"neighbourhood\"].isin(test_neigh)\n",
    "\n",
    "X_train, X_test = X[~test_mask], X[test_mask]\n",
    "y_train, y_test = y[~test_mask], y[test_mask]\n",
    "\n",
    "ranker.fit(X_train, y_train)\n",
    "y_score = ranker.predict(X_test)\n",
    "\n",
    "print(\"NDCG@10:\", round(ndcg_at_k(y_test, y_score, k=10), 3))\n",
    "print(\"NDCG@50:\", round(ndcg_at_k(y_test, y_score, k=50), 3))\n",
    "\n",
    "top_idx = np.argsort(y_score)[::-1][:10]\n",
    "ranked = df.loc[X_test.index[top_idx], [\"name\",\"neighbourhood\",\"room_type\",\"price\",\"number_of_reviews\",\"availability_365\",\"relevance\"]]\n",
    "print(\"\\nTop-10 ranked items (sample):\")\n",
    "print(ranked.reset_index(drop=True).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa267ec2",
   "metadata": {},
   "source": [
    "## ۸. مثال پیش‌بینی: بزرگی زلزله در سطح روزانه\n",
    "\n",
    "### ۸.۱ پیش‌بینی نظارت‌شده است اما وابسته به زمان\n",
    "\n",
    "پیش‌بینی $y_{t+h}$ را با استفاده از اطلاعات تا زمان $t$ انجام می‌دهد.\n",
    "با اینکه نظارت‌شده است، وابستگی زمانی قوانین را عوض می‌کند:\n",
    "\n",
    "- نباید از داده‌ی آینده برای آموزش استفاده کنید.\n",
    "- اعتبارسنجی باید بر اساس split زمانی باشد.\n",
    "\n",
    "### ۸.۲ مهندسی ویژگی با lag\n",
    "\n",
    "یک روش ساده این است که داده را روزانه تجمیع کنیم و ویژگی‌های lag بسازیم:\n",
    "\n",
    "- میانگین lag‌شده‌ی بزرگی\n",
    "- تعداد رخدادهای lag‌شده\n",
    "\n",
    "سپس یک مدل رگرسیون آموزش دهیم.\n",
    "\n",
    "### ۸.۳ ارزیابی لغزان\n",
    "\n",
    "از `TimeSeriesSplit` برای شبیه‌سازی ارزیابی پنجره‌ای استفاده می‌کنیم.\n",
    "این کامل نیست (در سیستم واقعی ممکن است gap داشته باشید)، اما از shuffle بسیار امن‌تر است.\n",
    "\n",
    "پیاده‌سازی می‌کنیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3cb1797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw rows (head):\n",
      "      date     time  latitude  longitude  depth  magnitude\n",
      "2008-11-01 00:31:25     -0.60   98.89553   20.0       2.99\n",
      "2008-11-01 01:34:29     -6.61  129.38722   30.1       5.51\n",
      "2008-11-01 01:38:14     -3.65  127.99068    5.0       3.54\n",
      "2008-11-01 02:20:05     -4.20  128.09700    5.0       2.42\n",
      "2008-11-01 02:32:18     -4.09  128.20047   10.0       2.41\n",
      "TimeSeries CV MAE (mean): 0.2143\n",
      "TimeSeries CV MAE (std):  0.0214\n",
      "\n",
      "Last 5 days (actual vs predicted mean magnitude):\n",
      "      date  mean_magnitude  pred_next_mean_mag  event_count\n",
      "2022-09-22        3.388400            3.467577           25\n",
      "2022-09-23        3.507105            3.343235           38\n",
      "2022-09-24        3.461333            3.539307           15\n",
      "2022-09-25        3.242609            3.466240           23\n",
      "2022-09-26        3.645238            3.492252           21\n"
     ]
    }
   ],
   "source": [
    "# Forecasting dataset: earthquake\n",
    "EQ_PATH = \"../../../Datasets/Regression/earthquake.csv\"\n",
    "sample_earthquake = \"date,time,latitude,longitude,depth,magnitude\\n2008-11-01,00:31:25,-0.6,98.89553,20.0,2.99\\n2008-11-02,01:34:29,-6.61,129.38722,30.1,5.51\\n2008-11-03,01:38:14,-3.65,127.99068,5.0,3.54\\n2008-11-04,02:20:05,-4.2,128.097,5.0,2.42\\n2008-11-05,02:32:18,-4.09,128.20047,10.0,2.41\\n\"\n",
    "\n",
    "eq_df = read_csv_or_sample(EQ_PATH, sample_earthquake)\n",
    "print(\"Raw rows (head):\")\n",
    "print(eq_df.head().to_string(index=False))\n",
    "\n",
    "# If you only have a few sample rows, create a multi-day synthetic series for demonstration.\n",
    "if len(eq_df) < 100:\n",
    "    df = synthesize_earthquake_timeseries(eq_df, days=220, avg_events_per_day=4, seed=19)\n",
    "else:\n",
    "    df = eq_df.copy()\n",
    "\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"date\"].astype(str) + \" \" + df[\"time\"].astype(str), errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"timestamp\"]).sort_values(\"timestamp\")\n",
    "\n",
    "daily = df.set_index(\"timestamp\").resample(\"D\")[\"magnitude\"].agg([\"mean\", \"count\"]).reset_index()\n",
    "daily.columns = [\"date\", \"mean_magnitude\", \"event_count\"]\n",
    "\n",
    "for lag in [1, 2, 3, 7]:\n",
    "    daily[f\"lag_mean_{lag}\"] = daily[\"mean_magnitude\"].shift(lag)\n",
    "    daily[f\"lag_count_{lag}\"] = daily[\"event_count\"].shift(lag)\n",
    "\n",
    "daily = daily.dropna().reset_index(drop=True)\n",
    "\n",
    "y = daily[\"mean_magnitude\"]\n",
    "X = daily.drop(columns=[\"date\", \"mean_magnitude\"])\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "model = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"sc\", StandardScaler()),\n",
    "    (\"ridge\", Ridge(alpha=1.0, random_state=0)),\n",
    "])\n",
    "\n",
    "maes = []\n",
    "for train_idx, test_idx in tscv.split(X):\n",
    "    model.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "    pred = model.predict(X.iloc[test_idx])\n",
    "    maes.append(mean_absolute_error(y.iloc[test_idx], pred))\n",
    "\n",
    "print(\"TimeSeries CV MAE (mean):\", round(float(np.mean(maes)), 4))\n",
    "print(\"TimeSeries CV MAE (std): \", round(float(np.std(maes)), 4))\n",
    "\n",
    "model.fit(X, y)\n",
    "daily[\"pred_next_mean_mag\"] = model.predict(X)\n",
    "\n",
    "print(\"\\nLast 5 days (actual vs predicted mean magnitude):\")\n",
    "print(daily[[\"date\", \"mean_magnitude\", \"pred_next_mean_mag\", \"event_count\"]].tail(5).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be1cb65",
   "metadata": {},
   "source": [
    "## ۹. جمع‌بندی و نکات کلیدی\n",
    "\n",
    "1. **از هدف و تصمیم شروع کنید.**  \n",
    "   الگوریتم‌ها بعداً می‌آیند.\n",
    "\n",
    "2. **معیارها وابسته به نوع وظیفه‌اند.**  \n",
    "   - رگرسیون: MAE/RMSE\n",
    "   - دسته‌بندی: F1/AUC (و در صورت نیاز کالیبراسیون)\n",
    "   - رتبه‌بندی: NDCG@k و معیارهای top-$k$\n",
    "   - پیش‌بینی: خطاهای وابسته به افق با split زمانی\n",
    "\n",
    "3. **پروتکل اعتبارسنجی بخشی از تعریف وظیفه است.**  \n",
    "   سری‌زمانی نیازمند ارزیابی زمان‌محور است.\n",
    "\n",
    "4. **baseline حیاتی است.**  \n",
    "   یک baseline ساده و درست می‌تواند از مدل پیچیده‌ای که غلط ارزیابی شده بهتر باشد.\n",
    "\n",
    "---\n",
    "\n",
    "## ۱۰. تمرین‌ها\n",
    "\n",
    "1. در بخش رگرسیون، به‌جای مدل خطی از `RandomForestRegressor` استفاده کنید و MAE/RMSE را مقایسه کنید.\n",
    "2. در بخش دسته‌بندی، آستانه‌ی $\\tau$ را طوری تنظیم کنید که F1 روی validation بیشینه شود.\n",
    "3. معیار Precision@k را برای بخش رتبه‌بندی پیاده‌سازی کنید و با NDCG@k مقایسه کنید.\n",
    "4. برای پیش‌بینی، split پنجره‌ی گسترش‌یابنده را امتحان کنید و خطاها را مقایسه کنید.\n",
    "\n",
    "---\n",
    "\n",
    "اگر دوست دارید، می‌توانیم در انتهای این نوت‌بوک یک «مینی‌پروژه» اضافه کنیم:\n",
    "با یک سناریوی کاربردی، نوع وظیفه را تعیین کنید، $y$ را تعریف کنید،\n",
    "معیار را انتخاب کنید و پایپ‌لاین حداقلی را بنویسید.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
