{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf48dddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@400;700&display=swap');\n",
       "@import url('https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&display=swap');\n",
       "\n",
       "\n",
       "/* Text areas (Classic Notebook + JupyterLab) */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "div.rendered_html, .output_subarea {\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "/* RTL for rendered markdown/html content */\n",
       ".rendered_html, .text_cell_render, .jp-RenderedHTMLCommon,\n",
       "h1, h2, h3, h4, h5, h6, p, strong, label, ol, ul, li {\n",
       "  line-height: 1.9;\n",
       "  font-family: \"Roboto\", \"Inter\", \"Source Sans 3\", system-ui, -apple-system, \"Segoe UI\", Arial, sans-serif; !important;\n",
       "}\n",
       "\n",
       "h1 { font-size: 2rem; color: #070F2B; font-weight: 900}\n",
       "h2 { font-size: 1.8rem; color: #070F2B; font-weight: 800}\n",
       "h3 { font-size: 1.6rem; color: #070F2B; font-weight: 700}\n",
       "h4 { font-size: 1.4rem; color: #1E3E62; font-weight: 600}\n",
       "h5 { font-size: 1.2rem; color: #1E3E62}\n",
       "h6 { font-size: 1rem; color: #1E3E62}\n",
       "p { font-size: 1.1rem; ; font-weight: 400}\n",
       "ol, ul, li, th, td  { font-size: 1rem; }\n",
       "\n",
       "/* Keep code + outputs LTR and monospace */\n",
       ".CodeMirror, .CodeMirror *,\n",
       "pre, code,\n",
       ".jp-CodeCell .jp-InputArea, .jp-CodeCell .jp-InputArea *,\n",
       ".jp-OutputArea, .jp-OutputArea * {\n",
       "  direction: ltr !important;\n",
       "  text-align: left !important;\n",
       "  font-size: 1rem !important;\n",
       "  font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "css = Path(\"../../../css/custom.css\").read_text(encoding=\"utf-8\")\n",
    "display(HTML(f\"<style>{css}</style>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b5ee15",
   "metadata": {},
   "source": [
    "# Chapter 5 — Decision Trees and Variants\n",
    "## Lesson 8: Handling Missing Values and Categorical Variables in Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca56dcb",
   "metadata": {},
   "source": [
    "\n",
    "Decision trees are often marketed as “works out of the box on messy tabular data.” That’s *partly* true: trees are flexible, non-linear, and require no feature scaling. But two very common realities still need careful engineering:\n",
    "\n",
    "1. **Missing values** (NaN / null / blank) — produced by data collection gaps, sensor dropouts, partial forms, or join mismatches.\n",
    "2. **Categorical variables** — strings and discrete labels such as `\"HIGH\"`, `\"LOW\"`, `\"Yes\"`, `\"No\"`, `\"Premium\"`, `\"East\"`.\n",
    "\n",
    "Many production-grade tree implementations include model-level tricks for missingness (e.g., default directions, surrogate splits, or probabilistic routing) and for categorical features (e.g., ordered target statistics). However, **scikit-learn’s standard `DecisionTreeClassifier/Regressor` does not accept NaNs**, and it expects purely numeric input. So, in practice, you typically handle both issues in a **preprocessing pipeline**.\n",
    "\n",
    "In this lesson you will learn **exactly how to do this correctly** (and how to avoid leakage), using multiple datasets from your repo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7b16b",
   "metadata": {},
   "source": [
    "\n",
    "### Learning objectives\n",
    "\n",
    "By the end of this lesson you should be able to:\n",
    "\n",
    "- Explain why missingness and categoricals are “special” for trees in different libraries.\n",
    "- Diagnose missingness patterns and choose sensible strategies (drop, impute, indicator, model-native handling).\n",
    "- Encode categoricals for trees (one-hot, ordinal, frequency, target encoding) and understand the bias/variance trade-offs.\n",
    "- Build **leakage-safe** pipelines with `ColumnTransformer` + `Pipeline` and evaluate them with cross-validation.\n",
    "- Implement a **safe target encoder** (out-of-fold) and understand when it’s worth the complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ddfb7e",
   "metadata": {},
   "source": [
    "\n",
    "### Environment setup\n",
    "\n",
    "We will use `pandas`, `numpy`, `matplotlib`, and `scikit-learn`.\n",
    "\n",
    "**Important:** dataset paths are relative to the notebook location. For Chapter 5 notebooks, use:\n",
    "\n",
    "- `../../../Datasets/Classification/...`\n",
    "- `../../../Datasets/Regression/...`\n",
    "- `../../../Datasets/Clustering/...` (not used in this lesson, but kept for consistency)\n",
    "\n",
    "If you run this notebook outside the repo, update the paths accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d195b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    mean_absolute_error, mean_squared_error\n",
    ")\n",
    "# sklearn 1.4+ deprecates mean_squared_error(..., squared=False) in favor of root_mean_squared_error\n",
    "try:\n",
    "    from sklearn.metrics import root_mean_squared_error\n",
    "except Exception:\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_text\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bf8885",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Missing values in decision trees: what’s going on?\n",
    "\n",
    "### 1.1 Why missing values are not “just another value”\n",
    "A standard CART-style split compares a feature against a threshold (numeric) or membership (categorical) and sends a sample left or right. If a value is missing, the model has no obvious rule for routing the sample.\n",
    "\n",
    "In a *pure* numeric split, we evaluate a condition such as:\n",
    "\n",
    "$$\n",
    "x_j \\le t\n",
    "$$\n",
    "\n",
    "But if $x_j$ is NaN, the comparison is undefined. That is why many libraries require you to decide how to treat missingness **before** fitting a classic decision tree.\n",
    "\n",
    "### 1.2 Common strategies used by tree implementations (conceptual)\n",
    "Different libraries implement different strategies:\n",
    "\n",
    "- **Drop rows** with missing features (simple but can bias data and waste signal).\n",
    "- **Impute** missing values (mean/median for numeric, mode for categorical, or a dedicated “Missing” category).\n",
    "- **Missing indicator**: add a binary feature $m_j = \\mathbb{1}[x_j \\text{ is missing}]$ so the tree can learn “missingness is informative.”\n",
    "- **Default direction** (common in gradient-boosted trees): learn where missing values go at each split.\n",
    "- **Surrogate splits** (classic CART idea): if the primary split feature is missing, use a secondary feature that best mimics the split.\n",
    "- **Probabilistic routing**: send missing samples left/right proportionally to observed frequencies.\n",
    "\n",
    "In scikit-learn’s classic `DecisionTree*`, you usually choose **imputation + (optional) indicator**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5f4e25",
   "metadata": {},
   "source": [
    "\n",
    "### 1.3 Practical decision checklist (for tabular ML)\n",
    "\n",
    "Use this checklist when you see missingness:\n",
    "\n",
    "1. **Measure** missingness rate per feature and per row.\n",
    "2. If missingness is tiny (e.g., < 1%), test **dropping** rows as a baseline.\n",
    "3. For numeric features, start with **median** imputation (robust to outliers).\n",
    "4. For categorical features, start with **most_frequent** or a constant `\"__MISSING__\"` category.\n",
    "5. Add **missing indicators** if you suspect missingness is informative (common in real-world data).\n",
    "6. Validate choices using cross-validation; don’t guess.\n",
    "\n",
    "We’ll apply this checklist in code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6374fc47",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Example 1 (Classification): `drug200.csv`\n",
    "\n",
    "This dataset is ideal for this lesson because:\n",
    "- It contains **categorical features** (`Sex`, `BP`, `Cholesterol`).\n",
    "- It has numeric features (`Age`, `Na_to_K`).\n",
    "- The target is multi-class (`Drug`).\n",
    "\n",
    "We will:\n",
    "1. Load the dataset.\n",
    "2. Inject missing values (so we can test strategies deterministically).\n",
    "3. Compare pipelines:\n",
    "   - Baseline: drop missing rows.\n",
    "   - Pipeline A: impute + one-hot.\n",
    "   - Pipeline B: impute + one-hot + missing-indicator (via constant category for categoricals, and median for numeric).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eda7559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>DrugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>DrugY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0   23   F    HIGH        HIGH   25.355  DrugY\n",
       "1   47   M     LOW        HIGH   13.093  drugC\n",
       "2   47   M     LOW        HIGH   10.114  drugC\n",
       "3   28   F  NORMAL        HIGH    7.798  drugX\n",
       "4   61   F     LOW        HIGH   18.043  DrugY"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Drug200 dataset\n",
    "path_drug = \"../../../Datasets/Classification/drug200.csv\"\n",
    "df_drug = pd.read_csv(path_drug)\n",
    "\n",
    "df_drug.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59054544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BP             0.10\n",
       "Sex            0.08\n",
       "Na_to_K        0.05\n",
       "Age            0.00\n",
       "Cholesterol    0.00\n",
       "Drug           0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a controlled missingness scenario for demonstration:\n",
    "# - Make ~8% of Sex missing\n",
    "# - Make ~10% of BP missing\n",
    "# - Make ~5% of Na_to_K missing\n",
    "\n",
    "df = df_drug.copy()\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "n = len(df)\n",
    "\n",
    "for col, rate in [(\"Sex\", 0.08), (\"BP\", 0.10), (\"Na_to_K\", 0.05)]:\n",
    "    idx = rng.choice(n, size=int(rate * n), replace=False)\n",
    "    df.loc[idx, col] = np.nan\n",
    "\n",
    "missing_rates = df.isna().mean().sort_values(ascending=False)\n",
    "missing_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5c036a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize missingness per column (simple bar plot)\n",
    "plt.figure()\n",
    "missing_rates.plot(kind=\"bar\")\n",
    "plt.title(\"Missingness rate per column (Drug200)\")\n",
    "plt.xlabel(\"Column\")\n",
    "plt.ylabel(\"Fraction missing\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca002a92",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Build pipelines (leakage-safe)\n",
    "\n",
    "A **leakage-safe** workflow means:\n",
    "- Split into train/test *first* (or use CV).\n",
    "- Fit imputers and encoders **only on training folds**.\n",
    "- Apply the fitted transformations to validation/test folds.\n",
    "\n",
    "`Pipeline` and `ColumnTransformer` enforce that discipline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba46e48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Sex', 'BP', 'Cholesterol'], ['Age', 'Na_to_K'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"Drug\"])\n",
    "y = df[\"Drug\"]\n",
    "\n",
    "# Identify columns by type\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "cat_cols, num_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5a7d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (drop missing rows + get_dummies)\n",
      "Test accuracy: 0.975609756097561\n"
     ]
    }
   ],
   "source": [
    "# Train/test split (stratified for classification)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Baseline: drop rows with any missing values (train and test separately)\n",
    "train_mask = X_train.notna().all(axis=1)\n",
    "test_mask  = X_test.notna().all(axis=1)\n",
    "\n",
    "X_train_drop = X_train.loc[train_mask].copy()\n",
    "y_train_drop = y_train.loc[train_mask].copy()\n",
    "X_test_drop  = X_test.loc[test_mask].copy()\n",
    "y_test_drop  = y_test.loc[test_mask].copy()\n",
    "\n",
    "baseline_clf = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "baseline_clf.fit(pd.get_dummies(X_train_drop, drop_first=False), y_train_drop)\n",
    "\n",
    "# Align dummy columns between train and test\n",
    "X_test_dum = pd.get_dummies(X_test_drop, drop_first=False)\n",
    "X_train_dum = pd.get_dummies(X_train_drop, drop_first=False)\n",
    "X_test_dum = X_test_dum.reindex(columns=X_train_dum.columns, fill_value=0)\n",
    "\n",
    "y_pred_base = baseline_clf.predict(X_test_dum)\n",
    "\n",
    "print(\"Baseline (drop missing rows + get_dummies)\")\n",
    "print(\"Test accuracy:\", accuracy_score(y_test_drop, y_pred_base))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa014975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline A (median/mode impute + one-hot)\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Pipeline A: Impute + OneHot + Decision Tree\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocess_A = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_A = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_A),\n",
    "    (\"model\", DecisionTreeClassifier(random_state=42, max_depth=5, min_samples_leaf=5)),\n",
    "])\n",
    "\n",
    "pipe_A.fit(X_train, y_train)\n",
    "y_pred_A = pipe_A.predict(X_test)\n",
    "\n",
    "print(\"Pipeline A (median/mode impute + one-hot)\")\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred_A))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eacbd9",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 A simple way to let the tree “see” missingness\n",
    "\n",
    "A robust trick for categoricals is to impute with a constant token (e.g., `\"__MISSING__\"`). After one-hot encoding, this produces a dedicated indicator column that the tree can split on.\n",
    "\n",
    "For numeric features, you can add explicit missing indicators, but to keep dependencies minimal we’ll show the categorical-indicator approach (and discuss numeric indicators conceptually).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a45bde44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline B (constant categorical impute => missing indicator via one-hot)\n",
      "Test accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Pipeline B: Impute categorical with a constant token so missingness becomes a category\n",
    "categorical_transformer_B = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"__MISSING__\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocess_B = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),  # numeric still median-imputed\n",
    "        (\"cat\", categorical_transformer_B, cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_B = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_B),\n",
    "    (\"model\", DecisionTreeClassifier(random_state=42, max_depth=5, min_samples_leaf=5)),\n",
    "])\n",
    "\n",
    "pipe_B.fit(X_train, y_train)\n",
    "y_pred_B = pipe_B.predict(X_test)\n",
    "\n",
    "print(\"Pipeline B (constant categorical impute => missing indicator via one-hot)\")\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7bd44b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report (Pipeline B)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       DrugY       0.96      1.00      0.98        23\n",
      "       drugA       1.00      1.00      1.00         6\n",
      "       drugB       1.00      0.75      0.86         4\n",
      "       drugC       1.00      1.00      1.00         4\n",
      "       drugX       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.96        50\n",
      "   macro avg       0.98      0.93      0.95        50\n",
      "weighted avg       0.96      0.96      0.96        50\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DrugY</th>\n",
       "      <th>drugA</th>\n",
       "      <th>drugB</th>\n",
       "      <th>drugC</th>\n",
       "      <th>drugX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DrugY</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugA</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugB</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugX</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DrugY  drugA  drugB  drugC  drugX\n",
       "DrugY     23      0      0      0      0\n",
       "drugA      0      6      0      0      0\n",
       "drugB      0      0      3      0      1\n",
       "drugC      0      0      0      4      0\n",
       "drugX      1      0      0      0     12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Classification report (Pipeline B)\")\n",
    "print(classification_report(y_test, y_pred_B))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_B)\n",
    "cm_df = pd.DataFrame(cm, index=pipe_B.classes_, columns=pipe_B.classes_)\n",
    "cm_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21bc76b",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3 Inspecting the learned rules\n",
    "\n",
    "Trees are easy to inspect. After preprocessing, we can extract the model and print a text summary of the split rules.\n",
    "\n",
    "Note: once you one-hot encode, feature names expand; we’ll reconstruct them from the `ColumnTransformer`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff5f3e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- Na_to_K <= 14.63\n",
      "|   |--- BP_HIGH <= 0.50\n",
      "|   |   |--- BP_LOW <= 0.50\n",
      "|   |   |   |--- BP_NORMAL <= 0.50\n",
      "|   |   |   |   |--- class: drugX\n",
      "|   |   |   |--- BP_NORMAL >  0.50\n",
      "|   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |--- BP_LOW >  0.50\n",
      "|   |   |   |--- Cholesterol_HIGH <= 0.50\n",
      "|   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |--- Cholesterol_HIGH >  0.50\n",
      "|   |   |   |   |--- class: drugC\n",
      "|   |--- BP_HIGH >  0.50\n",
      "|   |   |--- Age <= 50.00\n",
      "|   |   |   |--- Age <= 28.50\n",
      "|   |   |   |   |--- class: drugA\n",
      "|   |   |   |--- Age >  28.50\n",
      "|   |   |   |   |--- class: drugA\n",
      "|   |   |--- Age >  50.00\n",
      "|   |   |   |--- class: drugB\n",
      "|--- Na_to_K >  14.63\n",
      "|   |--- class: DrugY\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Helper to recover feature names after ColumnTransformer\n",
    "def get_feature_names_from_column_transformer(ct: ColumnTransformer):\n",
    "    output_features = []\n",
    "    for name, trans, cols in ct.transformers_:\n",
    "        if name == \"remainder\":\n",
    "            continue\n",
    "        if hasattr(trans, \"named_steps\"):\n",
    "            last = list(trans.named_steps.values())[-1]\n",
    "        else:\n",
    "            last = trans\n",
    "        if hasattr(last, \"get_feature_names_out\"):\n",
    "            try:\n",
    "                fn = last.get_feature_names_out(cols)\n",
    "            except TypeError:\n",
    "                fn = last.get_feature_names_out()\n",
    "            output_features.extend(fn.tolist())\n",
    "        else:\n",
    "            # Numeric pipeline typically doesn't change names\n",
    "            if isinstance(cols, (list, tuple)):\n",
    "                output_features.extend(list(cols))\n",
    "            else:\n",
    "                output_features.append(str(cols))\n",
    "    return output_features\n",
    "\n",
    "ct = pipe_B.named_steps[\"preprocess\"]\n",
    "feature_names = get_feature_names_from_column_transformer(ct)\n",
    "\n",
    "dt = pipe_B.named_steps[\"model\"]\n",
    "rules = export_text(dt, feature_names=feature_names, max_depth=3)\n",
    "print(rules[:4000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4109475",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Categorical variables in trees: options and trade-offs\n",
    "\n",
    "### 3.1 One-hot encoding (OHE)\n",
    "**Pros**\n",
    "- No false ordering.\n",
    "- Works well for low/medium cardinality categoricals.\n",
    "- Splits are interpretable (e.g., `BP_HIGH` vs not).\n",
    "\n",
    "**Cons**\n",
    "- High cardinality can explode dimensionality (memory/time).\n",
    "- Trees can overfit by splitting on rare categories.\n",
    "\n",
    "### 3.2 Ordinal encoding\n",
    "Map categories to integers (e.g., `LOW→0`, `NORMAL→1`, `HIGH→2`).\n",
    "\n",
    "**Pros**\n",
    "- Compact, fast.\n",
    "- Works well if categories have a real order (e.g., education level).\n",
    "\n",
    "**Cons**\n",
    "- Introduces an *artificial* ordering if no true order exists.\n",
    "- Trees might create “threshold” splits that group categories in unintended ways.\n",
    "\n",
    "### 3.3 Frequency / count encoding\n",
    "Replace each category by its frequency in training data.\n",
    "\n",
    "**Pros**\n",
    "- Very compact.\n",
    "- Sometimes surprisingly strong for high-cardinality features.\n",
    "- Encodes “rarity” which often correlates with interesting outcomes.\n",
    "\n",
    "**Cons**\n",
    "- Loses identity of categories; different categories with same frequency become identical.\n",
    "\n",
    "### 3.4 Target encoding (mean encoding)\n",
    "Replace a category by the mean target value for that category (classification: mean of $y=1$ in binary; regression: mean of $y$).\n",
    "\n",
    "**Pros**\n",
    "- Powerful for high-cardinality features.\n",
    "\n",
    "**Cons (critical!)**\n",
    "- High leakage risk if you compute category means using the full dataset.\n",
    "- Must be done *out-of-fold* or with strong smoothing and CV discipline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119d82c",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Example 2 (Regression): `house-prices.csv`\n",
    "\n",
    "We now switch to a regression task. This dataset includes:\n",
    "- Numeric: `SqFt`, `Bedrooms`, `Bathrooms`, `Offers`\n",
    "- Categorical: `Brick`, `Neighborhood`\n",
    "- Target: `Price`\n",
    "\n",
    "We will:\n",
    "- Inject missingness into `Brick` and `SqFt`.\n",
    "- Compare one-hot vs ordinal encoding for `Neighborhood`.\n",
    "- Evaluate with MAE and RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbe65396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home</th>\n",
       "      <th>Price</th>\n",
       "      <th>SqFt</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Offers</th>\n",
       "      <th>Brick</th>\n",
       "      <th>Neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114300</td>\n",
       "      <td>1790</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>114200</td>\n",
       "      <td>2030</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>114800</td>\n",
       "      <td>1740</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>94700</td>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>119800</td>\n",
       "      <td>2130</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Home   Price  SqFt  Bedrooms  Bathrooms  Offers Brick Neighborhood\n",
       "0     1  114300  1790         2          2       2    No         East\n",
       "1     2  114200  2030         4          2       3    No         East\n",
       "2     3  114800  1740         3          2       1    No         East\n",
       "3     4   94700  1980         3          2       3    No         East\n",
       "4     5  119800  2130         3          3       3    No         East"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_house = \"../../../Datasets/Regression/house-prices.csv\"\n",
    "df_house = pd.read_csv(path_house)\n",
    "\n",
    "df_house.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37837bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brick           0.078125\n",
       "SqFt            0.046875\n",
       "Price           0.000000\n",
       "Home            0.000000\n",
       "Bedrooms        0.000000\n",
       "Bathrooms       0.000000\n",
       "Offers          0.000000\n",
       "Neighborhood    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df_house.copy()\n",
    "rng = np.random.default_rng(123)\n",
    "\n",
    "# Inject some missingness\n",
    "n2 = len(df2)\n",
    "df2.loc[rng.choice(n2, size=max(1, int(0.08*n2)), replace=False), \"Brick\"] = np.nan\n",
    "df2.loc[rng.choice(n2, size=max(1, int(0.05*n2)), replace=False), \"SqFt\"] = np.nan\n",
    "\n",
    "df2.isna().mean().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35267862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(10255.600198412696), np.float64(14559.534126574883))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xh = df2.drop(columns=[\"Price\"])\n",
    "yh = df2[\"Price\"]\n",
    "\n",
    "cat_cols_h = Xh.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols_h = [c for c in Xh.columns if c not in cat_cols_h]\n",
    "\n",
    "Xh_train, Xh_test, yh_train, yh_test = train_test_split(\n",
    "    Xh, yh, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "numeric_trans_h = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "# One-hot version\n",
    "cat_trans_ohe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"__MISSING__\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocess_ohe = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_trans_h, num_cols_h),\n",
    "        (\"cat\", cat_trans_ohe, cat_cols_h),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_ohe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_ohe),\n",
    "    (\"model\", DecisionTreeRegressor(random_state=42, max_depth=6, min_samples_leaf=5)),\n",
    "])\n",
    "\n",
    "pipe_ohe.fit(Xh_train, yh_train)\n",
    "pred_ohe = pipe_ohe.predict(Xh_test)\n",
    "\n",
    "mae_ohe = mean_absolute_error(yh_test, pred_ohe)\n",
    "rmse_ohe = root_mean_squared_error(yh_test, pred_ohe)\n",
    "\n",
    "mae_ohe, rmse_ohe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5d0f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(9346.755952380952), np.float64(12815.69685188128))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordinal encoding version for categoricals (compact, but may impose false order)\n",
    "cat_trans_ord = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"__MISSING__\")),\n",
    "    (\"ordinal\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "])\n",
    "\n",
    "preprocess_ord = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_trans_h, num_cols_h),\n",
    "        (\"cat\", cat_trans_ord, cat_cols_h),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_ord = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_ord),\n",
    "    (\"model\", DecisionTreeRegressor(random_state=42, max_depth=6, min_samples_leaf=5)),\n",
    "])\n",
    "\n",
    "pipe_ord.fit(Xh_train, yh_train)\n",
    "pred_ord = pipe_ord.predict(Xh_test)\n",
    "\n",
    "mae_ord = mean_absolute_error(yh_test, pred_ord)\n",
    "rmse_ord = root_mean_squared_error(yh_test, pred_ord)\n",
    "\n",
    "mae_ord, rmse_ord\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b48deb",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 Interpretation\n",
    "\n",
    "You might see either encoding win depending on:\n",
    "- dataset size (this one is small),\n",
    "- tree depth / min leaf size,\n",
    "- how much signal the categorical provides,\n",
    "- and whether the imposed ordinal order accidentally helps or hurts.\n",
    "\n",
    "In general:\n",
    "- **OHE** is the safe default when category count is modest.\n",
    "- **Ordinal** can be okay when there is a natural order or when you control splits with strong regularization (e.g., shallow trees, larger `min_samples_leaf`).\n",
    "\n",
    "Now we’ll move to a more advanced topic: **target encoding** for high-cardinality categoricals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb41ce",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Target encoding without leakage (advanced but practical)\n",
    "\n",
    "Target encoding replaces a category with a statistic of the target for that category.\n",
    "\n",
    "For regression, a basic target encoding is:\n",
    "\n",
    "$$\n",
    "\\text{TE}(c) = \\mathbb{E}[y \\mid x=c]\n",
    "$$\n",
    "\n",
    "For binary classification, it is often the positive rate $\\mathbb{P}(y=1 \\mid x=c)$.\n",
    "\n",
    "### Why leakage happens\n",
    "If you compute $\\mathbb{E}[y \\mid x=c]$ using the full dataset and then train a model, you have “peeked” at the target for each sample’s category — the encoding includes the sample’s own label. For rare categories, this can be extreme leakage, giving artificially high validation scores and poor real-world performance.\n",
    "\n",
    "### The fix: out-of-fold encoding\n",
    "During cross-validation:\n",
    "- For each fold, compute category means using **only the training fold**.\n",
    "- Apply them to the validation fold.\n",
    "- Optionally apply smoothing toward the global mean to reduce variance.\n",
    "\n",
    "Below is a minimal, dependency-free implementation that works with scikit-learn pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6a1fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TargetMeanEncoderOOF(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Out-of-fold target mean encoder for a single categorical column.\n",
    "\n",
    "    - During fit_transform(X_train, y_train): produces OOF encodings (no self-leakage).\n",
    "    - During transform(X_test): uses mapping fitted on full training data.\n",
    "    - Uses smoothing to shrink rare-category means toward the global mean.\n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing=20.0, n_splits=5, random_state=42):\n",
    "        self.smoothing = float(smoothing)\n",
    "        self.n_splits = int(n_splits)\n",
    "        self.random_state = int(random_state)\n",
    "\n",
    "    def _fit_mapping(self, s, y):\n",
    "        global_mean = y.mean()\n",
    "        stats = y.groupby(s).agg([\"mean\", \"count\"])\n",
    "        stats[\"smooth\"] = (stats[\"count\"] * stats[\"mean\"] + self.smoothing * global_mean) / (stats[\"count\"] + self.smoothing)\n",
    "        mapping = stats[\"smooth\"].to_dict()\n",
    "        return global_mean, mapping\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_df = pd.DataFrame(X)\n",
    "        s = X_df.iloc[:, 0].astype(\"object\")\n",
    "        y = pd.Series(y).reset_index(drop=True)\n",
    "        self.global_mean_, self.mapping_ = self._fit_mapping(s, y)\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        X_df = pd.DataFrame(X)\n",
    "        s = X_df.iloc[:, 0].astype(\"object\").reset_index(drop=True)\n",
    "        y = pd.Series(y).reset_index(drop=True)\n",
    "\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        oof = np.empty(len(y), dtype=float)\n",
    "\n",
    "        for tr_idx, va_idx in kf.split(s):\n",
    "            s_tr, y_tr = s.iloc[tr_idx], y.iloc[tr_idx]\n",
    "            global_mean, mapping = self._fit_mapping(s_tr, y_tr)\n",
    "            enc = s.iloc[va_idx].map(mapping).fillna(global_mean).astype(float)\n",
    "            oof[va_idx] = enc.values\n",
    "\n",
    "        # Fit mapping on full data for later transform\n",
    "        self.global_mean_, self.mapping_ = self._fit_mapping(s, y)\n",
    "\n",
    "        return pd.DataFrame(oof, columns=[\"__target_mean\"])\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_df = pd.DataFrame(X)\n",
    "        s = X_df.iloc[:, 0].astype(\"object\")\n",
    "        out = s.map(self.mapping_).fillna(self.global_mean_).astype(float)\n",
    "        return out.to_frame(name=\"__target_mean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b695115d",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Example 3 (Regression + high-cardinality categoricals): `listings.csv`\n",
    "\n",
    "This dataset has many real-world categorical columns (e.g., neighborhoods, room types). High-cardinality categoricals are common in product ML (users, items, locations).\n",
    "\n",
    "We will:\n",
    "- Build a small regression task: predict `price` from a subset of features.\n",
    "- Compare:\n",
    "  - One-hot encoding\n",
    "  - Frequency encoding\n",
    "  - Target encoding (our leakage-aware encoder)\n",
    "\n",
    "To keep runtime reasonable, we will sample rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a063c1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>room_type</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.490900</td>\n",
       "      <td>-0.137670</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.517378</td>\n",
       "      <td>0.012742</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>Private room</td>\n",
       "      <td>Newham</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.498490</td>\n",
       "      <td>-0.181320</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>Kensington and Chelsea</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.466316</td>\n",
       "      <td>0.112080</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>Bexley</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.539760</td>\n",
       "      <td>-0.165780</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>Camden</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude  longitude  minimum_nights  number_of_reviews        room_type  \\\n",
       "0  51.490900  -0.137670               2                 20  Entire home/apt   \n",
       "1  51.517378   0.012742               1                 20     Private room   \n",
       "2  51.498490  -0.181320               1                 42  Entire home/apt   \n",
       "3  51.466316   0.112080               1                  1  Entire home/apt   \n",
       "4  51.539760  -0.165780               5                  2  Entire home/apt   \n",
       "\n",
       "            neighbourhood  price  \n",
       "0             Westminster  244.0  \n",
       "1                  Newham   51.0  \n",
       "2  Kensington and Chelsea  338.0  \n",
       "3                  Bexley  152.0  \n",
       "4                  Camden  131.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_listings = \"../../../Datasets/Regression/listings.csv\"\n",
    "df_list = pd.read_csv(path_listings)\n",
    "\n",
    "# Basic cleanup: ensure numeric price\n",
    "df_list[\"price\"] = pd.to_numeric(df_list[\"price\"], errors=\"coerce\")\n",
    "\n",
    "# Choose a subset of features (mix of numeric + categorical)\n",
    "use_cols = [\"latitude\", \"longitude\", \"minimum_nights\", \"number_of_reviews\", \"room_type\", \"neighbourhood\"]\n",
    "df_list = df_list[use_cols + [\"price\"]].dropna(subset=[\"price\"]).copy()\n",
    "\n",
    "# Sample for speed (adjust as needed) and RESET INDEX to avoid .loc KeyError later\n",
    "df_list = df_list.sample(n=min(3000, len(df_list)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "df_list.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23b95935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "room_type            0.05\n",
       "neighbourhood        0.05\n",
       "latitude             0.00\n",
       "minimum_nights       0.00\n",
       "longitude            0.00\n",
       "number_of_reviews    0.00\n",
       "price                0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inject a bit of missingness into categoricals to demonstrate handling\n",
    "rng = np.random.default_rng(7)\n",
    "n3 = len(df_list)\n",
    "\n",
    "# IMPORTANT: df_list index is 0..n3-1 (we reset_index above), so .loc with idx works safely.\n",
    "for col, rate in [(\"room_type\", 0.05), (\"neighbourhood\", 0.05)]:\n",
    "    idx = rng.choice(n3, size=max(1, int(rate*n3)), replace=False)\n",
    "    df_list.loc[idx, col] = np.nan\n",
    "\n",
    "df_list.isna().mean().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a54c7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Frequency (count) encoder for a single categorical column.\n",
    "\n",
    "    Works with:\n",
    "    - pandas DataFrame (single column)\n",
    "    - numpy array with shape (n_samples, 1) (common after SimpleImputer)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_df = pd.DataFrame(X)\n",
    "        s = X_df.iloc[:, 0].astype(\"object\")\n",
    "        freqs = s.value_counts(dropna=False)\n",
    "        self.mapping_ = (freqs / freqs.sum()).to_dict()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_df = pd.DataFrame(X)\n",
    "        s = X_df.iloc[:, 0].astype(\"object\")\n",
    "        out = s.map(self.mapping_).fillna(0.0).astype(float)\n",
    "        return out.to_frame(name=\"__freq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89d1e165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Encoding</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OneHot</td>\n",
       "      <td>81.987527</td>\n",
       "      <td>148.026645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frequency</td>\n",
       "      <td>84.202082</td>\n",
       "      <td>151.403117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TargetMean(OOF)</td>\n",
       "      <td>85.993144</td>\n",
       "      <td>150.802625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Encoding        MAE        RMSE\n",
       "0           OneHot  81.987527  148.026645\n",
       "1        Frequency  84.202082  151.403117\n",
       "2  TargetMean(OOF)  85.993144  150.802625"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xl = df_list.drop(columns=[\"price\"])\n",
    "yl = df_list[\"price\"]\n",
    "\n",
    "cat_cols_l = Xl.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols_l = [c for c in Xl.columns if c not in cat_cols_l]\n",
    "\n",
    "Xl_train, Xl_test, yl_train, yl_test = train_test_split(Xl, yl, test_size=0.25, random_state=42)\n",
    "\n",
    "numeric_trans_l = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "# --- One-hot pipeline ---\n",
    "cat_ohe_l = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"__MISSING__\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "pre_ohe_l = ColumnTransformer([\n",
    "    (\"num\", numeric_trans_l, num_cols_l),\n",
    "    (\"cat\", cat_ohe_l, cat_cols_l),\n",
    "])\n",
    "\n",
    "pipe_ohe_l = Pipeline(steps=[\n",
    "    (\"preprocess\", pre_ohe_l),\n",
    "    (\"model\", DecisionTreeRegressor(random_state=42, max_depth=8, min_samples_leaf=20)),\n",
    "])\n",
    "\n",
    "pipe_ohe_l.fit(Xl_train, yl_train)\n",
    "pred_ohe_l = pipe_ohe_l.predict(Xl_test)\n",
    "\n",
    "mae_ohe_l = mean_absolute_error(yl_test, pred_ohe_l)\n",
    "rmse_ohe_l = root_mean_squared_error(yl_test, pred_ohe_l)\n",
    "\n",
    "# --- Frequency encoding pipeline (per categorical column) ---\n",
    "pre_freq_l = ColumnTransformer(\n",
    "    [(\"num\", numeric_trans_l, num_cols_l)] +\n",
    "    [(f\"freq_{c}\", Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"__MISSING__\")),\n",
    "        (\"freq\", FrequencyEncoder()),\n",
    "    ]), [c]) for c in cat_cols_l]\n",
    ")\n",
    "\n",
    "pipe_freq_l = Pipeline(steps=[\n",
    "    (\"preprocess\", pre_freq_l),\n",
    "    (\"model\", DecisionTreeRegressor(random_state=42, max_depth=8, min_samples_leaf=20)),\n",
    "])\n",
    "\n",
    "pipe_freq_l.fit(Xl_train, yl_train)\n",
    "pred_freq_l = pipe_freq_l.predict(Xl_test)\n",
    "\n",
    "mae_freq_l = mean_absolute_error(yl_test, pred_freq_l)\n",
    "rmse_freq_l = root_mean_squared_error(yl_test, pred_freq_l)\n",
    "\n",
    "# --- Target mean encoding (OOF) pipeline ---\n",
    "pre_te_l = ColumnTransformer(\n",
    "    [(\"num\", numeric_trans_l, num_cols_l)] +\n",
    "    [(f\"te_{c}\", Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"__MISSING__\")),\n",
    "        (\"te\", TargetMeanEncoderOOF(smoothing=20.0, n_splits=5, random_state=42)),\n",
    "    ]), [c]) for c in cat_cols_l]\n",
    ")\n",
    "\n",
    "pipe_te_l = Pipeline(steps=[\n",
    "    (\"preprocess\", pre_te_l),\n",
    "    (\"model\", DecisionTreeRegressor(random_state=42, max_depth=8, min_samples_leaf=20)),\n",
    "])\n",
    "\n",
    "pipe_te_l.fit(Xl_train, yl_train)\n",
    "pred_te_l = pipe_te_l.predict(Xl_test)\n",
    "\n",
    "mae_te_l = mean_absolute_error(yl_test, pred_te_l)\n",
    "rmse_te_l = root_mean_squared_error(yl_test, pred_te_l)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Encoding\": [\"OneHot\", \"Frequency\", \"TargetMean(OOF)\"],\n",
    "    \"MAE\": [mae_ohe_l, mae_freq_l, mae_te_l],\n",
    "    \"RMSE\": [rmse_ohe_l, rmse_freq_l, rmse_te_l],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc62b5",
   "metadata": {},
   "source": [
    "\n",
    "### 6.1 Takeaways\n",
    "\n",
    "- One-hot often wins when cardinality is moderate and data size is sufficient, but it can be memory-heavy.\n",
    "- Frequency encoding is a compact “cheap baseline” that sometimes performs surprisingly well.\n",
    "- Target encoding can be strong for high-cardinality, but its real value depends on:\n",
    "  - enough data per category,\n",
    "  - leakage-safe implementation,\n",
    "  - and appropriate smoothing / regularization.\n",
    "\n",
    "**Rule of thumb:** start with OHE; if you have hundreds/thousands of categories (e.g., user IDs, product IDs, neighborhoods), evaluate frequency or target encoding with disciplined cross-validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2443dbc1",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Best practices summary (trees + missing + categoricals)\n",
    "\n",
    "### Missing values\n",
    "- **Start simple:** median/mode imputation.\n",
    "- For categorical missingness, prefer a dedicated token `\"__MISSING__\"` so missingness becomes an explicit feature after OHE.\n",
    "- Use missing indicators if missingness might carry information.\n",
    "- Prefer pipelines to avoid leakage.\n",
    "\n",
    "### Categorical variables\n",
    "- Default: **OneHotEncoder(handle_unknown=\"ignore\")**.\n",
    "- If you have very high cardinality:\n",
    "  - evaluate **frequency** or **target encoding**,\n",
    "  - use smoothing and out-of-fold discipline for target encoding,\n",
    "  - control tree capacity: `max_depth`, `min_samples_leaf`, `min_samples_split`.\n",
    "\n",
    "### Capacity control (prevents overfitting on rare categories)\n",
    "- Increase `min_samples_leaf` (very effective).\n",
    "- Limit `max_depth`.\n",
    "- Consider post-pruning or ensembles (next chapter).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b0d246",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Exercises (with guidance)\n",
    "\n",
    "1. **Drug200 robustness**\n",
    "   - Increase missingness to 20% in `BP` and 20% in `Sex`.\n",
    "   - Compare Pipeline A vs Pipeline B again.\n",
    "   - Which pipeline degrades more slowly? Why?\n",
    "\n",
    "2. **House prices sensitivity**\n",
    "   - Vary `max_depth` from 2 to 12 for the OHE pipeline.\n",
    "   - Plot depth vs RMSE.\n",
    "   - Explain the bias–variance pattern you see.\n",
    "\n",
    "3. **High-cardinality experiment**\n",
    "   - In `listings.csv`, add `neighbourhood_group` (if present) and compare encodings again.\n",
    "   - Try different smoothing values for `TargetMeanEncoder` (e.g., 1, 10, 50, 200).\n",
    "\n",
    "4. **New dataset challenge**\n",
    "   - Use `../../../Datasets/Classification/stars.csv` (categoricals: `Color`, `Spectral_Class`) to predict `Type`.\n",
    "   - Implement a classification pipeline with constant-impute + OHE.\n",
    "   - Add class weighting or depth control if you see imbalance.\n",
    "\n",
    "5. **Write-up**\n",
    "   - In 5–10 bullet points, document your final recommendation for “trees + missing + categoricals” for a real project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0b3811",
   "metadata": {},
   "source": [
    "\n",
    "### What’s next?\n",
    "\n",
    "In the next lesson we will discuss **tree stability and variance**, why small data changes can create different trees, and how this motivates bagging and random forests.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
